{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"aigcpaper","date":"2023-10-20T10:08:21.379Z","updated":"2023-10-20T10:31:41.632Z","comments":true,"path":"api/articles/aigcpaper.json","keywords":null,"cover":[],"content":"<p><a href=\"https://github.com/luban-agi/awesome-aigc-tutorials\"><img\r\nsrc=\"https://camo.githubusercontent.com/64f8905651212a80869afbecbf0a9c52a5d1e70beab750dea40a994fa9a9f3c6/68747470733a2f2f617765736f6d652e72652f62616467652e737667\"\r\nalt=\"Awesome\" /></a> <a href=\"https://opensource.org/licenses/MIT\"><img\r\nsrc=\"https://img.shields.io/badge/License-MIT-green.svg\"\r\nalt=\"License: MIT\" /></a> <img\r\nsrc=\"https://img.shields.io/github/last-commit/luban-agi/Awesome-AIGC-Tutorials?color=green\" />\r\n<a href=\"https://github.com/luban-agi/Awesome-AIGC-Tutorials\"><img\r\nsrc=\"https://img.shields.io/github/stars/luban-agi/Awesome-AIGC-Tutorials?style=social\"\r\nalt=\"GitHub Repo stars\" /></a></p>\r\n<p>这里收集了关于AIGC的各种精选教程和资源，既适合初学者也适合进阶AI爱好者。</p>\r\n<h2 id=\"目录\">📜 目录</h2>\r\n<ul>\r\n<li><a href=\"#-入门\">👋 入门</a></li>\r\n<li><a href=\"#-大语言模型\">💬 大语言模型</a>\r\n<ul>\r\n<li><a href=\"#-提示工程\">💡 提示工程</a></li>\r\n<li><a href=\"#-大语言模型实践\">🔧 大语言模型实践</a></li>\r\n<li><a href=\"#-大语言模型理论\">🔬 大语言模型理论</a></li>\r\n</ul></li>\r\n<li><a href=\"#-ai绘画\">🎨 AI绘画</a>\r\n<ul>\r\n<li><a href=\"#-艺术基础与ai绘画技巧\">🧑‍🎨 艺术基础与AI绘画技巧</a></li>\r\n<li><a href=\"#-stable-diffusion原理与应用\">🌊 Stable\r\nDiffusion原理与应用</a></li>\r\n</ul></li>\r\n<li><a href=\"#-ai音频\">🔊 AI音频</a></li>\r\n<li><a href=\"#-多模态\">🌈 多模态</a></li>\r\n<li><a href=\"#-深度学习\">🧠 深度学习</a></li>\r\n<li><a href=\"#-ai系统\">💻 AI系统</a></li>\r\n<li><a href=\"#-其他\">🗂 其他</a>\r\n<ul>\r\n<li><a href=\"#-点赞历史\">✨ 点赞历史</a></li>\r\n<li><a href=\"#-友情链接\">🤝 友情链接</a></li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"入门\">👋 入门</h2>\r\n<ul>\r\n<li><a href=\"https://www.deeplearning.ai/courses/ai-for-everyone/\">AI\r\nfor Everyone - 吴恩达</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.youtube.com/playlist?list=PLwRdpYzPkkn302_rL5RrXvQE8j0jLP02j\">Practical\r\nAI for Teachers and Students - 沃顿商学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://microsoft.github.io/AI-For-Beginners/\">Artificial\r\nIntelligence for Beginners - 微软</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a\r\nhref=\"https://www.cloudskillsboost.google/journeys/118\">Generative AI\r\nlearning path - 谷歌</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h2 id=\"大语言模型\">💬 大语言模型</h2>\r\n<h3 id=\"提示工程\">💡 提示工程</h3>\r\n<ul>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\">ChatGPT\r\nPrompt Engineering for Developers - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/\">Building\r\nSystems with the ChatGPT API - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\">LangChain\r\nfor LLM Application Development - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/Video-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/\">LangChain:\r\nChat with Your Data - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.coursera.org/learn/prompt-engineering?utm_medium=sem&amp;utm_source=gg&amp;utm_campaign=B2C_EMEA_prompt-engineering_vanderbilt_FTCOF_learn_country-GB-country-UK&amp;campaignid=20462816306&amp;adgroupid=157715342052&amp;device=c&amp;keyword=prompt%20engineering%20coursera&amp;matchtype=b&amp;network=g&amp;devicemodel=&amp;adposition=&amp;creativeid=670151312123&amp;hide_mobile_promo&amp;gclid=Cj0KCQjwuZGnBhD1ARIsACxbAVg8RCaUF0lwFyVnMuP7T7bHoH0jST0XXhQ3S1vmDxtZc8O1WlJ8FXQaAtG-EALw_wcB\">Prompt\r\nEngineering for ChatGPT - 范德堡大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://learnprompting.org/\">Learn Prompting</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"https://www.pinecone.io/learn/series/langchain/\">LangChain\r\nAI Handbook - James Briggs, Francisco Ingham</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/书籍-%2391672c\" /></li>\r\n</ul>\r\n<h3 id=\"大语言模型实践\">🔧 大语言模型实践</h3>\r\n<ul>\r\n<li><a\r\nhref=\"https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/\">LLM\r\nBootcamp - The Full Stack</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/finetuning-large-language-models/\">Finetuning\r\nLarge Language Models - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h3 id=\"大语言模型理论\">🔬 大语言模型理论</h3>\r\n<ul>\r\n<li><a href=\"https://stanford-cs324.github.io/winter2023/\">CS324 -\r\nAdvances in Foundation Models - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" />\r\n<ul>\r\n<li>斯坦福大学关于大模型的新课，主要材料是一些notes，介绍了大语言模型的基础知识、能力范围、训练部署以及一些大模型相关的问题（数据安全、法律、危害等），总体来说比较简单，适合入门。2023年的版本对课纲进行了更新，增加了关于图像-文本和多模态的大模型内容。</li>\r\n</ul></li>\r\n<li><a href=\"https://self-supervised.cs.jhu.edu/sp2023/index.html\">CS\r\n601.471/671 NLP: Self-supervised Models - 约翰霍普金斯大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" />\r\n<ul>\r\n<li>JHU也是NLP大牛校，这门课难度适中，课程主页上各类资源还挺多的，建议大家看一看。</li>\r\n</ul></li>\r\n<li><a href=\"https://web.stanford.edu/class/cs224n/\">CS224N: Natural\r\nLanguage Processing with Deep Learning - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>这门课Christopher\r\nManning在斯坦福开了很多年，很经典的课程。前面是NLP的基础知识，后面几节课会涉及到大语言模型。</li>\r\n</ul></li>\r\n<li><a href=\"https://web.stanford.edu/~jurafsky/slp3/\">Speech and\r\nLanguage Processing - Dan Jurafsky and James H. Martin</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/书籍-%2391672c\" />\r\n<ul>\r\n<li>最经典的NLP教材，本来计划在大概三四年前就完稿的，但是由于近几年NLP领域发展实在太快，作者干脆就不设DDL了，一直在持续更新中。</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://www.cs.princeton.edu/courses/archive/fall22/cos597G/\">COS\r\n597G (Fall 2022): Understanding Large Language Models - 普林斯顿大学</a>\r\n<img src=\"https://img.shields.io/badge/Level-困难-red\" />\r\n<ul>\r\n<li>Danqi\r\nChen的课，课程难度较高，主要材料是PPT和相关的论文，适合深入LLM某个方向的同学。</li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"ai绘画\">🎨 AI绘画</h2>\r\n<h3 id=\"艺术基础与ai绘画技巧\">🧑‍🎨 艺术基础与AI绘画技巧</h3>\r\n<ul>\r\n<li><a\r\nhref=\"https://www.niji.academy/work/lecture\">系列讲座:每周一个关于艺术基础的有趣话题\r\n- Niji Academy</a> <a\r\nhref=\"https://mp.weixin.qq.com/s/CxEv5NQF_wzAtqXnuNbKog\">[中文版]</a>\r\n<img src=\"https://img.shields.io/badge/Level-简单-green\" /></li>\r\n<li><a\r\nhref=\"https://ciweicui.feishu.cn/docx/DPbidgdBeoNw55xKjO6c7ao3nbc\">AIGCTalk-Midjourney学习手册</a>\r\n<img src=\"https://img.shields.io/badge/Level-简单-green\" /></li>\r\n<li><a\r\nhref=\"https://space.bilibili.com/630876766/channel/collectiondetail?sid=1045607\">【Midjourney】保姆级AI绘画创作系列教学课程\r\n- 莱森</a> <img src=\"https://img.shields.io/badge/Level-简单-green\" />\r\n<img src=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h3 id=\"stable-diffusion原理与应用\">🌊 Stable Diffusion原理与应用</h3>\r\n<ul>\r\n<li><a\r\nhref=\"https://space.bilibili.com/12566101/channel/seriesdetail?sid=2706990\">【AI绘画】Stable\r\nDiffusion 系列教程</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>秋葉aaaki大神喂饭级别Stable Diffusion 系列教程</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/how-diffusion-models-work/\">How\r\nDiffusion Models Work - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.bilibili.com/video/BV14c411J7f2/?vd_source=a4218e1e16a294070cadf4eefa94fa32\">扩散模型\r\n- Diffusion Model - 李宏毅</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>偏宏观，比较通俗易懂</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://www.bilibili.com/video/BV1Re4y1s7uV/?p=1&amp;vd_source=a4218e1e16a294070cadf4eefa94fa32\">Diffusion扩散模型\r\n- 唐宇迪</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>唐宇迪老师讲stable diffusion和dalle推理讲的比较清楚</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://github.com/huggingface/diffusion-models-class\">Hugging\r\nFace Diffusion Models Course</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n</ul>\r\n<h2 id=\"ai音频\">🔊 AI音频</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://huggingface.co/learn/audio-course/chapter0/introduction\">Hugging\r\nFace Audio Course</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"http://web.stanford.edu/class/cs224s/\">CS224S: Spoken\r\nLanguage Processing - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n</ul>\r\n<h2 id=\"多模态\">🌈 多模态</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://cmu-multicomp-lab.github.io/mmml-tutorial/icml2023/\">Tutorial\r\non MultiModal Machine Learning (ICML 2023) - 卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://cmu-multicomp-lab.github.io/mmml-course/fall2022/\">11-777:\r\nMultiModal Machine Learning (Fall 2022) - 卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://cmu-multicomp-lab.github.io/adv-mmml-course/spring2022/\">11-877:\r\nAdvanced Topics in MultiModal Machine Learning (Fall 2022) -\r\n卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /></li>\r\n</ul>\r\n<h2 id=\"深度学习\">🧠 深度学习</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://www.youtube.com/playlist?list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1\">Neural\r\nNetworks/Deep Learning - StatQuest</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://www.3blue1brown.com/topics/neural-networks\">Neural\r\nNetworks - 3Blue1Brown</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://karpathy.ai/zero-to-hero.html\">Neural Networks:\r\nZero to Hero - Andrej Karpathy</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://course.fast.ai/\">Practical Deep Learning for Coders\r\n- fast.ai</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/courses/deep-learning-specialization/\">Deep\r\nLearning Specialization - 吴恩达</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"http://introtodeeplearning.com/\">6.S191: Introduction to\r\nDeep Learning - 麻省理工学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://web.stanford.edu/class/cs25/\">CS25: Transformers\r\nUnited V2 - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deepmind.com/learning-resources/deep-learning-lecture-series-2020\">Deep\r\nLearning Lecture Series 2020 - DeepMind x 伦敦大学学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021\">Reinforcement\r\nLearning Lecture Series 2021 - DeepMind x 伦敦大学学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h2 id=\"ai系统\">💻 AI系统</h2>\r\n<ul>\r\n<li><a href=\"https://ucbrise.github.io/cs294-ai-sys-sp22/\">AI-Sys-Sp22\r\nMachine Learning Systems - 加州大学伯克利分校</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"https://dlsyscourse.org/\">Deep Learning Systems: Algorithms\r\nand Implementation - Tianqi Chen, Zico Kolter</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://stanford-cs329s.github.io/\">CS 329S: Machine\r\nLearning Systems Design - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"https://www.cs.cmu.edu/~zhihaoj2/15-849/\">15-849: Machine\r\nLearning Systems - 卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /></li>\r\n<li><a\r\nhref=\"https://www.cs.princeton.edu/courses/archive/spring21/cos598D/general.html\">Computer\r\nScience 598D - Systems and Machine Learning - 普林斯顿大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /></li>\r\n</ul>\r\n<h2 id=\"aigc视频会议访谈\">AIGC视频会议&amp;访谈</h2>\r\n<h3 id=\"智源社区\">智源社区</h3>\r\n<p><strong>【论文分享】</strong>【AugGPT：利用ChatGPT进行文本数据增强\r\n】[<a href=\"https://event.baai.ac.cn/activities/664\">link</a>]</p>\r\n<p><strong>【论文分享】</strong>【ChatGPT的鲁棒性探究——对抗性和分布外泛化的视角\r\n】[<a href=\"https://event.baai.ac.cn/activities/657\">link</a>]</p>\r\n<p><strong>【论文分享】</strong>【传统检索模型和大语言模型在信息搜索中的应用和对比\r\n】[<a href=\"https://event.baai.ac.cn/activities/656\">link</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2209.10063\">paper</a>]，[<a\r\nhref=\"https://github.com/wyu97/GenRead\">code</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/24380\">blog</a>]</p>\r\n<h3 id=\"访谈视频\">访谈&amp;视频</h3>\r\n<p><strong>【访谈】</strong>【OpenAI 的核心研发人员 Jack Rae 在参加\r\nStanford MLSys Seminar 的访谈时进行了一个名为 Compression for\r\nAGI的主题分享 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/hQmvltuMlClBonM6UJmtLg\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【万字长文：想训大模型？这里有一份避坑指南】[<a\r\nhref=\"https://mp.weixin.qq.com/s/yX5B1ZzV7vewQs1-ezHIQg\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【微软Bing版ChatGPT表明想做人类，并且对纽约时报专栏作家表达爱意】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485854&amp;idx=1&amp;sn=011e0ef0f2c69cd48d042495b2a47eb3&amp;chksm=ced54a7af9a2c36c29fec6301236685d443bde94681ec3f669408d953ae92bb54b686aeab9f8&amp;token=447941009&amp;lang=zh_CN#rd\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【Midjourney创始人David\r\nHolz关于生成式AI的访谈】[<a\r\nhref=\"https://mp.weixin.qq.com/s/jMyuSYu8ACk2peu_OfZK0w\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【OpenAI创始人：GPT-4的研究起源和构建心法】[<a\r\nhref=\"https://mp.weixin.qq.com/s/hO1ZdqgOjpA328luobQ9eg\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【ABC News\r\n专访OpenAI首席执行官萨姆·奥尔特曼：AI风险和重塑社会的问题】[<a\r\nhref=\"%5BOpenAI%20CEO%20Sam%20Altman%20says%20AI%20will%20reshape%20society,%20acknowledges%20risks:%20&#39;A%20little%20bit%20scared%20of%20this%5D(https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122)\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【OpenAI联合创始人Ilya\r\nSutskever等专访：开源人工智能是不明智的】[<a\r\nhref=\"https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【OpenAI董事长、CTO Greg Brockman专访\r\n：GPT-4 并不完美，不过人无完人】[<a\r\nhref=\"https://techcrunch.com/2023/03/15/interview-with-openais-greg-brockman-gpt-4-isnt-perfect-but-neither-are-you/\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【图灵奖获得者 Yoshua Bengio 认为 ChatGPT\r\n是一个“警钟”】[<a\r\nhref=\"https://mp.weixin.qq.com/s/2-QoJHKWxiS63vEjX9OOGQ\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【《麻省理工科技评论》对 ChatGPT\r\n幕后团队，进行了一次深入的独家专访】[<a\r\nhref=\"https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【口述历史，探析ChatGPT的创造历程，ChatGPT内部故事】[<a\r\nhref=\"https://mp.weixin.qq.com/s/RAdIxzdgs3elUiozB8cH8g\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【对话ChatGPT之父！AI会改变什么？不会改变什么？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zNuOmVeVKP335iJ4RNJqNw\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【对话OpenAI研究科学家：他们是如何让GPT4更像人的？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iJImioHXxelCxUsETSxuXw\">访谈记录</a>]</p>\r\n<p><strong>【视频】</strong>【邱锡鹏教授介绍以ChatGPT为核心的大规模语言模型的相关知识及未来的发展方向\r\n】[<a href=\"https://www.bilibili.com/video/BV1Xb411X7c3/\">B站</a>]</p>\r\n<h2 id=\"llm体验效果专业评估\">LLM体验效果&amp;专业评估</h2>\r\n<p><strong>【LLM效果对比】</strong>【360智脑_VS_讯飞星火】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486609&amp;idx=2&amp;sn=7fedb8ab37588d43968fdec2d7e5fcdd&amp;chksm=ced54f75f9a2c663b9a2671f2548e2940730735605356cc0ffe72bc737470136a40032c80bfe&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【阿里通义千问_VS_讯飞星火】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486534&amp;idx=1&amp;sn=6f36d41b618790cba62e63eb25bb033b&amp;chksm=ced54fa2f9a2c6b4a901528f87a7e74628dfd79d835f4cdea1ee4dea442f339adfd2736b2305&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【Bard_VS_Baize-7B_VS_文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486317&amp;idx=1&amp;sn=ea3cc745d2991b8c657325392ce68f71&amp;chksm=ced54889f9a2c19f3c2f85d8d7af7fff366027f79d1f4a5b2c650fea1b5dee9efde0b7c992ca&amp;token=1173964254&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【Bard_VS_Bing_VS_ChatGPT】[<a\r\nhref=\"https://www.theverge.com/2023/3/24/23653377/ai-chatbots-comparison-bard-bing-chatgpt-gpt-4\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【Bard_VS_文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486260&amp;idx=1&amp;sn=a41224fee7ed4cb4a48eb40a420d7479&amp;chksm=ced548d0f9a2c1c6f4930f30447468f9f01bb2af6031368e302b13a6354fc4bca6636e3b297e&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【ChatGPT_VS_GPT4】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485952&amp;idx=2&amp;sn=e54a62e358bf7aee3c007d59600fd452&amp;chksm=ced549e4f9a2c0f2868eb8877c14fbe287a469e63b09774cefcb9edc4c0601016f6d36561973&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【OpenAssistant_VS_百度文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486413&amp;idx=2&amp;sn=3816e5a4bccceee5e2af868166b18897&amp;chksm=ced54829f9a2c13fb787b7a7e3c2aa0799eb7ff6d124f6847349346146900e05684ceb8cc7f7&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言新闻发布会内容复现】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486081&amp;idx=1&amp;sn=034480a8b00778cb6a4f2b5ea4214974&amp;chksm=ced54965f9a2c0733ff09fbff4953da484180f48545da3d9b476f1e7375c162f9e8d4eaa0afd&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言_VS_ChatGLM-6B】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486081&amp;idx=2&amp;sn=fd87305419158d66dd4b05b57bee1324&amp;chksm=ced54965f9a2c073ba1badfedbc6610036455cd769a3c8ee3445f7fbff9364b5624091be9914&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言 VS GPT-4：20道问答PK】[<a\r\nhref=\"https://mp.weixin.qq.com/s/l1pTPlohMmiYEMc4x6QKhw\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言 vs GPT-4实测！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/uO8N3RpcrYU8rV1RkwBxzQ\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【讯飞星火_VS_文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486490&amp;idx=1&amp;sn=c8d756f7f26a4e35f8b67ae485efabce&amp;chksm=ced54ffef9a2c6e8d66f8b744d6af524e320d5aec384d142621cee53fd2150f2c7db1fa7596a&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【一文看遍各行业对ChatGPT的专业评估】[<a\r\nhref=\"https://mp.weixin.qq.com/s/2JryWW33j9udOpi3dK5X9g\">blog</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【ChatGPT关于推理、幻觉和交互的多任务、多语言、多通道评估\r\n】[<a href=\"https://arxiv.org/abs/2302.04023\">paper</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【如何评价 OpenAI 的超级对话模型\r\nChatGPT ？】[<a\r\nhref=\"https://www.zhihu.com/question/570189639\">paper</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【用ChatGPT参加计算机科学考试】[<a\r\nhref=\"https://arxiv.org/abs/2303.09461\">paper</a>]</p>\r\n<p><strong>【LLM知识评估】</strong>【C-Eval：构造中文大模型的知识评估基准】[<a\r\nhref=\"https://cevalbenchmark.com/\">主页</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/4560jl7ctWmHz3xGVIKkRw\">paper</a>]，[<a\r\nhref=\"https://github.com/SJTU-LIT/ceval\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/4560jl7ctWmHz3xGVIKkRw\">blog</a>]</p>\r\n<p><strong>【MLLM幻觉评估】</strong>【多模态大模型的幻觉问题与评估】[<a\r\nhref=\"https://mp.weixin.qq.com/s/s0z-mAyjAaqvNcaTg2VFEA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2305.10355\">paper</a>]，[<a\r\nhref=\"https://github.com/RUCAIBox/POPE\">code</a>]</p>\r\n<p><strong>【各大大模型评测】</strong>【粗看大模型ChatGLM、MOSS、Bloomz在中文垂域评测中的性能表现：医学、法律、心理学、教育等四大类试题下的测试报告介绍】[<a\r\nhref=\"https://arxiv.org/pdf/2304.12986.pdf\">paper</a>]，[<a\r\nhref=\"github.com/Felixgithub2017/MMCU\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Hq6bn_4vD559TMQxx806tg\">blog</a>]</p>\r\n<p><strong>【国内大模型评测】</strong>【评测国内各种对标 ChatGPT\r\n的大语言模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Oe1Rc0kXjMOD2G_Sqambow\">blog</a>]，[<a\r\nhref=\"https://github.com/dongrixinyu/JioNLP/wiki/LLM%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86\">code</a>]</p>\r\n<p><strong>【大模型排行榜】</strong>【OpenLLM大模型排行榜】[<a\r\nhref=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\">主页</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/t1Th8iFOGoyuqqysUiIcXQ\">blog</a>]，[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/642996275\">最新进展blog</a>]</p>\r\n<p><strong>【大模型排行榜】</strong>【斯坦福发布LLM排行榜AlpacaEval，微软WizardLM登顶开源模型第一】[<a\r\nhref=\"https://mp.weixin.qq.com/s/7X8pRaexWJ4c0kVswawU1A\">blog</a>]，[<a\r\nhref=\"https://tatsu-lab.github.io/alpaca_eval\">主页</a>]，[<a\r\nhref=\"https://github.com/tatsu-lab/alpaca_eval\">code</a>]</p>\r\n<h2 id=\"llm垂直领域大模型\">LLM垂直领域大模型</h2>\r\n<h3 id=\"法律\">法律</h3>\r\n<p>【再看基于LLaMA的最新微调模型变体：CaMA、ExpertLLaMA以及第四个中文法律微调模型LexiLaw】[<a\r\nhref=\"https://mp.weixin.qq.com/s/FYWmMH2ndN5XfWvwI9dcUA\">blog</a>]</p>\r\n<p>【基于中文法律知识的大语言模型——LaWGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s/dI839IF0hdBTAfOBUg7Pfw\">blog</a>]</p>\r\n<h3 id=\"医疗\">医疗</h3>\r\n<p>【AD-AutoGPT：用于阿尔茨海默病信息流行病学的自主GPT】[<a\r\nhref=\"https://arxiv.org/abs/2306.10095\">paper</a>]</p>\r\n<p>【MedQA-ChatGLM - 基于真实医疗对话数据在ChatGLM上进行微调】[<a\r\nhref=\"http://github.com/WangRongsheng/MedQA-ChatGLM\">code</a>]，[<a\r\nhref=\"https://www.wangrs.co/MedQA-ChatGLM/\">主页</a>]</p>\r\n<p>【谷歌医疗大模型登Nature，Med-PaLM重磅揭秘！AI医生成绩比肩人类】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Qf4Ts7UKJNzkW1Tfy-b0Zg\">blog</a>]，[<a\r\nhref=\"https://www.nature.com/articles/s41586-023-06291-2\">paper</a>]</p>\r\n<p>【PULSE：中文医疗大语言模型】[<a\r\nhref=\"https://huggingface.co/OpenMEDLab/PULSE-7bv5\">code</a>]</p>\r\n<h3 id=\"金融\">金融</h3>\r\n<p>【FinGPT：一个「专用于金融领域」的开源大语言模型（LLM）框架，源码公开！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/A9euFin675nxGGciiX6rJQ\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2306.06031v1.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/ai4finance-foundation/fingpt\">code</a>]</p>\r\n<h3 id=\"环境\">环境</h3>\r\n<p>【清华&amp;中国气象局大模型登Nature：预报时效首次达3小时】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Aygm03CdA0zFNf9F3_JU5A\">blog</a>]，[<a\r\nhref=\"https://www.nature.com/articles/s41586-023-06184-4\">paper</a>]</p>\r\n<h3 id=\"网络安全\">网络安全</h3>\r\n<p>【专用于网络攻击的模型FraudGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s/OtLNybsbxDlbVb-cs4Zk8g\">blog</a>]</p>\r\n<h3 id=\"交通\">交通</h3>\r\n<p>【北交大开源交通大模型TransGPT·致远，可免费商用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/WvzyjHqI0lOGIyPlCIFNQg\">blog</a>]，[<a\r\nhref=\"https://github.com/DUOMO/TransGPT\">code</a>]</p>\r\n<h3 id=\"其他\">其他</h3>\r\n<p>【南洋理工开源海外中文大语言模型Panda LLM |\r\n探索数据因素和训练策略如何影响大模型性能表现】[<a\r\nhref=\"https://arxiv.org/pdf/2305.03025v1.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/dandelionsllm/pandallm\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/IsWSPAvwgT263wjO7TYTZQ\">blog</a>]</p>\r\n<h2 id=\"llm文本检测\">LLM文本检测</h2>\r\n<p><strong>【论文&amp;代码】</strong>【美国麻省大学&amp;谷歌研究院：改写文本可以避开AI生成文本的检测器，但检索则是一种有效的防御】[<a\r\nhref=\"https://papers.labml.ai/api/v1/redirect/pdf?paper_key=2cfe8cecc9f211edb95839eec3084ddd\">paper</a>]，[<a\r\nhref=\"https://github.com/martiansideofthemoon/ai-detection-paraphrases\">code</a>]</p>\r\n<p><strong>【论文】</strong>【人工智能生成的文本能被可靠地检测出来吗？】[<a\r\nhref=\"https://arxiv.org/pdf/2303.11156.pdf\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486128&amp;idx=3&amp;sn=e5ea32b7d7cb4c8c41f29a9ea15ac3ac&amp;chksm=ced54954f9a2c0425a65761f1766550f6b90857da0106f6fd55f3c6773fbdbd1fc45bbb9369a&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【DetectGPT（斯坦福大学）：利用概率曲率检测文本是否大模型生成】[<a\r\nhref=\"https://arxiv.org/abs/2301.11305\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485713&amp;idx=2&amp;sn=805caf25603cf15dbf71949f85b9d041&amp;chksm=ced54af5f9a2c3e3e0dffd728592fd7ab8f738869e94240daba4fad9f6ac90a2f76a6b458e3f&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://ericmitchell.ai/detectgpt/\">code&amp;data</a>]</p>\r\n<p><strong>【论文】</strong>【Detecting LLM-Generated-Text综述】[<a\r\nhref=\"https://github.com/datamllab/The-Science-of-LLM-generated-Text-Detection\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485747&amp;idx=1&amp;sn=5e5029a70c54c08f6f8c40631962b1e1&amp;chksm=ced54ad7f9a2c3c184ccb123199510bb09470e054fb5cb887e70bac204927b65e296f8921db1&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【一个专为<strong>教育</strong>者打造的全新\r\nAI 检测模型】[<a\r\nhref=\"https://gptzero.substack.com/p/gptzerox\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【OpenAI重磅发布官方「ChatGPT检测器」】[<a\r\nhref=\"https://mp.weixin.qq.com/s/EcZE7TgHspf22rPRWhAybw\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【斯坦福最新研究：不要过度依赖GPT生成内容，其检测器可能存在不利于非母语英语写作者的偏见】[<a\r\nhref=\"https://arxiv.org/abs/2304.02819\">paper</a>]</p>\r\n<h2 id=\"llm长文本解决方案\">LLM长文本解决方案</h2>\r\n<p><strong>【苏剑林】</strong>【Transformer升级之路：一种全局长度外推的新思路】[<a\r\nhref=\"https://mp.weixin.qq.com/s/YJ647EUfzWaJsGoMdgsguA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT能写长篇小说了，ETH提出RecurrentGPT实现交互式超长文本生成】[<a\r\nhref=\"https://arxiv.org/abs/2305.13304\">paper</a>]，[<a\r\nhref=\"https://github.com/aiwaves-cn/RecurrentGPT\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/5UVTwSWgoz7uhozMeps3EQ\">blog</a>]，[<a\r\nhref=\"https://www.aiwaves.org/recurrentgpt\"\r\ntitle=\"长篇小说写作\">demo1</a>]，[<a\r\nhref=\"https://www.aiwaves.org/interactivefiction\"\r\ntitle=\"交互式小说\">demo2</a>]</p>\r\n<p><strong>【博客】</strong>【语言大模型100K上下文窗口的秘诀】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_i0eQgYNSLJydv3qOTqr-Q\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【RoPE可能是LLM时代的Resnet】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BVm1XC7r1yzOiWIrEbWg3A\">blog</a>]</p>\r\n<h2 id=\"llm可控性与安全\">LLM可控性与安全</h2>\r\n<p><strong>【可控性】</strong>【微软提出Control-GPT：用GPT-4实现可控文本到图像生成！】[<a\r\nhref=\"https://arxiv.org/abs/2305.18583\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/U3eWeGOEt9nhW-Xwbuah9w\">blog</a>]</p>\r\n<p><strong>【可控性】</strong>【AIGC如何安全可控?中山大学等最新《AIGC中对隐私和安全的挑战及其补救措施：探索隐私计算、区块链潜在应用》全面阐述】[<a\r\nhref=\"https://www.zhuanzhi.ai/paper/0dd95e1d5aae9eb2e60aabf36a107482\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/V8QjMQSO2tX6PFx_LfLIEA\">blog</a>]</p>\r\n<p><strong>【可控性】</strong>【ControlVideo:\r\n可控的Training-free的文本生成视频】[<a\r\nhref=\"https://mp.weixin.qq.com/s/CAH6u-MT3cFM359d5_Xpxg\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2305.13077.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/YBYBZhang/ControlVideo\">code</a>]</p>\r\n<p><strong>【安全】</strong>【大模型切脑后变身PoisonGPT，虚假信息案例】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27736\">blog</a>]，[<a\r\nhref=\"https://colab.research.google.com/drive/16RPph6SobDLhisNzA5azcP-0uMGGq10R?usp=sharing&amp;ref=blog.mithrilsecurity.io\">code</a>]</p>\r\n<p><strong>【安全】</strong>【ChatGPT羊驼家族全沦陷！CMU博士击破LLM护栏，人类毁灭计划脱口而出】[<a\r\nhref=\"https://mp.weixin.qq.com/s/298nwP98UdRNybV2Fuo6Wg\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2307.15043\">paper</a>]，[<a\r\nhref=\"https://github.com/llm-attacks/llm-attacks\">code</a>]</p>\r\n<h2 id=\"llm训练微调优化以及部署\">LLM训练、微调、优化以及部署</h2>\r\n<p><strong>【LLM学习网站】</strong>【训练、微调、优化和部署大模型最新技术LLM\r\nLearning Lab】[<a\r\nhref=\"https://lightning.ai/pages/llm-learning-lab/\">官网</a>]</p>\r\n<h3 id=\"llm训练\">LLM训练</h3>\r\n<p><strong>【LLM训练】</strong>【DeepSpeed的Tutorials】[<a\r\nhref=\"https://www.deepspeed.ai\">主页</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/xpNQtl7hPs3fy9S7VRbIkg\">DeepSpeed\r\nGetting Starte</a>]</p>\r\n<p><strong>【LLM训练】</strong>【如何使用 Megatron-LM 训练语言模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/QPg6gOWGbQDezTl8OFZU3g\">blog</a>]</p>\r\n<p><strong>【LLM训练】</strong>【Muti Query Attention 和 Attention with\r\nLinear Bias（附源码）】[<a\r\nhref=\"https://mp.weixin.qq.com/s/GXMwnbWLce9Aq4alEHCHJA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/1911.02150.pdf\">paper</a>]</p>\r\n<h3 id=\"llm微调\">LLM微调</h3>\r\n<p><strong>【LLM微调】</strong>【PEFT:\r\n在低资源硬件上对十亿规模模型进行参数高效微调 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/x2mQBE0pfTv8w3Czp8JkDg\">blog</a>]</p>\r\n<p><strong>【LLM微调】</strong>【大语言模型（LLM）微调技术笔记】[<a\r\nhref=\"https://github.com/ninehills/ninehills.github.io/issues/92\">code</a>]</p>\r\n<p><strong>【LLM微调】</strong>【大模型LLM-微调经验分享&amp;总结】[<a\r\nhref=\"https://github.com/liucongg/ChatGLM-Finetuning\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/pkBvL0k7sZWaW6jMlSSIZA\">blog</a>]</p>\r\n<p><strong>【LLM微调】</strong>【LoRA：卷完图像生成领域，卷文本生成领域的东西，到时是个啥？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/emLpTAOhr8khO1hTgQhU9w\">blog</a>]，[<a\r\nhref=\"https://github.com/microsoft/LoRA\">code</a>]</p>\r\n<p><strong>【LLM微调】</strong>【Washington大学2023年5月新提出一种高效的微调方法QLoRA，通过降低显存使用，实现在单个48GB\r\nGPU上对65B参数的大模型进行微调，只需微调12个小时就可以达到97%的ChatGPT水平。同时只用int4就可以保持fp16精度的效果。】[<a\r\nhref=\"https://arxiv.org/pdf/2305.14314.pdf\">paper</a>]</p>\r\n<p><strong>【LLM微调】</strong>【华盛顿大学提出全新量化和微调方法，在DB-GPT上享受33B参数的LLM】[<a\r\nhref=\"https://mp.weixin.qq.com/s/A3flqm2FeOn0WQr5mrD1-Q\">blog</a>]</p>\r\n<p><strong>【LLM微调】</strong>【陈丹琦团队提出低内存高效零阶优化器MeZO，单卡A100可训练300亿参数模型】[<a\r\nhref=\"https://arxiv.org/abs/2305.17333\">paper</a>]，[<a\r\nhref=\"https://github.com/princeton-nlp/MeZO\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/JteUpY4fEbENQFvReRLPJg\">blog</a>]</p>\r\n<h3 id=\"llm优化\">LLM优化</h3>\r\n<p><strong>【LLM优化】</strong>【LLM，压缩即泛化，泛化即智能】[<a\r\nhref=\"https://mp.weixin.qq.com/s/tSj9npIPg8IlYr2jbtg-Og\">blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【LLM-Pruner: 剪枝+少量数据+少量训练 =\r\n高效的LLM压缩】[<a\r\nhref=\"https://mp.weixin.qq.com/s/feqFfy4n31eztoZfodMieQ\">blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【邱锡鹏团队提出新优化器LOMO｜650亿参数，8块GPU全参数微调】[<a\r\nhref=\"https://mp.weixin.qq.com/s/339iXf2bimusfq6zQmFpWw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2306.09782\">paper</a>]</p>\r\n<p><strong>【LLM优化】</strong>【伯克利开源LLM推理与服务库：GPU减半、吞吐数十倍猛增】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27505\">中文blog</a>]，[<a\r\nhref=\"https://vllm.ai/?continueFlag=24b2e01413fd53e24a2779b4a664ca16\">英文blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【LLM\r\nAccelerator：使用参考文本无损加速大语言模型推理】[<a\r\nhref=\"https://mp.weixin.qq.com/s/H1JaQZ9-m2gkZaIwzJTTtg\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2304.04487.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/microsoft/LMOps\">code</a>]</p>\r\n<p><strong>【LLM优化】</strong>【大模型推理性能优化之KV Cache解读】[<a\r\nhref=\"https://mp.weixin.qq.com/s/ydjcUOF9iUM581hUTSXPdw\">blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【CAME：大模型训练成本降低近一半】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iUXu_Pfsop0bq7ktoXTY4A\">blog</a>]</p>\r\n<h3 id=\"llm部署\">LLM部署</h3>\r\n<p><strong>【LLM部署】</strong>【工程实践！以LLAMA为例的大模型部署方案】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zGkkekFqKsnM66uQwfUPcw\">blog</a>]</p>\r\n<p><strong>【LLM部署】</strong>【大模型部署框架FastLLM解析，支持X86/Arm/CUDA\r\n3种架构的硬件！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/j19QdlFvblcABXzB7Vi5wg\">blog</a>]，[<a\r\nhref=\"https://github.com/ztxz16/fastllm\">code</a>]</p>\r\n<h2 id=\"llm博客论文以及代码\">LLM博客、论文以及代码</h2>\r\n<p><strong>【综述】</strong>【中文大语言模型汇总：医疗、法律、金融、教育、数学微调，\r\n目前已1.1K星】[<a\r\nhref=\"https://github.com/HqWu-HITCS/Awesome-Chinese-LLM\">code</a>]</p>\r\n<p><strong>【综述】</strong>【大型语言模型综述全新出炉：从T5到GPT-4最全盘点，国内20余位研究者联合撰写】[<a\r\nhref=\"https://arxiv.org/abs/2303.18223\">paper</a>]</p>\r\n<p><strong>【综述】</strong>【大语言模型综述全新出炉：51页论文带你盘点LLM领域专业化技术】[<a\r\nhref=\"https://arxiv.org/abs/2305.18703\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/0DrowrTIgXsBhj3sYu6Aog\">blog</a>]</p>\r\n<p><strong>【综述】</strong>【AIGC综述:\r\n从GAN到ChatGPT的生成式人工智能简史】[<a\r\nhref=\"https://arxiv.org/abs/2303.04226v1\">paper</a>]</p>\r\n<p><strong>【综述】</strong>【大模型综述来了！一文带你理清全球AI巨头的大模型进化史】[<a\r\nhref=\"https://arxiv.org/pdf/2304.13712.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/Mooler0410/LLMsPracticalGuide\">code</a>]</p>\r\n<p><strong>【复旦大学】</strong>【复旦大学教授肖仰华：ChatGPT\r\n浪潮下，面向大模型如何做数据治理？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/od24PYvFLUJe4NQxjvsbMw\">blog</a>]</p>\r\n<p><strong>【谷歌】</strong>【面向决策的基础模型: 问题、方法与机会】[<a\r\nhref=\"https://arxiv.org/abs/2303.04129\">paper</a>]</p>\r\n<p><strong>【谷歌】</strong>【较大语言模型上下文学习的方式有所不同】[<a\r\nhref=\"https://arxiv.org/abs/2303.03846\">paper</a>]</p>\r\n<p><strong>【谷歌】</strong>【通用语音识别大模型已经支持100+语言】[<a\r\nhref=\"https://mp.weixin.qq.com/s/fHr2vL-w4JtYt5utcZrbsw\">blog</a>]</p>\r\n<p><strong>【谷歌】</strong>【发布5620亿参数多模态模型PaLM-E，机器人操控再上台阶】[<a\r\nhref=\"https://arxiv.org/abs/2303.03378\">paper</a>]，[<a\r\nhref=\"https://palm-e.github.io/\">blog</a>]，[<a\r\nhref=\"https://twitter.com/DannyDriess/status/1632904675124035585\">twitter</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/yZt3sEQPzVjnIvqXsNOnPA\">video</a>]</p>\r\n<p><strong>【Huawei】</strong>【PanGu-Σ:\r\n稀疏异构计算万亿参数语言模型研究参数语言模型】[<a\r\nhref=\"https://arxiv.org/abs/2303.10845\">paper</a>]</p>\r\n<p><strong>【剑桥大学】</strong>【奖励聊天机器人在现实世界中与数以百万计的用户进行互动】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06135.pdf\">paper</a>]</p>\r\n<p><strong>【LeCun】</strong>【人工智能系统最终是否需要以现实为基础，而不仅仅是从语言中学习？】[<a\r\nhref=\"https://spectrum.ieee.org/ai-hallucination\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【大型语言模型是否需要感官基础来理解意义和理解？】[<a\r\nhref=\"https://drive.google.com/file/d/1BU5bV3X5w65DwSMapKcsr0ZvrMRU_Nbi/view\">slices</a>]</p>\r\n<p><strong>【LeCun】</strong>【ChatGPT是「外星人」，所以才会胡说八道】[<a\r\nhref=\"https://www.noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&amp;utm_medium=noemasocial\">paper</a>]，[<a\r\nhref=\"https://twitter.com/ylecun/status/1633459264508542978\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【AI聊天机器人并不关注用户的社交属性】[<a\r\nhref=\"https://www.noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&amp;utm_medium=noemasocial\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【LeCun和马库斯齐喷ChatGPT：大语言模型果然是邪路？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/5e0aTSEAym9rF5QxRndLgQ\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【ChatGPT无法实现通用人工智能，但ALM技术路线也许可以】[<a\r\nhref=\"https://mp.weixin.qq.com/s/MEdl3zmiYJU1iFsTXmibng\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【「增强语言模型」的综述 】[<a\r\nhref=\"https://arxiv.org/abs/2302.07842\">paper</a>]</p>\r\n<p><strong>【LeCun】</strong>【自回归LLM的缺陷之一，大语言模型必须知道的8个要点】[<a\r\nhref=\"https://cims.nyu.edu/~sbowman/eightthings.pdf\">paper</a>]</p>\r\n<p><strong>【MIT】</strong>【从词模型到世界模型：从自然语言到思维概率语言的转变】[<a\r\nhref=\"https://arxiv.org/abs/2306.12672\">paper</a>]</p>\r\n<p><strong>【李开复】</strong>【AI进入2.0时代，所有应用都会被重写一遍\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zV8Y9RQnIoExwa1mmarZmA\">blog</a>]</p>\r\n<p><strong>【纽约大学】</strong>【提出ILF（从语言反馈中模仿学习）：利用语言反馈大规模训练语言模型】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16755.pdf\">paper</a>]</p>\r\n<p><strong>【OpenAI】</strong>【GPT就是GPT：大模型对劳动力市场影响潜力的早期研究】[<a\r\nhref=\"https://arxiv.org/pdf/2303.10130.pdf\">paper</a>]</p>\r\n<p><strong>【OpenAI】</strong>【ABC News\r\n专访OpenAI首席执行官萨姆·奥尔特曼：AI风险和重塑社会的问题】[<a\r\nhref=\"https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【最新发布通用人工智能路线图！AGI比想象中来得更快！】[<a\r\nhref=\"https://openai.com/blog/planning-for-agi-and-beyond/\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【Sam\r\nAltman 担心“潜在的可怕的”人工智能工具以及“未来的人们如何看待我们” 】[<a\r\nhref=\"https://finance.yahoo.com/news/openai-ceo-sam-altman-frets-165250285.html\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【The Age of\r\nAI：拾象大模型及OpenAI投资思考】[<a\r\nhref=\"https://mp.weixin.qq.com/s/AxX-Q7njegNTAxMkYFwsfA\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【为什么ChatGPT用强化学习而非监督学习？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/4USDakdomupWuwwhex6fMg\">blog</a>]</p>\r\n<p><strong>【OpenNLPLab】</strong>【为什么ChatGPT用强化学习而非监督学习？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/UZ9ZTdI0zOXp8OOQ3FK_1A\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2307.14995\">paper</a>]，[<a\r\nhref=\"https://github.com/OpenNLPLab/TransnormerLLM\">codel</a>]</p>\r\n<p><strong>【PWC】</strong>【ChatGPT和生成式AI的11大安全趋势】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_RAx3vAx1ykQTJTEEoc37w\">blog</a>]</p>\r\n<p><strong>【人大】</strong>【人大最新大语言模型综述，51页全面回顾大语言模型】[<a\r\nhref=\"https://arxiv.org/pdf/2303.18223.pdf\">paper</a>]</p>\r\n<p><strong>【清华大学】</strong>【张学工教授：AI技术前沿——从ChatGPT到更多突破】[<a\r\nhref=\"https://mp.weixin.qq.com/s/oeZd52BYKU3hhauZZ0eirQ\">blog</a>]</p>\r\n<p><strong>【斯坦福】</strong>【研究大语言模型反映了谁的观点？】[<a\r\nhref=\"https://arxiv.org/pdf/2303.17548.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/tatsu-lab/opinions_qa\">code</a>]</p>\r\n<p><strong>【斯坦福】</strong>【大模型及其公平使用】[<a\r\nhref=\"https://arxiv.org/pdf/2303.15715.pdf\">paper</a>]</p>\r\n<p><strong>【斯坦福】</strong>【构建大模型生态系统图，用于跟踪大模型的足迹】[<a\r\nhref=\"https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=home\">blog</a>]</p>\r\n<p><strong>【斯坦福】</strong>【斯坦福报告：基础模型的机遇与风险】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iEwvkqMT7KEqmnHk8NVz6w\">blog</a>]</p>\r\n<p><strong>【微软】</strong>【一种新的大语言模型NLG评估框架】[<a\r\nhref=\"https://arxiv.org/abs/2303.16634\">paper</a>]</p>\r\n<p><strong>【微软】</strong>【低代码LLM: LLM的可视化编程】[<a\r\nhref=\"https://arxiv.org/abs/2304.08103\">paper</a>]</p>\r\n<p><strong>【微软】</strong>【微软提出LLMA:大型语言模型的无损加速,可以无损地加速带有引用的大型语言模型\r\n(LLM) 推理】[<a\r\nhref=\"https://arxiv.org/pdf/2304.04487.pdf\">paper</a>]</p>\r\n<p><strong>【微软 &amp;\r\nMeta】</strong>【ART：大型语言模型的自动多步骤推理和工具使用】[<a\r\nhref=\"https://arxiv.org/pdf/2303.09014.pdf\">paper</a>]</p>\r\n<p><strong>【EleutherAI&amp;耶鲁大学】</strong>【提出Pythia：\r\n跨越训练和扩展的大型语言模型分析套件】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01373.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/EleutherAI/pythia\">code</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT的底层逻辑】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Rv5htsD2x7TmD-E42RL6Vg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【智慧信息的压缩：模型智能的涌现之道】[<a\r\nhref=\"https://mp.weixin.qq.com/s/hQmvltuMlClBonM6UJmtLg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【拨动大模型的琴弦｜Delta Tuning 成果登上\r\nNature子刊封面！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/m3fNselWKQ2m5XnBe79fQQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大型人工智能模型中出现的不可预测的能力】[<a\r\nhref=\"%5Bhttps://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/%20%5D(https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316)\">blog</a>\r\n)]</p>\r\n<p><strong>【博客】</strong>【为什么现在的大语言模型（LLM）都是Decoder-only的架构？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/ZsHX-M9pisUvG9vqfzdzTQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大型语言模型的涌现能力】[<a\r\nhref=\"https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大型语言模型成本分析】[<a\r\nhref=\"https://hub.baai.ac.cn/view/24047\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【超越ChatGPT：大模型的智能极限 】[<a\r\nhref=\"https://yaofu.notion.site/e1cd16d1fae84f87aeddf872c838e07c\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Nature：AI模型越大越好吗? 】[<a\r\nhref=\"https://www.nature.com/articles/d41586-023-00641-w\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【一场关于ChatGPT话语权的深度思考：人类会在大模型中迷失自我吗？】[<a\r\nhref=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/RPiIh5cbxzXl5uMo_BVFMg\">blog译文</a>]</p>\r\n<p><strong>【博客】</strong>【马斯克强调的TruthGPT 是什么】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_nSYK63DvqE7ZJyJz6NeEA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【对话式AI搜索的技术路线猜想】[<a\r\nhref=\"https://mp.weixin.qq.com/s/AIIu4rRi1WZRQn3oHtuwdg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【AI走过多少路，才迎来了ChatGPT？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/WWc39HtuV-TrbwFybX112Q\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【如何负责任地创建、发布和共享生成式 AI】[<a\r\nhref=\"https://www.technologyreview.com/2023/02/27/1069166/how-to-create-release-and-share-generative-ai-responsibly/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型时代的“Linux”生态，开启人工智能新十年】[<a\r\nhref=\"https://mp.weixin.qq.com/s/sUmA3nSSVfNQFBgSjiSn0g\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【揭秘ChatGPT背后的AI“梦之队”：90后科研“后浪”展示强大创新能力｜智谱研究报告】[<a\r\nhref=\"https://mp.weixin.qq.com/s/sncE01utzu_-r3dLFYU5QA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【In-Context Learning玩法大全 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/sC3Xq1QQmtC8Tz84oRRwcw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【一文理解“上下文学习”----大语言模型突现能力】[<a\r\nhref=\"https://mp.weixin.qq.com/s/0kchPu20nwCKCXk4PZBkOg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【回应吴军老师 |\r\n\"ChatGPT不算新技术革命\"】[<a\r\nhref=\"https://mp.weixin.qq.com/s/dZldwGaYnUcDlB4nUpASMg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Poe向所有开发者推出Poe\r\nAPI，以便广泛获取基于LLM的服务】[<a\r\nhref=\"https://github.com/poe-platform/api-bot-tutorial\">code</a>]</p>\r\n<p><strong>【博客】</strong>【【LLM系列之底座模型对比】LLaMA、Palm、GLM、BLOOM、GPT模型结构对比】[<a\r\nhref=\"https://mp.weixin.qq.com/s/UkifGP2OXxGWeMV7Jm4zWQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型实践总结】[<a\r\nhref=\"https://mp.weixin.qq.com/s/FPweLbvDrCnIzb5PETHMLQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【【LLM系列之GPT】GPT（Generative\r\nPre-trained Transformer）生成式预训练模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1Bpt5MG6mbZCYAXDJmIr3A\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【【LLM系列之Tokenizer】如何科学地训练一个LLM分词器】[<a\r\nhref=\"https://mp.weixin.qq.com/s/4_P2G2Q0YmunQh7DwDas3w\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型词表扩充必备工具SentencePiece】[<a\r\nhref=\"https://mp.weixin.qq.com/s/qQMZ1s7lt-LLkQKx7HIDMw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型知识&amp;推理评估基准】[<a\r\nhref=\"https://mp.weixin.qq.com/s/P0ohd5DpwJOkL8DFVC4qoA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文说清大模型在自动驾驶领域的应用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/5tSwRz-fI4ccLPEn2KrgqA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【一文速览大语言模型在推荐系统中的应用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/RdRLKjzbTWCATmtRMfxW0Q\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【NAACL &amp;\r\nACL：大模型的两种知识继承方案】[<a\r\nhref=\"https://aclanthology.org/2022.naacl-main.288/\">方案一</a>]，[<a\r\nhref=\"https://aclanthology.org/2022.acl-long.151/\">方案二</a>]</p>\r\n<p><strong>【博客】</strong>【a16Z：大模型应用程序的新兴架构】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27506\">中文blog</a>]，[<a\r\nhref=\"https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/\">英文blog</a>]</p>\r\n<p><strong>【论文】</strong>【RetNet：MSRA提出Transformer全新替代大模型基础架构，推理速度8倍提升，内存占用减少70%】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247686895&amp;idx=2&amp;sn=9a2763953d209a29e5d0b03e8b75a912&amp;chksm=e8dead9ddfa9248bea848d16358c5a3eabf11cdd13b5aa96033f3ab2b6dc1ee089bedc73c332&amp;token=1541731120&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2307.08621\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【大模型微调指南：当GPU资源不足时的有效解决方案】[<a\r\nhref=\"https://arxiv.org/pdf/2303.15647.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【<strong>TaskMatrix.AI: Completing Tasks by\r\nConnecting Foundation Models with Millions of APIs</strong> 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16434.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【<strong>AnnoLLM: Making Large Language\r\nModels to Be Better Crowdsourced Annotators</strong> 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16854.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【南加州大学:大语言模型统计偏好的挑战和危险】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03738.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【卡内基·梅隆大学 |\r\n语言生成模型可能造成危害：那么我们能做些什么呢？】[<a\r\nhref=\"https://arxiv.org/pdf/2210.07700.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【鹏程实验室等最新《大规模多模态预训练模型》全面综述】[<a\r\nhref=\"https://arxiv.org/abs/2302.10035\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【预训练基础模型综合调研：从 BERT 到 ChatGPT\r\n的历史 】[<a href=\"https://arxiv.org/abs/2302.09419\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【洛桑联邦理工学院提出REFINER框架，用于微调大规模语言模型】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01904.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【LLM-Adapters：\r\n用于大型语言模型的参数高效微调的适配器系列】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01933.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【大型语言模型的涌现记忆和可预测记忆】[<a\r\nhref=\"https://arxiv.org/abs/2304.11158\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【机器心理学：使用心理学方法研究大型语言模型中的涌现能力和行为】[<a\r\nhref=\"https://arxiv.org/abs/2303.13988v1\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Chameleon：使用大型语言模型进行即插即用的组合推理】[<a\r\nhref=\"https://arxiv.org/abs/2304.09842\">paper</a>]</p>\r\n<p><strong>【代码】</strong>【大型语言模型相关文献资源列表】[<a\r\nhref=\"https://github.com/RUCAIBox/LLMSurvey\">code</a>]</p>\r\n<h2 id=\"llm数据集\">LLM数据集</h2>\r\n<p>【<strong>COIG-PC</strong>】【智源研究院发布国内首个大规模、可商用中文开源指令数据集COIG：最大规模中文多任务指令集，上新千个中文数据集】[<a\r\nhref=\"https://mp.weixin.qq.com/s/PvJa8dPHk6aGEv1G1B3PUw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2304.07987.pdf\">paper</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/BAAI/COIG-PC\">COIG-PC数据下载地址</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/BAAI/COIG\">COIG数据下载地址</a>]</p>\r\n<p>【<strong>Instruct/Prompt\r\nTuning可用数据</strong>】【总结当前开源可用的Instruct/Prompt\r\nTuning数据】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vDbTJo3F7sy3-NY8xxg8jw\">blog</a>]</p>\r\n<p>【<strong>MiniGPT-4</strong>】【GPT-4平替版：MiniGPT-4，支持图像理解和对话，现已开源】[<a\r\nhref=\"https://drive.google.com/file/d/1nJXhoEcy3KTExr17I7BXqY5Y9Lx_-n-9/view\">dataset</a>]</p>\r\n<p>【<strong>Multimodal\r\nC4</strong>】【多模态C4：一个开放的、10亿规模的、与文本交错的图像语料库】[<a\r\nhref=\"https://arxiv.org/abs/2304.06939\">paper</a>]，[<a\r\nhref=\"https://github.com/allenai/mmc4\">code</a>]</p>\r\n<p>【<strong>Mind2Web</strong>】【Mind2Web:\r\n首个全面衡量大模型上网能力的数据集】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vge4CJbBfLXFIYYyNC12Hw\">blog</a>]</p>\r\n<p>【<strong>OpenAssistant\r\nConversations</strong>】【该数据集是一个由人工生成、人工注释的助理式对话语料库，覆盖了广泛的主题和写作风格，由\r\n161443 条消息组成，分布在 66497 个会话树中，使用 35\r\n种不同的语言。该语料库是全球众包工作的产物，涉及超过 13500\r\n名志愿者。为了证明 OpenAssistant Conversations\r\n数据集的有效性，该研究还提出了一个基于聊天的助手\r\nOpenAssistant，其可以理解任务、与第三方系统交互、动态检索信息。】[<a\r\nhref=\"https://huggingface.co/datasets/OpenAssistant/oasst1\">dataset</a>]，[<a\r\nhref=\"https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view\">paper</a>]，[<a\r\nhref=\"https://github.com/LAION-AI/Open-Assistant\">code</a>]</p>\r\n<p>【<strong>Panda LLM</strong>】【为了让Panda\r\nLLM在中文数据集上获得强大的性能，作者使用了强大的指令微调instruction-tuning技术，将LLaMA基础模型在五个开源的中文数据集进行混合训练，其中包括来自各种语言领域的1530万个样本，例如维基百科语料，新闻语料，百科问答语料，社区问答语料，和翻译语料。】[<a\r\nhref=\"https://mp.weixin.qq.com/s/IsWSPAvwgT263wjO7TYTZQ\">blog</a>]</p>\r\n<p>【<strong>RedPajama</strong>】【RedPajama开源项目｜复制超过1.2万亿个令牌的LLaMA训练数据集】[<a\r\nhref=\"https://www.together.xyz/blog/redpajama\">原始blog</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25485\">中文blog</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T\">dataset</a>]，[<a\r\nhref=\"https://github.com/togethercomputer/RedPajama-Data\">code</a>]</p>\r\n<h2 id=\"prompt工程\">Prompt工程</h2>\r\n<p><strong>【博客】</strong>【OpenAI 应用人工智能研究负责人Lilian\r\nWeng新博文：关于提示工程的介绍】[<a\r\nhref=\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Prompt Engineering全面自动化】[<a\r\nhref=\"https://mp.weixin.qq.com/s/aj8Ls463jpF92ssn6Acwzg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT提示示例集合】[<a\r\nhref=\"https://prompts.chat\">地址</a>]，[<a\r\nhref=\"https://github.com/f/awesome-chatgpt-prompts/\">code</a>]，<a\r\nhref=\"https://huggingface.co/datasets/fka/awesome-chatgpt-prompts\">huggingface</a>]</p>\r\n<p><strong>【博客】</strong>【深入浅出Prompt Learning要旨及常用方法】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Wgj1ATMAkL1Gx4dsAlkJZw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT火爆，最全prompt工程指南登GitHub热榜，标星4.7k！】[<a\r\nhref=\"https://github.com/dair-ai/Prompt-Engineering-Guide\">code</a>]，<a\r\nhref=\"https://www.youtube.com/watch?v=dOxUroR57xs\">youtube</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT Prompt工程：设计、实践与思考】[<a\r\nhref=\"https://mp.weixin.qq.com/s/a8hjzZ_Rzl6pOU1PRAARJQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【全面的提示工程指南】[<a\r\nhref=\"https://www.promptingguide.ai/zh\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【指令学习综述｜ChatGPT背后的指令学习是什么】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BK30JkIlshwkdHRjaRCD2g\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2303.10475v2.pdf\">paper</a>]</p>\r\n<p><strong>【博客】</strong>【免费教你提示工程，全中文教学】[<a\r\nhref=\"https://www.learnprompt.pro/\">主页</a>]，[<a\r\nhref=\"https://github.com/LearnPrompt/LearnPrompt\">code</a>]</p>\r\n<p><strong>【博客】</strong>【吴恩达Prompt课程笔记】[<a\r\nhref=\"https://islinxu.github.io/prompt-engineering-note/\">主页</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT使用进阶，Prompt工程】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Uy_wX6DsASBDU2f_6qAy-Q\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【面向大型语言模型的<strong>提升提示集成</strong>】[<a\r\nhref=\"https://arxiv.org/abs/2304.05970\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【DTG：一种简单有效的Prompt方法，激发大模型思考判断能力！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Eio62_Hn0mML3Pfb3G36cA\">blog</a>]</p>\r\n<h2 id=\"agi开源工具博客论文\">AGI开源工具&amp;博客&amp;论文</h2>\r\n<p><strong>【工具】</strong>【Google发布统计深度学习框架平台：OpenXLA】[<a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/AGI/Google_OpenXLA.md\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【AGI的火花一作Sébastien\r\nBubeck演讲万字全文】[<a\r\nhref=\"https://mp.weixin.qq.com/s/H1RVdH0fmwM0GjfV3uvd4g\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【AGI通用智能发展的思考：是否存在足够通用的处理器？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/16TfOu4qfqlbQHpDgDUM2A\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【OpenAGI:当大语言模型遇到领域专家】[<a\r\nhref=\"https://arxiv.org/abs/2304.04370\">paper</a>]，[<a\r\nhref=\"https://github.com/agiresearch/OpenAGI\">code</a>]</p>\r\n<h2 id=\"文本生成\">文本生成</h2>\r\n<h3 id=\"chatgpt\">ChatGPT</h3>\r\n<p>从GPT3到ChatGPT模型的发展路线图</p>\r\n<figure>\r\n<img src=\"images/chatgpt-3.jpg\" alt=\"ChatGPT_family\" />\r\n<figcaption aria-hidden=\"true\">ChatGPT_family</figcaption>\r\n</figure>\r\n<h4 id=\"chatgpt-应用篇\">ChatGPT 应用篇</h4>\r\n<p><strong>【58】</strong>【从 GPT 到 ChatGPT 的演进与应用思考】[<a\r\nhref=\"https://mp.weixin.qq.com/s/3Pr82xKpZ7mAWQcxPPB1xA\">blog</a>]</p>\r\n<p><strong>【MIT &amp; 哈佛大学 】</strong>【语言模型可以预测公众舆论\r\n】[<a href=\"https://arxiv.org/pdf/2303.16779.pdf\">paper</a>]</p>\r\n<p><strong>【中科院】</strong>【ChatGPT助力芯片，传统\r\nEDA如何演变成智能EDA】[<a\r\nhref=\"https://mp.weixin.qq.com/s/JyveUDEYKLrFolfCFLqhhw\">blog</a>]</p>\r\n<p><strong>【微软】</strong>【《ChatGPT机器人:设计原则和模型能力》论文\r\n】[<a\r\nhref=\"https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/\">paper</a>]</p>\r\n<p><strong>【微软】</strong>【各种环境下的ChatGPT赋能长步机器人控制：\r\n一个案例的应用 】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03893.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts\">code</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT获得了「Wolfram」超能力】[<a\r\nhref=\"https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【OpenAI开发Plugin将 ChatGPT\r\n连接到互联网】[<a\r\nhref=\"https://techcrunch.com/2023/03/23/openai-connects-chatgpt-to-the-internet/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatAug：利用ChatGPT进行文本数据增强】[<a\r\nhref=\"https://arxiv.org/abs/2302.13007\">paper</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT 是数据隐私的另一个障碍吗】[<a\r\nhref=\"https://www.bizcommunity.com/Article/196/639/236418.html\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【基于ChatGPT的数据增强方法：ChatAug和AugGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486140&amp;idx=1&amp;sn=bba4342966c99559938824f2d747d231&amp;chksm=ced54958f9a2c04ec121b8c198d69a5a17c8b3e0a96a0cfcd8d1271bd6097a2cbf66895dd8a9&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Character.AI\r\n在ChatGPT基础上加入个性化、UGC两大武器，有比 ChatGPT\r\n更丰富的使用场景】[<a\r\nhref=\"https://mp.weixin.qq.com/s/U4R8loz1G9PYM_l6IvNF_A\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【让ChatGPT可以<strong>语音交互</strong>】[<a\r\nhref=\"https://mp.weixin.qq.com/s/H4XLCQ-kR7T28yywHJL4uA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【“ChatGPT们”的淘金时代】[<a\r\nhref=\"https://mp.weixin.qq.com/s/otdenJh5FJsCgi5ONy9JIQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【70 款 ChatGPT 插件评测（含样例分析）】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vHwAk63ukRteF1u1myrTlA\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【人大提出WebBrain：NLP新任务，通过网络数据的挖掘生成真实文章】[<a\r\nhref=\"https://arxiv.org/abs/2304.04358\">paper</a>]，[<a\r\nhref=\"https://github.com/qhjqhj00/WebBrain\">code</a>]</p>\r\n<p><strong>【医疗】</strong>【ChatGPT爆火带来思考：医学界或将迎来与AI融合的奇点？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/x8ppg6GVCAeLNpv5uJ7B7g\">blog</a>]</p>\r\n<p><strong>【教育】</strong>【论ChatGPT大语言模型在教育中的机遇与挑战\r\n】[<a\r\nhref=\"https://url39.ctfile.com/f/2501739-809898048-6394c7?p=2096\">blog</a>]</p>\r\n<p><strong>【投资】</strong>【ChatGPT在投资研究领域的应用初探及原理分析】[<a\r\nhref=\"https://mp.weixin.qq.com/s/LFPeSLeEOTb1-2YJBXclbQ\">blog</a>]</p>\r\n<p><strong>【软件】</strong>【OpenAI总裁Greg\r\nBrockman转发｜一种编译语言的调试器，利用ChatGPT旨在增强您使用GDB进行调试体验】[<a\r\nhref=\"https://github.com/pgosar/ChatGDB\">code</a>]</p>\r\n<p><strong>【软件】</strong>【不必排队等 OpenAI Plugins，OpenBMB\r\n开源大模型工具学习引擎】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25189\">blog</a>]</p>\r\n<p><strong>【其他】</strong>【分析了ChatGPT技术以及落地应用场景 】[<a\r\nhref=\"https://url39.ctfile.com/f/2501739-805099789-098b62?p=2096\">blog</a>]</p>\r\n<h4 id=\"chatgpt-工具篇\">ChatGPT 工具篇</h4>\r\n<p><strong>【工具】</strong>【ChatGPT 应用汇总及操作手册】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485794&amp;idx=1&amp;sn=6aa0500e3139b67246dd5f96007d1487&amp;chksm=ced54a86f9a2c390d86856181f1fcd09091cf84d67e81535b6d592617f49fe24349779cfa1e5&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【工具】</strong>【ChatGPT提示和技巧速查手册】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485766&amp;idx=1&amp;sn=43ad627e4e183d7a108c3c57ab0e02dc&amp;chksm=ced54aa2f9a2c3b4a2d529e4ed7c2acc7fa32e7465837045d3ec607701e0da2a55c0c557cad2&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【工具】</strong>【非常全面的ChatGPT、LLM相关资源整理分享】[<a\r\nhref=\"https://github.com/cedrickchee/chatgpt-universe\">code</a>]</p>\r\n<p><strong>【工具】</strong>【ChatGPT超全面课程】[<a\r\nhref=\"https://tested-salto-cab.notion.site/The-Ultimate-Chat-GPT-Course-69ed24a317a942d288e740419b1ad6f6\">blog</a>]</p>\r\n<p><strong>【工具】</strong>【BloombergGPT: A Large Language Model for\r\nFinance】[<a\r\nhref=\"https://papers.labml.ai/api/v1/redirect/pdf?paper_key=b0e4b03ecf5c11edb95839eec3084ddd\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【ChatPDF：一键上传PDF文件即可解读 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/S1DUJrNK5_H5krvHotOwHQ\">blog</a>]，[<a\r\nhref=\"https://www.chatpdf.com/\">试用地址</a>]</p>\r\n<p><strong>【工具】</strong>【ChatWeb：可爬取网页正文，并根据正文回答问题\r\n】[<a href=\"https://github.com/SkywalkerDarren/chatWeb\">code</a>]</p>\r\n<p><strong>【工具】</strong>【chatgpt_academic：中科院基于 ChatGPT\r\n专属定制的学术研究及日常开发工具】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25298\">blog</a>]，[<a\r\nhref=\"https://github.com/binary-husky/chatgpt_academic\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/qingxu98/gpt-academic\">demo</a>]</p>\r\n<p><strong>【工具】</strong>【Einstein GPT：SaaS 行业巨头 Salesforce\r\n宣布与 OpenAI 合作，推出 Einstein\r\nGPT，这是全球首个用于客户关系管理（CRM）的生成式 AI 产品 】[<a\r\nhref=\"https://www.salesforce.com/products/einstein/overview/?d=cta-body-promo-8\">Einstein\r\nGPT地址</a>]，[<a\r\nhref=\"https://openai.com/waitlist/slack\">试用地址</a>]</p>\r\n<p><strong>【工具】</strong>【HuggingGPT: Solving AI Tasks with ChatGPT\r\nand its Friends in HuggingFace 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.17580.pdf\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【ImpressionGPT：\r\n利用ChatGPT对放射科报告进行总结的迭代优化框架】[<a\r\nhref=\"https://arxiv.org/abs/2304.08448\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【OpenGpt：创建ChatGPT小应用的AI平台】[<a\r\nhref=\"https://open-gpt.app/\">官网</a>]，[<a\r\nhref=\"https://github.com/futantan/OpenGpt\">code</a>]</p>\r\n<p><strong>【工具】</strong>【TagGPT：腾讯提出零样本多模态标签的大语言模型TagGPT】[<a\r\nhref=\"https://arxiv.org/abs/2304.03022\">paper</a>]，[<a\r\nhref=\"https://github.com/TencentARC/TagGPT\">code</a>]</p>\r\n<p><strong>【工具】</strong>【Visual ChatGPT:\r\n在视觉模型加持下的ChatGPT，聊天生图全拿捏了。】[<a\r\nhref=\"https://arxiv.org/pdf/2303.04671.pdf\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【NetGPT：用于网络流量的生成预训练Transformer模型】[<a\r\nhref=\"https://arxiv.org/pdf/2304.09513.pdf\">paper</a>]</p>\r\n<h4 id=\"chatgpt-技术篇\">ChatGPT 技术篇</h4>\r\n<p><strong>【符尧】</strong>【深度拆解GPT-3.5能力起源】[<a\r\nhref=\"https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756\">原文blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/ckd6KxeTfdQas_UCsJ7HgQ\">译文blog</a>]</p>\r\n<p><strong>【知乎】</strong>【ChatGPT发展历程、原理、技术架构详解和产业未来】[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/590655677\">blog</a>]</p>\r\n<p><strong>【斯坦福】</strong>【82页PPT ！最新ChatGPT: 提示学习,\r\n指导微调和RLHF 】[<a\r\nhref=\"https://pan.baidu.com/s/15Bs1u7z1RhCdfiR3oJ_gJQ\">blog</a>]，[提取码:chat]</p>\r\n<p><strong>【微软】</strong>【让天下没有难训练的大模型，微软亚洲研究院开源TorchScale\r\n】[<a href=\"https://github.com/microsoft/torchscale\">code</a>]</p>\r\n<p><strong>【亚马逊 】</strong>【他们提出了包含视觉特征的\r\nMultimodal-CoT，该架构在参数量小于 10 亿的情况下，在 ScienceQA\r\n基准测试中，比 GPT-3.5 高出 16 个百分点 】[<a\r\nhref=\"https://arxiv.org/abs/2302.00923\">paper</a>]，[<a\r\nhref=\"https://github.com/amazon-science/mm-cot\">code</a>]</p>\r\n<p><strong>【OpenBMB】</strong>【Nature ：生成式 AI 的前景与风险】[<a\r\nhref=\"https://mp.weixin.qq.com/s/d6t2xpdvSDCHzO2gG1N6eQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文解读：从Transformer到ChatGPT，通用人工智能曙光初现】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iZyKmWgXUkPv3Phyaw4Ppg\">blog</a>]</p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Inference_Cost.md\">ChatGPT_Inference_Cost</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Official_API_Learning.md\">ChatGPT_Official_API_Learning</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Parameter_is_not_175B.md\">ChatGPT_Parameter_is_not_175B</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Road_Map_from_yao.fu.md\">ChatGPT_Road_Map_from_yao.fu</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/Lessons_Learned_from_ChatGPT_Recurrence.md\">Lessons_Learned_from_ChatGPT_Recurrence</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/LLM_Pre-training_Guide（Bloom-175B）.md\">LLM_Pre-training_Guide（Bloom-175B）</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/The_guide_of_training_LLM.md\">The_guide_of_training_LLM</a></p>\r\n<p><strong>【博客】</strong>【AI芯片制造商Cerebras发布7个基于GPT的大语言模型，现已开源】[<a\r\nhref=\"https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/\">官网地址</a>\r\n)]，[<a href=\"https://www.cerebras.net/cerebras-gpt\">GPT地址</a>]，[<a\r\nhref=\"https://huggingface.co/cerebras\">Hugging Face地址</a>]</p>\r\n<p><strong>【博客】</strong>【大模型论文周报丨GPT-4发布，谷歌开放PaLM\r\nAPI，斯坦福7B开源模型Alpaca媲美GPT-3.5】[<a\r\nhref=\"https://mp.weixin.qq.com/s/C6g_H6xfFn59IxnLpbjA1g\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【LLaMA模型Meta版泄露，GitHub获8K星】[<a\r\nhref=\"https://mp.weixin.qq.com/s/2M19WSq2YICo-3t5ibQcig\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT or Grammarly? Evaluating ChatGPT\r\non Grammatical Error Correction Benchmark 】[<a\r\nhref=\"https://arxiv.org/abs/2303.13648\">paper</a>]</p>\r\n<p><strong>【博客】</strong>【打造中国版ChatGPT，国内哪家实力最强】[<a\r\nhref=\"https://mp.weixin.qq.com/s/B-n_qz110HmhSP66NKRCiQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【复旦大学邱锡鹏教授解读ChatGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485810&amp;idx=1&amp;sn=47eb672c688517d6bade2c62c7eae94f&amp;chksm=ced54a96f9a2c380ccacfbb223df52de64f2c410a91e726023a074fc98fb87fcd9f60f5a4957&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文:可能是全网最晚的ChatGPT技术总结\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/LJoxupaKflL793TCwnpyPg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT作为知识库问答系统的问答能力评测\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/xul2-SENnqxV8VehozDKHg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT作者John\r\nShulman：我们成功的秘密武器】[<a\r\nhref=\"https://www.talkrl.com/episodes/john-schulman\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/sDeBYMvAwbJr5_tj7Q20-w\">blog译文</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT 是数据隐私的另一个障碍吗】[<a\r\nhref=\"https://www.bizcommunity.com/Article/196/639/236418.html\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Hugging Face 每周速递: ChatGPT API\r\n怎么用？我们帮你搭好页面了 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/oeXgd78vFV8os2uTGZkFQQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【复旦大学教授肖仰华：ChatGPT\r\n浪潮下，面向大模型如何做数据治理？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/od24PYvFLUJe4NQxjvsbMw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【腾讯在ChatGPT的布局】[<a\r\nhref=\"https://mp.weixin.qq.com/s/rdpGZII3pu3MHr-lFm3GyQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【浅析ChatGPT：历史沿革、应用现状及前景展望】[<a\r\nhref=\"https://mp.weixin.qq.com/s/fQ8DmL_M3QMiFX23Tf0z7w\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT 背后的“功臣”——人类反馈强化学习RLHF\r\n技术详解】[<a\r\nhref=\"https://mp.weixin.qq.com/s/mZdZS9QNda26Ae0OIhRjFA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文解析！复现和使用GPT-3/ChatGPT，你所应该知道的】[<a\r\nhref=\"https://mp.weixin.qq.com/s/ILpbRRNP10Ef1z3lb2CqmA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【想训练ChatGPT？得先弄明白Reward\r\nModel怎么训（附源码） 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1v4Uuc1YAZ9MRr1UWMH9xw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT核心技术：强化学习PPO算法】[<a\r\nhref=\"https://mp.weixin.qq.com/s/z4oc9xQmduKMolWxztdHjA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【解读 ChatGPT\r\n背后的技术重点：RLHF、IFT、CoT、红蓝对抗】[<a\r\nhref=\"https://mp.weixin.qq.com/s/y4ywidZ55BQLgQzJa_Wjbg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【OpenAI ChatGPT Code Interpreter入门】[<a\r\nhref=\"https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting\">blog</a>]</p>\r\n<p><strong>【伦理】</strong>【加拿大魁北克大学教授详述：我们该拿ChatGPT怎么办？】[<a\r\nhref=\"https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【AIGC时代的ChatGPT全面综述】[<a\r\nhref=\"https://arxiv.org/abs/2304.06488\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT is a Knowledgeable but\r\nInexperienced Solver: An Investigation of Commonsense Problem in Large\r\nLanguage Models】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16421.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【GPT-3 和 GPT-3.5 系列模型的全面分析】[<a\r\nhref=\"https://arxiv.org/abs/2303.10420v1\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT Outperforms Crowd-Workers for\r\nText-Annotation Tasks】[<a\r\nhref=\"https://arxiv.org/pdf/2303.15056.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【微软&amp;佐治亚理工学院 |\r\nAdaLoRA：自适应预算分配以实现参数有效的微调】[<a\r\nhref=\"https://arxiv.org/pdf/2303.10512.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/QingruZhang/AdaLoRA\">code</a>]</p>\r\n<p><strong>【论文】</strong>【微软 | 大型语言模型的语境忠实提示法】[<a\r\nhref=\"https://arxiv.org/pdf/2303.11315.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【KAUST |\r\nChatGPT问，BLIP-2回答模型：面向丰富的视觉描述的自动提问】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06594.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/Vision-CAIR/ChatCaptioner\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT真的可以取代知识图谱问答吗？ 】[<a\r\nhref=\"https://arxiv.org/abs/2303.07992\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/cvBVgxCrreic6U6CU-YB-A\">paper翻译</a>]</p>\r\n<p><strong>【论文】</strong>【Meta &amp;\r\n斯坦福大学推出FlexGen：用单个GPU进行大型语言模型的高吞吐量生成性推理】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06865.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/FMInference/FlexGen\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT破圈的「秘密武器」：详解RLHF如何影响人类社会！\r\n】[<a href=\"https://arxiv.org/abs/2303.02891\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/DCFhefWGQS5naYwT3o6neg\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【探讨ChatGPT在对抗攻击和分布外泛化下的鲁棒性】[<a\r\nhref=\"https://arxiv.org/pdf/2302.12095.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/microsoft/robustlearn\">code</a>]</p>\r\n<p><strong>【论文】</strong>【复旦清华联合顶刊发文｜ChatGPT：潜力、前景和局限\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1D62QuxXFDXWwwRXrB-Ivw\">blog</a>]，[<a\r\nhref=\"https://link.springer.com/article/10.1631/FITEE.2300089\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【引导ChatGPT不要输出有害信息】[<a\r\nhref=\"https://arxiv.org/pdf/2302.07459.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Junnan\r\nLi大佬发表最新多模态的杰作BLIP2】[<a\r\nhref=\"https://arxiv.org/abs/2301.12597\">paper</a>]，[<a\r\nhref=\"https://github.com/salesforce/LAVIS/tree/main/projects/blip2\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/xmSy4m7NheY8iComv7grxQ\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【Instruction Tuning：无/少样本学习新范式\r\n】[<a href=\"https://arxiv.org/abs/2109.01652\">paper</a>]，[<a\r\nhref=\"https://github.com/google-research/flan\">code</a>]</p>\r\n<p><strong>【论文】</strong>【GPTScore：一种新的评估语言模型方法】[<a\r\nhref=\"https://arxiv.org/abs/2302.04166\">paper</a>]，[<a\r\nhref=\"https://github.com/jinlanfu/GPTScore\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT内核：InstructGPT，基于反馈指令的PPO强化学习】[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/589747432\">blog</a>]，[<a\r\nhref=\"https://www.bilibili.com/video/BV1hd4y187CR\">B站</a>]</p>\r\n<p><strong>【论文】</strong>【Fine-tune-CoT：小模型也能做推理，完美逆袭大模型\r\n】[<a href=\"https://arxiv.org/pdf/2212.10071.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/itsnamgyu/reasoning-teacher\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT的潜力解锁：自然语言处理中应用、优势、限制和未来方向的全面探索】[<a\r\nhref=\"https://arxiv.org/pdf/2304.02017.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【阿里巴巴&amp;清华大学|大型语言模型在算术任务中的表现如何？】[<a\r\nhref=\"https://arxiv.org/pdf/2304.02015.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/GanjinZero/math401-llm\">code</a>]</p>\r\n<p><strong>【代码】</strong>【本科生60行代码教你手搓GPT大模型 】[<a\r\nhref=\"https://github.com/jaymody/picoGPT/tree/29e78cc52b58ed2c1c483ffea2eb46ff6bdec785\">code</a>]</p>\r\n<h3 id=\"gpt4\">GPT4</h3>\r\n<h4 id=\"gpt4-官方文档\">GPT4 官方文档</h4>\r\n<p><strong>【博客】</strong>【GPT4_System_Card中文翻译】[<a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Official/GPT-4_System_Card_zh.md\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【GPT4_Technical_Report中文翻译】[<a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Official/GPT4_Technical_Report_zh.md\">blog</a>]</p>\r\n<h4 id=\"gpt4-博客篇\">GPT4 博客篇</h4>\r\n<p><strong>【博客】</strong>【【万字长文】GPT-4秘密泄露！所有的信息都在这里！从GPT-4\r\n架构、基础设施、训练数据集、成本、视觉到MoE！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vgUKe31pykC12sUV5xyLNQ\">blog</a>]，[<a\r\nhref=\"https://www.semianalysis.com/p/gpt-4-architecture-infrastructure\">原blog</a>]</p>\r\n<p><strong>【纽约时报】</strong>【GPT-4 令人印象深刻但仍在 10\r\n个方面具有缺陷】[<a\r\nhref=\"https://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html\">blog</a>]</p>\r\n<p><strong>【Open AI】</strong>【多模态大模型GPT-4的新突破】[<a\r\nhref=\"https://hub.baai.ac.cn/view/24852\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【重磅发布GPT-4】[<a\r\nhref=\"https://openai.com/research/gpt-4\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【GPT-4 创造者 Ilya Sutskever 谈 AI 幻觉和\r\nAI 民主】[<a\r\nhref=\"https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/?sh=7743f01e1218\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【GPT-4创造者：第二次改变AI浪潮的方向】[<a\r\nhref=\"https://mp.weixin.qq.com/s/rZBEDlxFVsVXoL5YUVU3XQ\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【当GPT-4进入北京市2022高考考场能有什么表现？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/N_j01KSuEKuVwCCD69G92g\">blog</a>]</p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Blog/GPT4_Technical_Detail.md\">GPT4技术细节</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Blog/GPT4_Technical_Summary.md\">GPT4技术关键点总结</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT_VS_GPT4/GPT4_VS_ChatGPT（from_nytimes）.md\">GPT4和ChatGPT的效果对比</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://doc.clickup.com/37456139/d/h/13q28b-324/e2a22b0c164b1f9\">The\r\nUltimate GPT-4 Guide</a></p>\r\n<h4 id=\"gpt4-论文篇\">GPT4 论文篇</h4>\r\n<p><strong>【微软】</strong>【用GPT-4进行指令调优】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03277.pdf\">paper</a>]，[<a\r\nhref=\"https://instruction-tuning-with-gpt-4.github.io/\">code</a>]</p>\r\n<p><strong>【论文】</strong>【点燃通用人工智能的火花：GPT-4的早期实验】[<a\r\nhref=\"https://arxiv.org/pdf/2303.12712.pdf\">原始paper</a>]，[<a\r\nhref=\"https://event-cdn.baai.ac.cn/file/file-browser/waTXJn85fm3FPyDXpsZ4faGk47trjjYb.pdf\">中文版paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/H1RVdH0fmwM0GjfV3uvd4g\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【GPT4All：用GPT-3.5-Turbo的大规模数据提炼训练一个助理式聊天机器人】[<a\r\nhref=\"https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/nomic-ai/gpt4all\">code</a>]</p>\r\n<p><strong>【论文】</strong>【美国东北大学：可以通过要求GPT4反思“你为什么错了？”来提高30%的性能】[<a\r\nhref=\"https://arxiv.org/abs/2303.11366\">paper</a>]，[<a\r\nhref=\"https://github.com/noahshinn024/reflexion\">code</a>]</p>\r\n<p><strong>【论文】</strong>【对ChatGPT/GPT-4研究的总结以及对大型语言模型未来的展望】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01852.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【评估日本医疗执照考试的GPT-4和ChatGPT】[<a\r\nhref=\"https://arxiv.org/pdf/2303.18027.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Amazon |\r\n深入研究LLMs与AutoGPT的结合：揭示出GPT-4惊人的人类决策能力！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Gbz7ZVVdeTq64mj1-__aQA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2306.02224.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/younghuman/LLMAgent\">code</a>]</p>\r\n<h3 id=\"anima\">Anima</h3>\r\n<p>【33B QLoRA大语言模型Anima的性能超越了对比的所有的中文开源模型。】[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/638058537?utm_source=wechat_session&amp;utm_medium=social&amp;s_r=0\">blog</a>]，[<a\r\nhref=\"https://github.com/lyogavin/Anima\">code</a>]，[<a\r\nhref=\"https://huggingface.co/lyogavin/Anima33B\">model</a>]</p>\r\n<h3 id=\"bard\">Bard</h3>\r\n<p>【谷歌再次开放Bard访问权，向着ChatGPT发起再一次攻击】[<a\r\nhref=\"%5Bhttp://Bard.google.com%5D(http://bard.google.com/)\">报名地址</a>\r\n)]，[<a\r\nhref=\"https://twitter.com/sundarpichai/status/1638180697352593408\">blog</a>]，[<a\r\nhref=\"https://www.theverge.com/23649897/google-Bard-chatbot-search-engine\">theverge</a>]</p>\r\n<h3 id=\"baize\">Baize</h3>\r\n<p>【用ChatGPT训练羊驼：「Baize」开源，轻松构建专属模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zxElGfclNbBwTuDG4Qrxnw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2304.01196\">paper</a>]，[<a\r\nhref=\"https://github.com/project-baize/baize/blob/main/README.md\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/project-baize/baize-lora-7B\">demo</a>]</p>\r\n<h3 id=\"baichuan以及扩展\">baichuan以及扩展</h3>\r\n<p><strong>【baichuan-7b】</strong>【王小川大模型首亮相！70亿参数霸榜，清北抢先用｜独家专访】[<a\r\nhref=\"https://mp.weixin.qq.com/s/qA_E_3dUe1sSOUM87ZgHdQ\">blog</a>]，[<a\r\nhref=\"https://huggingface.co/baichuan-inc/baichuan-7B\">Hugging\r\nFace</a>]，[<a\r\nhref=\"https://github.com/baichuan-inc/baichuan-7B\">code</a>]，[<a\r\nhref=\"https://modelscope.cn/models/baichuan-inc/baichuan-7B/summary\">Model\r\nScope</a>]，[<a\r\nhref=\"https://cevalbenchmark.com/static/leaderboard_zh.html\">C-EVAL</a>]</p>\r\n<p><strong>【firefly-baichuan-7b-qlora-sft】</strong>[使用Firefly项目中的QLoRA训练流程，在moss-003-sft-data百万多轮指令数据上进行了指令微调baichuan-7b模型]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/_eTkDGG5DmxyWeiQ6DIxBw\">blog</a>]，[<a\r\nhref=\"https://huggingface.co/YeungNLP/firefly-baichuan-7b-qlora-sft\">Hugging\r\nFace model</a>]，[<a\r\nhref=\"https://github.com/baichuan-inc/baichuan-7B\">code</a>]，[<a\r\nhref=\"https://modelscope.cn/models/baichuan-inc/baichuan-7B/summary\">Model\r\nScope</a>]，[<a\r\nhref=\"https://cevalbenchmark.com/static/leaderboard_zh.html\">C-EVAL</a>]</p>\r\n<h3 id=\"bloom\">BLOOM</h3>\r\n<p>【【LLM系列之BLOOM】BLOOM: 多语言大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_Vj-KNxS5SfuF_h7bfMb5Q\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2211.05100\">paper</a>]，[<a\r\nhref=\"https://github.com/huggingface/transformers-bloom-inference/tree/main\">code</a>]，[<a\r\nhref=\"https://huggingface.co/bigscience/bloom\">huggingface</a>]</p>\r\n<h3 id=\"biomedgpt\">BiomedGPT</h3>\r\n<p>【BiomedGPT: 统一通用的生物医学生成式预训练Transformer】[<a\r\nhref=\"https://arxiv.org/abs/2305.17100\">paper</a>]</p>\r\n<h3 id=\"claude\">Claude</h3>\r\n<p>【ChatGPT最强竞品Claude今日开放API】[<a\r\nhref=\"https://www.anthropic.com/product\">产品地址</a>]，[<a\r\nhref=\"https://www.anthropic.com/earlyaccess\">申请地址</a>]，[<a\r\nhref=\"https://console.anthropic.com/docs/api\">API说明</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Wx5q-rEwG4sROvnewGxWrw\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Yu551-z14lpiFGSOfXE2Tw\">Claude支持100k上下文</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/27790\">Claude2发布</a>]</p>\r\n<h3 id=\"claude-2\">Claude 2</h3>\r\n<p>【ChatGPT最强竞品Claude2来了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_uIPPJHmiYaBFxtKXdwFbA\">blog</a>]</p>\r\n<h3 id=\"chatglm-6b以及扩展\">ChatGLM-6B以及扩展</h3>\r\n<p>【ChatGLM：千亿基座的对话模型开启内测 ⸺对应单卡版本开源】[<a\r\nhref=\"https://chatglm.cn/blog\">blog</a>]，[<a\r\nhref=\"https://github.com/THUDM/ChatGLM-6B.git\">code</a>]</p>\r\n<p>【chatglm+langchain+互联网，你可以将大模型接入网络了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/lO6SrEuv4-vNbL8B3G-f8g\">blog</a>]，[<a\r\nhref=\"https://github.com/LemonQu-GIT/ChatGLM-6B-Engineering/\">code</a>]</p>\r\n<p><strong>【Chinese-LangChain】</strong>【基于ChatGLM-6b+langchain实现本地化知识库检索与智能答案生成】[<a\r\nhref=\"https://github.com/yanqiangmiffy/Chinese-LangChain\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/xAsZZ_LOkr9Nj-JafSbXnA\">blog</a>]</p>\r\n<p>【ChatGLM_multi_gpu_zero_Tuning：简单高效实现多卡微调大模型】[<a\r\nhref=\"https://github.com/CSHaitao/ChatGLM_mutli_gpu_tuning\">code</a>]</p>\r\n<p>【浅尝prompt咒语设计：one-shot微调chatglm-6b实践信息抽取】[<a\r\nhref=\"https://mp.weixin.qq.com/s/l7lCbdJ9XGzLPTb3zKDAzQ\">blog</a>]</p>\r\n<p>【ChatGLM-6B模型结构组件源码阅读】[<a\r\nhref=\"https://mp.weixin.qq.com/s/r7KEJmrpJZmY7KBP4veS6A\">blog</a>]</p>\r\n<p>【基于1万亿token开源大模型Falcon，超越650亿的LLaMA，可商用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/jbRRjG2ferhFPWsMtCaJyg\">blog1</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Vy_xWBuZU0AaaPMCIhKIyw\">blog2</a>]</p>\r\n<h3 id=\"chatyuan\">ChatYuan</h3>\r\n<p>【ChatYuan：基于PromptCLUE-large的中文对话开源大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485655&amp;idx=1&amp;sn=ad80d8a17d4aaab90b17a79b638c712d&amp;chksm=ced54b33f9a2c225ce292b4e3d5725a668d0bfc9fe0be610c847b31b61714ecf75c06dac1cb5&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<h3 id=\"copilot-x\">Copilot X</h3>\r\n<p>【GitHub Copilot X编辑器发布，大大提升编码速度】[<a\r\nhref=\"https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/\">blog</a>]</p>\r\n<h3 id=\"colossalai\">ColossalAI</h3>\r\n<p>【穷孩子如何体验ColossalAI SFT（Colab篇）】[<a\r\nhref=\"https://mp.weixin.qq.com/s/NS4yySeYd7QUYb7CB9V0lA\">blog</a>]</p>\r\n<h3 id=\"cpm-bee\">CPM-Bee</h3>\r\n<p>【中文基座模型CPM-Bee开源了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BO4cDB9KRSODZw3TvZpUAA\">blog</a>]，[<a\r\nhref=\"https://github.com/OpenBMB/CPM-Bee\">code</a>]，[<a\r\nhref=\"https://huggingface.co/openbmb/cpm-bee-10b\">HuggingFace</a>]</p>\r\n<h3 id=\"chatdb\">ChatDB</h3>\r\n<p>【清华大学和北京智源人工智能研究院的研究者们提出了ChatDB：用数据库作为符号性记忆模块来增强大语言模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/o3j1vNLHlJ6qTea219A4Qw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2306.03901\">paper</a>]，[<a\r\nhref=\"https://chatdatabase.github.io\">主页</a>]，[<a\r\nhref=\"https://github.com/huchenxucs/ChatDB\">code</a>]</p>\r\n<h3 id=\"dolly\">Dolly</h3>\r\n<p>【声称它\r\n\"<strong>像ChatGPT一样神奇</strong>\"，但只需要<strong>使用一台机器</strong>在<strong>不到三个小时的时间里</strong>训练的数据少得多。】[<a\r\nhref=\"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\">blog</a>]，[<a\r\nhref=\"https://www.databricks.com\">Databricks Inc地址</a>]</p>\r\n<h3 id=\"dolly2.0\">Dolly2.0</h3>\r\n<p>【Databricks的dolly-v2-12b，是一个在Databricks机器学习平台上训练的指令跟随型大型语言模型】[<a\r\nhref=\"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\">blog_en</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25434\">blog_zh</a>]</p>\r\n<h3 id=\"deepspeed-chat\">DeepSpeed-Chat</h3>\r\n<p>【DeepSpeed对话：易于使用、快速而实惠的RLHF训练，在各种规模下训练ChatGPT模型】[<a\r\nhref=\"https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat\">code</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25414\">blog</a>]</p>\r\n<h3 id=\"frugalgpt\">FrugalGPT</h3>\r\n<p>【斯坦福提出FrugalGPT｜性能媲美GPT4，成本降低98%】[<a\r\nhref=\"https://arxiv.org/pdf/2305.05176.pdf\">paper</a>]，[<a\r\nhref=\"https://www.reddit.com/r/singularity/comments/13dnfd7/frugalgpt_can_match_the_performance_of_the_best/\">blog</a>]</p>\r\n<h3 id=\"gpt3.5\">GPT3.5</h3>\r\n<p>【GPT3.5试用地址 】[<a\r\nhref=\"https://platform.openai.com/playground\">试用地址</a>]</p>\r\n<h3 id=\"jittorllms\">JittorLLMs</h3>\r\n<p>【笔记本没有显卡也能跑大模型，具有高性能、配置要求低、中文支持好、可移植等特点】[<a\r\nhref=\"https://github.com/Jittor/JittorLLMs\">code</a>]</p>\r\n<h3 id=\"llm-as-controller\">LLM as Controller</h3>\r\n<p>【LLM as Controller—无限拓展LLM的能力边界】[<a\r\nhref=\"https://mp.weixin.qq.com/s/jeb7ugGC6zxsOsfE-w-I0A\">blog</a>]</p>\r\n<h3 id=\"metagpt\">MetaGPT</h3>\r\n<p>【MetaGPT：多角色元编程框架】[<a\r\nhref=\"https://github.com/geekan/MetaGPT\">code</a>]</p>\r\n<h3 id=\"minigpt-4\">MiniGPT-4</h3>\r\n<p>【类似GPT-4图像理解与对话能力的AI大模型，已开源】[<a\r\nhref=\"https://minigpt-4.github.io/\">主页</a>]，[<a\r\nhref=\"https://github.com/Vision-CAIR/MiniGPT-4/blob/main/MiniGPT_4.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/Vision-CAIR/MiniGPT-4\">code</a>]，[<a\r\nhref=\"https://youtu.be/__tftoxpBAw\">video</a>]，[<a\r\nhref=\"https://drive.google.com/file/d/1nJXhoEcy3KTExr17I7BXqY5Y9Lx_-n-9/view\">dataset</a>]，[<a\r\nhref=\"https://6b89c70eb5e14dca33.gradio.live/\">Demo</a>]，[<a\r\nhref=\"https://b2517615b965687635.gradio.live/\">Demo1</a>]，[<a\r\nhref=\"https://c8de8ff74b6a6c6a9b.gradio.live/\">Demo2</a>]，[<a\r\nhref=\"https://0a111504e072685259.gradio.live/\">Demo3</a>]，[<a\r\nhref=\"https://90bc0bac96e6457e8f.gradio.live/\">Demo4</a>]</p>\r\n<h3 id=\"moss\">MOSS</h3>\r\n<p>【FudanNLP团队最新成果，借助RLHF实现人类对齐的MOSS-RLHF来了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BjXtnEEVCQiPOy-_qCNM4g\">blog</a>]，[<a\r\nhref=\"https://openlmlab.github.io/MOSS-RLHF/\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/togethercomputer/OpenChatKit\">测试链接</a>]，[<a\r\nhref=\"https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B\">模型权重</a>]，[<a\r\nhref=\"https://laion.ai/blog/oig-dataset/\">数据集</a>]</p>\r\n<h3 id=\"openchatkit\">OpenChatKit</h3>\r\n<p>【ChatGPT开源平替OpenChatKit：参数量200亿，在4300万条指令上微调而成】[<a\r\nhref=\"https://mp.weixin.qq.com/s/9Av3nhJLrcYAsBW9vVGjTw\">blog</a>]，[<a\r\nhref=\"https://github.com/togethercomputer/OpenChatKit\">code</a>]，[<a\r\nhref=\"https://openlmlab.github.io/MOSS-RLHF/paper/SecretsOfRLHFPart1.pdf\">技术报告</a>]</p>\r\n<h3 id=\"openassistant\">OpenAssistant</h3>\r\n<p>【ChatGPT全球最大开源平替OpenAssistant，基于Pythia和LLaMA微调而来，主要用于训练人类标注的数据，支持35种语言，免费可用RLHF数据】[<a\r\nhref=\"https://open-assistant.io/chat\">官网</a>]，[<a\r\nhref=\"https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view\">paper</a>]，[<a\r\nhref=\"https://github.com/LAION-AI/Open-Assistant\">code</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/OpenAssistant/oasst1\">dataset</a>]，[<a\r\nhref=\"https://youtu.be/ddG2fM9i4Kk\">youtube</a>]</p>\r\n<h3 id=\"webcpm\">WebCPM</h3>\r\n<p>【首个联网支持中文问答开源模型WebCPM】[<a\r\nhref=\"https://arxiv.org/abs/2305.06849\">paper</a>]，[<a\r\nhref=\"https://github.com/thunlp/WebCPM\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/m4zsF2HDFHSKc23Oq0O98w\">blog</a>]</p>\r\n<h3 id=\"llama以及扩展\">LLaMA以及扩展</h3>\r\n<p><strong>【LLaMA】</strong>【Meta开放小模型LLaMA，性能超过GPT-3】[<a\r\nhref=\"https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/\">paper</a>]，[<a\r\nhref=\"https://github.com/facebookresearch/llama\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485822&amp;idx=1&amp;sn=b365d93a0a08769aef77f34069da1422&amp;chksm=ced54a9af9a2c38cd5779284b5e9ae573846153e7dc00961dc163664a657d6a3fa5c8c14c7d2&amp;token=447941009&amp;lang=zh_CN#rd\">blog1</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/fGNuTcYE8QI9_JKS9LcQ7w\">blog2</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/B9Ue0ihUGAFjT_X__R2u8Q\">详聊LLaMA大模型的技术细节</a>]</p>\r\n<p><strong>【LLaMA 2】【LLaMA 2技术细节详细介绍！】</strong>[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486800&amp;idx=1&amp;sn=9b629ca41b9f6b4feedad94363a17253&amp;chksm=ced54eb4f9a2c7a2a5b20c182981b4323b18509f2ca8f482c2a8cdbb29bf570488bdcd280eb6&amp;token=882149695&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/UnzhBJjZfPXsaSu8gNnosw\">在 Hugging Face\r\n上玩转LLaMA 2</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Mee7sMq_bxLpIOOr91li9A\">伯克利AI博士详解Llama\r\n2的技术细节</a>]，[<a\r\nhref=\"https://github.com/michael-wzhu/Chinese-LlaMA2\">Chinese-LlaMA2</a>]</p>\r\n<p><strong>【llama2.c】</strong>【OpenAI联创Karpathy爱上羊驼：纯C代码实现婴儿Llama2，MacBook可运行，已揽1.6k星】[<a\r\nhref=\"https://mp.weixin.qq.com/s/VVR6N1duJM5vAU5cY9FrDQ\">blog</a>]，[<a\r\nhref=\"https://github.com/karpathy/llama2.c\">code</a>]</p>\r\n<p><strong>【LLaMA评测】</strong>[<a\r\nhref=\"https://mp.weixin.qq.com/s/kImwfWWtXMmEDVOhJZ4dJg\">blog</a>]</p>\r\n<p><strong>【Alpaca】</strong>【斯坦福发布了一个由LLaMA\r\n7B微调的模型Alpaca（羊驼），训练3小时，性能比肩GPT-3.5】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485890&amp;idx=1&amp;sn=2d1414fc3751353c31b946b3e954a465&amp;chksm=ced54a26f9a2c330082e8c0014c96a6d9bef62e3581875031f203268a11fad09645a75b482b0&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://crfm.stanford.edu/2023/03/13/alpaca.html\">官网</a>]，[<a\r\nhref=\"https://crfm.stanford.edu/alpaca\">model</a>]，[<a\r\nhref=\"https://github.com/tatsu-lab/stanford_alpaca\">code</a>]</p>\r\n<p><strong>【Alpaca-CoT】</strong>【Alpaca-CoT：多接口统一的轻量级LLM指令微调平台】[<a\r\nhref=\"https://github.com/PhoebusSi/Alpaca-CoT\">code</a>]，[<a\r\nhref=\"https://sota.jiqizhixin.com/project/alpaca-cot\">官网</a>]</p>\r\n<p><strong>【BiLLa】</strong>【BiLLa 是开源的推理能力增强的中英双语\r\nLLaMA 模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/8KDpDC6Fkb_61gFfkcT8TQ\">blog</a>]，[<a\r\nhref=\"https://github.com/Neutralzz/BiLLa\">code</a>]</p>\r\n<p><strong>【CaMA】</strong>【一种支持中英语言的LLaMA模型】[<a\r\nhref=\"https://github.com/zjunlp/CaMA\">code</a>]</p>\r\n<p><strong>【ChatLLaMA】</strong>【初创公司 Nebuly\r\nAI在LLaMA基础上加入RLHF 开源 ChatLLaMA 训练方法】[<a\r\nhref=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama\">code</a>]</p>\r\n<p><strong>【ColossalAI】</strong>【完整复现ChatGPT全流程】[<a\r\nhref=\"https://github.com/hpcaitech/ColossalAI\">code</a>]</p>\r\n<p><strong>【ColossalChat】</strong>【用于克隆 ChatGPT 和完整 RLHF\r\n管道的开源解决方案】[<a\r\nhref=\"https://github.com/hpcaitech/ColossalAI\">code</a>]，[<a\r\nhref=\"https://syncedreview.com/2023/03/29/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline/\">blog</a>]</p>\r\n<p><strong>【CAMEL】</strong>【从LLaMA衍生并适应临床的模型】[<a\r\nhref=\"https://github.com/starmpcc/CAMEL\">code</a>]，[<a\r\nhref=\"https://starmpcc.github.io/CAMEL/\">blog</a>]</p>\r\n<p><strong>【草本（原华驼）】</strong>【让LLaMA模型成为中医专家】[<a\r\nhref=\"https://arxiv.org/pdf/2304.06975v1.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/TYpc_63qDlR6MwscxCKKhA\">blog1</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/iuQANmwCS7AXQRik7HwQPg\">blog2</a>]</p>\r\n<p><strong>【DB-GPT】</strong>【基于vicuna-13b和FastChat的开源实验项目】[<a\r\nhref=\"https://github.com/csunny/DB-GPT\">code</a>]</p>\r\n<p><strong>【DeepSpeed-Chat】</strong>【最强ChatGPT训练框架，一键完成RLHF训练！\r\n】[<a\r\nhref=\"https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/kVEBUF20u4SUsHelF39o8Q\">blog</a>]</p>\r\n<p><strong>【ExpertLLaMA】</strong>【一个使用ExpertPrompting构建的开源聊天机器人，其能力达到ChatGPT的96%。】[<a\r\nhref=\"https://github.com/OFA-Sys/ExpertLLaMA\">code</a>]</p>\r\n<p><strong>【FreedomGPT】</strong>【FreedomGPT使用Electron 和\r\nReact构建，它是一个桌面应用程序，允许用户在他们的本地机器上运行LLaMA。】[<a\r\nhref=\"https://freedomgpt.com/\">官网地址</a>]</p>\r\n<p><strong>【FLAN】</strong>【【LLM系列之FLAN】Scaling\r\nInstruction-Finetuned Language Models】[<a\r\nhref=\"https://mp.weixin.qq.com/s/5jEJH6UBHrk_ILbrLsd6TQ\">blog</a>]</p>\r\n<p><strong>【GoGPT/GoGPT2】</strong>【基于Llama/Llama\r\n2训练的底座大模型,再扩充词表+继续预训练】[<a\r\nhref=\"https://github.com/yanqiangmiffy/GoGPT\">GoGPT code</a>]，[<a\r\nhref=\"https://huggingface.co/golaxy/gogpt2-7b\">GoGPT2 code</a>]</p>\r\n<p><strong>【Koala】</strong>【加州大学BAIR团队提出Koala：学术研究的对话模型】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25284\">blog_zh</a>]，[<a\r\nhref=\"https://bair.berkeley.edu/blog/2023/04/03/koala/\">blog_en</a>]</p>\r\n<p><strong>【LLaMA-Adapter】</strong>【<strong>LLaMA-Adapter</strong>，一种用于微调指令遵循<a\r\nhref=\"https://github.com/facebookresearch/llama\">LLaMA</a>模型的轻量级自适应方法，使用<a\r\nhref=\"https://github.com/tatsu-lab/stanford_alpaca\">Stanford\r\nAlpaca</a>提供的 52K 数据。】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16199.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/ZrrSkywalker/LLaMA-Adapter\">code</a>]</p>\r\n<p><strong>【LaVIN】</strong>【MMA方案让羊驼模型实现多模态：训练时间减少71.4%，成本节省99.9%】[<a\r\nhref=\"https://arxiv.org/pdf/2305.15023.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/luogen1996/LaVIN\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/MRLYk1b7VJ_b6OmJ9mzkdw\">blog</a>]</p>\r\n<p><strong>【lit-llama】</strong>【基于nanoGPT的LLaMA语言模型，支持量化、LoRA微调和预训练】[<a\r\nhref=\"https://github.com/Lightning-AI/lit-llama\">code</a>]</p>\r\n<p><strong>【LlamaIndex】</strong>【面向QA 系统的全新文档摘要索引】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1zvXlcGfVdxU8_Pj5f2E1g\">blog</a>]</p>\r\n<p><strong>【llama.cpp】</strong>【量化130亿参数LLaMA模型的llama.cpp，推理仅需4GB内存】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485875&amp;idx=1&amp;sn=a4e09d31802c087f1f47bd292e380c19&amp;chksm=ced54a57f9a2c341935b81aa27824dfa740beb7ce33289e0cb5190b5910040c0904371b7e8a0&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【llama.cpp优化版】</strong>【Edge AI 变得更快|在 C/C++\r\n中移植 Facebook 的 LLaMA 模型】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25307\">blog</a>]</p>\r\n<p><strong>【LIMA】</strong>【使用 LoRA 技术对 LLaMA 65B\r\n大模型进行微调及推理】[<a\r\nhref=\"https://mp.weixin.qq.com/s?search_click_id=7213828026277652651-1688375605291-1083947599&amp;__biz=MjM5ODExNDA2MA==&amp;mid=2449961473&amp;idx=2&amp;sn=f080fa7b1b5657db9872724caee56519&amp;chksm=b13c7462864bfd741f0f061b87187f2cde36b68020cfe3402717a6858563311cb642eb340989&amp;rd2werd=1&amp;key=ea1d916ce49bb536ce48f3aba8e329d1e1aa6fdcda4f73580b0a5adbd624721e6a974570fd6ef2823ecfa6c95e2dc09179b51e440e9179f79d0ba01f62cf795d6c697f95bf05a28904f4172b11e1ce873a2d7a0e85c74d509e916176aacb43657fd11a6de7611d65bd4ae82315835aa138a423887a219f2971c6a525679fd805&amp;ascene=65&amp;uin=MTkwNzA5OTA4Mw%3D%3D&amp;devicetype=iMac+MacBookPro13%2C2+OSX+OSX+12.6.7+build(21G651)&amp;version=13080109&amp;nettype=WIFI&amp;lang=zh_CN&amp;countrycode=CN&amp;fontScale=100&amp;exportkey=n_ChQIAhIQ0Z339%2BFUk%2Bp0YpfMQjB%2BhxKDAgIE97dBBAEAAAAAANJyNCKr%2F3UAAAAOpnltbLcz9gKNyK89dVj0q5AacL9r2sPbvlDuJo6SwYSJ2wbfYGvc3EDxuk%2BMQS0vl8RLluMN%2Fuh9u2LxBZTHTiuQct62Bjib68qd1EvB8CgGKMV34B5%2BKHCutInPzdE9Uac6dxp0VYtd%2BJnEwljL8jf7mWZdwTkPdEZl1P0OEb3HFzczXelqDR3h7D2xEVmQuFHGIeVi7iPOHMT0AWhhGLdbrVhCKbPT3%2BX9FPOLjJSql2UD95dTmSzZKqdvOIMGpD5t%2F98jDuMUojr9HUMdvljQ1XkiJVnd%2FbqSsLS3S5t7E%2Ftjmjb9g7IxWkY%3D&amp;acctmode=0&amp;pass_ticket=mJ3t3nBN%2BXhKCYp9bzJSkTl%2B9PwobzvYen%2F5Kv4kpcj1Lig98d0DXbcAyqBW0vaB&amp;wx_header=0\">blog</a>]</p>\r\n<p><strong>【PaLM】</strong>【【LLM系列之PaLM】PaLM: Scaling Language\r\nModeling with Pathways】[<a\r\nhref=\"https://mp.weixin.qq.com/s/MT1xCsJp98BM-lkuOKJF-A\">blog</a>]</p>\r\n<p><strong>【StackLLaMA】</strong>【使用 RLHF 训练 LLaMA 的实践指南】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25341\">blog_zh</a>]，[<a\r\nhref=\"https://huggingface.co/blog/stackllama\">blog_en</a>]</p>\r\n<p><strong>【Vicuna】</strong>【通过对从ShareGPT收集的用户共享对话进行微调的LLaMA训练，Vicuna-13B达到了OpenAI\r\nChatGPT和Google Bard 90%*以上的质量 】[<a\r\nhref=\"https://vicuna.lmsys.org/\">Vicuna官网地址</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25328\">blog</a>]</p>\r\n<h2 id=\"图像视频生成\">图像、视频生成</h2>\r\n<p><strong>【博客】</strong>【Genmo\r\nChat】【这是一款创造性的copilot，使用GPT-4和一大套生成人工智能工具创建并编辑您需要的任何视频或图像。\r\n】[<a href=\"https://www.genmo.ai/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【BlenderGPT】【<strong>一款基于GPT-4的扩展程序BlenderGPT开源，这是一个由GPT3/4驱动的全能AI编辑助手，为Blender提供支持</strong>\r\n】[<a href=\"https://github.com/gd3kr/BlenderGPT\">code</a>]</p>\r\n<p><strong>【博客】</strong>【Firefly】【Adobe制造了一个人工智能图像生成器--并表示它没有窃取艺术家的作品来做这件事\r\n】[<a\r\nhref=\"https://www.theverge.com/2023/3/21/23648315/adobe-firefly-ai-image-generator-announced\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Bing Image Creator】【微软推出Bing Image\r\nCreator，用户可根据文本提示创建图片】[<a\r\nhref=\"https://techcrunch.com/2023/03/21/microsoft-brings-openais-dall-e-image-creator-to-the-new-bing/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Hugging Face\r\n现已支持使用达摩院text-to-video模型从文本生成视频】[<a\r\nhref=\"https://modelscope.cn/models/damo/text-to-video-synthesis/summary\">模型地址</a>]</p>\r\n<p><strong>【论文】</strong>【最新女娲大模型，中科院提出NUWA-XL：扩散模型中的扩散，生成超长视频】[<a\r\nhref=\"https://arxiv.org/pdf/2303.12346.pdf\">paper</a>]，[<a\r\nhref=\"https://msra-nuwa.azurewebsites.net/#/\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【艾伦AI研究院 &amp; 华盛顿大学 |\r\nCHAMPAGNE：从大规模的网络视频中学习真实世界的对话】[<a\r\nhref=\"https://arxiv.org/pdf/2303.09713.pdf\">paper</a>]，[<a\r\nhref=\"https://seungjuhan.me/champagne\">code</a>]</p>\r\n<p><strong>【论文】</strong>【用AI直接复现你在想什么，Stable\r\nDiffusion逼真复现图像】[<a\r\nhref=\"https://sites.google.com/view/stablediffusion-with-brain/\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/gIwj2eqNph8jHWOhYYEXIg\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【Stable\r\nDiffusion公司新作Gen-1：基于扩散模型的视频合成新模型，加特效杠杠的！】[<a\r\nhref=\"https://arxiv.org/pdf/2302.03011\">paper</a>]，[<a\r\nhref=\"https://research.runwayml.com/gen1\">site</a>]</p>\r\n<p><strong>【论文】</strong>【使用Diffusers 实现 ControlNet\r\n高速推理】[<a\r\nhref=\"https://mp.weixin.qq.com/s/k8rE9GrF97E-0TKJhih9kw\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【文生图引入ControlNet，深度、边缘信息全能复用\r\n】[<a href=\"https://arxiv.org/pdf/2302.05543.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/lllyasviel/ControlNet\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT｜可用于AI绘画，效果飞升47% 】[<a\r\nhref=\"https://arxiv.org/abs/2302.12192\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【智源研究院提出SegGPT：\r\n一个用于分割上下文中所有事物的通用模型】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03284.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【OpenAI开源新模型代码库Consistency\r\nModels，无需对抗训练即可快速获得高质量样本】[<a\r\nhref=\"https://arxiv.org/abs/2303.01469\">paper</a>]，[<a\r\nhref=\"https://github.com/openai/consistency_models\">code</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25445\">blog</a>]</p>\r\n<p><strong>【可控图文大模型】</strong>【伯克利&amp;微软｜用GPT-4进行可控的文本-图像生成】[<a\r\nhref=\"https://arxiv.org/abs/2305.18583\">paper</a>]</p>\r\n<h2 id=\"代码生成\">代码生成</h2>\r\n<p><strong>【综述】</strong>【代码大模型综述：中科院和MSRA调研27个LLMs，并给出5个有趣挑战】[<a\r\nhref=\"https://mp.weixin.qq.com/s/t2SMftox6546E7kvRgQMnA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2212.09420\">paper</a>]，[<a\r\nhref=\"https://nl2code.github.io\">项目主页</a>]</p>\r\n<p><strong>【博客】</strong>【GPT-Engineer｜提需求即可生成整个代码库，已20K星】[<a\r\nhref=\"https://mp.weixin.qq.com/s/rtsVsQbh7NnTh5vjgNMJHQ\">blog</a>]，[<a\r\nhref=\"https://github.com/AntonOsika/gpt-engineer\">code</a>]</p>\r\n<p><strong>【博客】</strong>【StarCoder: 最先进的代码大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/f-WwzLcEO-ZJczI-_bZh3Q\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【北京大学：具有大语言模型的自我规划代码生成】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06689.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【谷歌提出Self-Debugging:教导大型语言模型进行自我调试】[<a\r\nhref=\"https://arxiv.org/pdf/2304.05128.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【通过自我改进实现更好的代码语言模型，显著提高模型生成任务的性能】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01228.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Baldur:\r\n基于大型语言模型的完全证明生成与修复】[<a\r\nhref=\"https://arxiv.org/abs/2303.04910\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【CodeGeeX: A Pre-Trained Model for Code\r\nGeneration with Multilingual Evaluations on HumanEval-X 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.17568.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/THUDM/CodeGeeX\">code</a>]</p>\r\n<p><strong>【论文】</strong>【代码模型 CodeGeeX2-6B\r\n开源，最低6GB显存，性能优于StarCoder】[<a\r\nhref=\"https://mp.weixin.qq.com/s/roQSCo-7s361P3TmJjjZjA\">blog</a>]，[<a\r\nhref=\"https://github.com/THUDM/CodeGeeX2\">code</a>]</p>\r\n<p><strong>【论文】</strong>【CodeT5+：非常灵活的、面向代码理解和生成的开放大型代码语言模型】[<a\r\nhref=\"https://arxiv.org/abs/2305.07922\">paper</a>]</p>\r\n<p>【<strong>工具</strong>】【Cursor：一个集成了 GPT-4\r\n的国内直接可以访问的，优秀而强大的免费代码生成器，可以帮助你快速编写、编辑和讨论代码。】[<a\r\nhref=\"https://www.cursor.so/\">官网地址</a>]</p>\r\n<p><strong>【论文】</strong>【MIT最新研究：利用大预言模型生成Code】[<a\r\nhref=\"https://arxiv.org/abs/2303.05510\">paper</a>]，[<a\r\nhref=\"https://github.com/shunzh/Code-AI-Tree-Search\">code</a>]，[<a\r\nhref=\"https://codeaimcts.github.io/\">项目网址</a>]</p>\r\n<p><strong>【论文】</strong>【MathPrompter:\r\n基于大型语言模型的数学推理】[<a\r\nhref=\"https://arxiv.org/abs/2303.05398\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【MIT最新研究：利用大语言模型生成Code】[<a\r\nhref=\"https://arxiv.org/abs/2303.05510\">paper</a>]，[<a\r\nhref=\"https://github.com/shunzh/Code-AI-Tree-Search\">code</a>]，[<a\r\nhref=\"https://codeaimcts.github.io/\">官网地址</a>]</p>\r\n<h2 id=\"语音生成\">语音生成</h2>\r\n<p><strong>【论文】</strong>【Meta AI研究者推出MUSICGEN】[<a\r\nhref=\"https://arxiv.org/pdf/2306.05284.pdf\">paper</a>]，[<a\r\nhref=\"https://the-decoder.com/metas-open-source-ai-musicgen-turns-text-and-melody-into-new-songs/\">blog</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/facebook/MusicGen\">demo</a>]</p>\r\n<p><strong>【论文】</strong>【文字、图片一键生成逼真音效，音频界AIGC来了】[<a\r\nhref=\"https://arxiv.org/abs/2301.12661\">paper</a>]，[<a\r\nhref=\"https://text-to-audio.github.io\">code</a>]</p>\r\n<p>【<strong>论文</strong>】【音乐可视化｜利用大型语言模型和文本到图像模型帮助生成「音乐迪斯科」】[<a\r\nhref=\"https://arxiv.org/pdf/2304.08551.pdf\">paper</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25517\">blog</a>]</p>\r\n<p>【<strong>论文</strong>】【MetaAI发布第一个生成的人工智能语音模型Voicebox】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27492\">blog</a>]，[<a\r\nhref=\"https://research.facebook.com/file/649409006862002/paper_fixed.pdf\">paper</a>]</p>\r\n<h2 id=\"多模态生成\">多模态生成</h2>\r\n<p><strong>【BLIP-2】</strong>【高效训练多模态大模型（BLIP-2）】[<a\r\nhref=\"https://arxiv.org/abs/2301.12597\">paper</a>]，[<a\r\nhref=\"https://github.com/salesforce/LAVIS/tree/main/projects/blip2\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/Salesforce/BLIP2\">demo</a>]，[<a\r\nhref=\"https://huggingface.co/docs/transformers/main/en/model_doc/blip-2\">doc</a>]，[<a\r\nhref=\"https://github.com/salesforce/LAVIS\">fine-tuing</a>]，[<a\r\nhref=\"https://hf.co/spaces/Salesforce/BLIP2\">hugging face\r\nspaces</a>]</p>\r\n<p><strong>【VisCPM】</strong>【SOTA 开源中文多模态大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Fgfbs1vV7RF6kpyk4bfIYw\">blog</a>]，[<a\r\nhref=\"https://github.com/OpenBMB/VisCPM\">code</a>]</p>\r\n<p><strong>【HuggingFace Transformers\r\nAgents】</strong>【一键控制10万多个AI模型，HuggingFace给类ChatGPT模型们做了个「APP\r\nStore」】[<a\r\nhref=\"https://huggingface.co/docs/transformers/transformers_agents\">demo</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/8gyTqT1B4C2Da_6dmtaNiw\">blog</a>]</p>\r\n<p><strong>【LLaVA】</strong>【熔岩羊驼LLaVA来了：像GPT-4一样可以看图聊天，无需邀请码，在线可玩】[<a\r\nhref=\"https://arxiv.org/pdf/2304.08485.pdf\">paper</a>]，[<a\r\nhref=\"https://llava-vl.github.io/\">introduce</a>]</p>\r\n<p><strong>【UniDiffuser】</strong>【清华朱军团队开源UniDiffuser：首个基于Transformer的多模态扩散大模型！文图互生、改写全拿下！】[<a\r\nhref=\"https://ml.cs.tsinghua.edu.cn/diffusion/unidiffuser.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/thu-ml/unidiffuser\">code</a>]</p>\r\n<p><strong>【Video-LLaMA】</strong>【人机视频对话｜Video-LLaMA多模态框架，使大型语言模型具备了理解视频内容的能力】[<a\r\nhref=\"https://arxiv.org/abs/2306.02858\">paper</a>]</p>\r\n<p><strong>【X-LLM】</strong>【多模态语言训练大模型】[<a\r\nhref=\"https://x-llm.github.io/\">项目地址</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2305.04160\">paper</a>]</p>\r\n<h2 id=\"参考链接来源\">🗂 参考链接来源</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://github.com/luban-agi/Awesome-AIGC-Tutorials/tree/main\">Awesome-AIGC-Tutorials/</a></li>\r\n<li><a\r\nhref=\"https://github.com/gongminmin/awesome-aigc\">https://github.com/gongminmin/awesome-aigc</a></li>\r\n<li><a\r\nhref=\"https://github.com/Moonvy/OpenPromptStudio\">https://github.com/Moonvy/OpenPromptStudio</a></li>\r\n<li><a\r\nhref=\"https://github.com/wshzd/Awesome-AIGC/tree/main\">https://github.com/wshzd/Awesome-AIGC/tree/main</a></li>\r\n</ul>\r\n<h3 id=\"友情链接\">🤝 友情链接</h3>\r\n<ul>\r\n<li><a href=\"http://waytoagi.com/\">WayToAGI</a>\r\n<ul>\r\n<li>WaytoAGI.com\r\n是最全面的中文AIGC资源知识库，包括最新AI动态、提示词、学习指南等，长期保持活跃更新。</li>\r\n</ul></li>\r\n<li><a href=\"https://github.com/luban-agi/Awesome-Tool-Learning\">Awesome\r\nTool Learning</a>\r\n<ul>\r\n<li>Awesome Tool Learning\r\n提供丰富的关于工具学习的资源，包括论文、框架和应用程序。</li>\r\n</ul></li>\r\n<li><a href=\"https://github.com/luban-agi/Awesome-Domain-LLM\">Awesome\r\nDomain LLM</a>\r\n<ul>\r\n<li>这个GitHub仓库是一个汇集和整理了自ChatGPT等大语言模型出现后，各种垂直领域开源模型、数据集和评测基准的列表，同时鼓励大家为其贡献未收录的资源。</li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"声明\">🗂声明</h2>\r\n<p>以上部分资料来自网络整理，供大家学习参考，如有侵权，麻烦联系我删除！</p>\r\n","feature":true,"text":" 这里收集了关于AIGC的各种精选教程和资源，既适合初学者也适合进阶AI爱好者。 📜 目录 👋 入门 💬 大语言模型 💡 提示工程 🔧 大语言模型实践 🔬 大语...","permalink":"/post/aigcpaper","photos":[],"count_time":{"symbolsCount":"26k","symbolsTime":"24 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%9B%AE%E5%BD%95\"><span class=\"toc-text\">📜 目录</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%A5%E9%97%A8\"><span class=\"toc-text\">👋 入门</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">💬 大语言模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B\"><span class=\"toc-text\">💡 提示工程</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5\"><span class=\"toc-text\">🔧 大语言模型实践</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA\"><span class=\"toc-text\">🔬 大语言模型理论</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ai%E7%BB%98%E7%94%BB\"><span class=\"toc-text\">🎨 AI绘画</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%89%BA%E6%9C%AF%E5%9F%BA%E7%A1%80%E4%B8%8Eai%E7%BB%98%E7%94%BB%E6%8A%80%E5%B7%A7\"><span class=\"toc-text\">🧑‍🎨 艺术基础与AI绘画技巧</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#stable-diffusion%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8\"><span class=\"toc-text\">🌊 Stable Diffusion原理与应用</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ai%E9%9F%B3%E9%A2%91\"><span class=\"toc-text\">🔊 AI音频</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E6%A8%A1%E6%80%81\"><span class=\"toc-text\">🌈 多模态</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0\"><span class=\"toc-text\">🧠 深度学习</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ai%E7%B3%BB%E7%BB%9F\"><span class=\"toc-text\">💻 AI系统</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#aigc%E8%A7%86%E9%A2%91%E4%BC%9A%E8%AE%AE%E8%AE%BF%E8%B0%88\"><span class=\"toc-text\">AIGC视频会议&amp;访谈</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%99%BA%E6%BA%90%E7%A4%BE%E5%8C%BA\"><span class=\"toc-text\">智源社区</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%AE%BF%E8%B0%88%E8%A7%86%E9%A2%91\"><span class=\"toc-text\">访谈&amp;视频</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E4%BD%93%E9%AA%8C%E6%95%88%E6%9E%9C%E4%B8%93%E4%B8%9A%E8%AF%84%E4%BC%B0\"><span class=\"toc-text\">LLM体验效果&amp;专业评估</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">LLM垂直领域大模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B3%95%E5%BE%8B\"><span class=\"toc-text\">法律</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8C%BB%E7%96%97\"><span class=\"toc-text\">医疗</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%87%91%E8%9E%8D\"><span class=\"toc-text\">金融</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">环境</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8\"><span class=\"toc-text\">网络安全</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BA%A4%E9%80%9A\"><span class=\"toc-text\">交通</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%B6%E4%BB%96\"><span class=\"toc-text\">其他</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B\"><span class=\"toc-text\">LLM文本检测</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E9%95%BF%E6%96%87%E6%9C%AC%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88\"><span class=\"toc-text\">LLM长文本解决方案</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E5%8F%AF%E6%8E%A7%E6%80%A7%E4%B8%8E%E5%AE%89%E5%85%A8\"><span class=\"toc-text\">LLM可控性与安全</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E8%AE%AD%E7%BB%83%E5%BE%AE%E8%B0%83%E4%BC%98%E5%8C%96%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2\"><span class=\"toc-text\">LLM训练、微调、优化以及部署</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">LLM训练</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E5%BE%AE%E8%B0%83\"><span class=\"toc-text\">LLM微调</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">LLM优化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E9%83%A8%E7%BD%B2\"><span class=\"toc-text\">LLM部署</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E5%8D%9A%E5%AE%A2%E8%AE%BA%E6%96%87%E4%BB%A5%E5%8F%8A%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">LLM博客、论文以及代码</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">LLM数据集</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#prompt%E5%B7%A5%E7%A8%8B\"><span class=\"toc-text\">Prompt工程</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#agi%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7%E5%8D%9A%E5%AE%A2%E8%AE%BA%E6%96%87\"><span class=\"toc-text\">AGI开源工具&amp;博客&amp;论文</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90\"><span class=\"toc-text\">文本生成</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatgpt\"><span class=\"toc-text\">ChatGPT</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#chatgpt-%E5%BA%94%E7%94%A8%E7%AF%87\"><span class=\"toc-text\">ChatGPT 应用篇</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#chatgpt-%E5%B7%A5%E5%85%B7%E7%AF%87\"><span class=\"toc-text\">ChatGPT 工具篇</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#chatgpt-%E6%8A%80%E6%9C%AF%E7%AF%87\"><span class=\"toc-text\">ChatGPT 技术篇</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#gpt4\"><span class=\"toc-text\">GPT4</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#gpt4-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3\"><span class=\"toc-text\">GPT4 官方文档</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#gpt4-%E5%8D%9A%E5%AE%A2%E7%AF%87\"><span class=\"toc-text\">GPT4 博客篇</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#gpt4-%E8%AE%BA%E6%96%87%E7%AF%87\"><span class=\"toc-text\">GPT4 论文篇</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#anima\"><span class=\"toc-text\">Anima</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#bard\"><span class=\"toc-text\">Bard</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#baize\"><span class=\"toc-text\">Baize</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#baichuan%E4%BB%A5%E5%8F%8A%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">baichuan以及扩展</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#bloom\"><span class=\"toc-text\">BLOOM</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#biomedgpt\"><span class=\"toc-text\">BiomedGPT</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#claude\"><span class=\"toc-text\">Claude</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#claude-2\"><span class=\"toc-text\">Claude 2</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatglm-6b%E4%BB%A5%E5%8F%8A%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">ChatGLM-6B以及扩展</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatyuan\"><span class=\"toc-text\">ChatYuan</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#copilot-x\"><span class=\"toc-text\">Copilot X</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#colossalai\"><span class=\"toc-text\">ColossalAI</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#cpm-bee\"><span class=\"toc-text\">CPM-Bee</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatdb\"><span class=\"toc-text\">ChatDB</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#dolly\"><span class=\"toc-text\">Dolly</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#dolly2.0\"><span class=\"toc-text\">Dolly2.0</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#deepspeed-chat\"><span class=\"toc-text\">DeepSpeed-Chat</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#frugalgpt\"><span class=\"toc-text\">FrugalGPT</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#gpt3.5\"><span class=\"toc-text\">GPT3.5</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#jittorllms\"><span class=\"toc-text\">JittorLLMs</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm-as-controller\"><span class=\"toc-text\">LLM as Controller</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#metagpt\"><span class=\"toc-text\">MetaGPT</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#minigpt-4\"><span class=\"toc-text\">MiniGPT-4</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#moss\"><span class=\"toc-text\">MOSS</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#openchatkit\"><span class=\"toc-text\">OpenChatKit</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#openassistant\"><span class=\"toc-text\">OpenAssistant</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#webcpm\"><span class=\"toc-text\">WebCPM</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llama%E4%BB%A5%E5%8F%8A%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">LLaMA以及扩展</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E5%83%8F%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90\"><span class=\"toc-text\">图像、视频生成</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90\"><span class=\"toc-text\">代码生成</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AF%AD%E9%9F%B3%E7%94%9F%E6%88%90\"><span class=\"toc-text\">语音生成</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E6%A8%A1%E6%80%81%E7%94%9F%E6%88%90\"><span class=\"toc-text\">多模态生成</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E6%9D%A5%E6%BA%90\"><span class=\"toc-text\">🗂 参考链接来源</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5\"><span class=\"toc-text\">🤝 友情链接</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A3%B0%E6%98%8E\"><span class=\"toc-text\">🗂声明</span></a></li></ol>","author":{"name":"AIGC生成式人工智能开发者","slug":"blog-author","avatar":"https://robohash.org/JRU.png?set=set1","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"人工智能科技与文献网","uid":"28c7d3817ed8352eb1372ac636977eb8","slug":"ai1","date":"2023-10-20T09:55:43.516Z","updated":"2022-04-16T14:44:23.675Z","comments":true,"path":"api/articles/ai1.json","keywords":null,"cover":null,"text":" image AI新闻网：https://www.marktechpost.com/ 算法核心基础与AI模型设计【我的CSDN技术博客】：https://blo...","permalink":"/post/ai1","photos":["https://www.marktechpost.com/wp-content/uploads/2022/03/Screen-Shot-2022-03-31-at-4.17.59-PM-1024x663.png"],"count_time":{"symbolsCount":"2.2k","symbolsTime":"2 mins."},"categories":[{"name":"人工智能","slug":"人工智能","count":3,"path":"api/categories/人工智能.json"}],"tags":[{"name":"人工智能","slug":"人工智能","count":1,"path":"api/tags/人工智能.json"}],"author":{"name":"AIGC生成式人工智能开发者","slug":"blog-author","avatar":"https://robohash.org/JRU.png?set=set1","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}