{"title":"AIGC与大模型技术汇总","uid":"ffbd048b2d61dd97e5d6fd9f1e2a77c3","slug":"aigcpaper","date":"2023-10-20T12:18:45.830Z","updated":"2023-10-20T18:54:28.023Z","comments":true,"path":"api/articles/aigcpaper.json","keywords":null,"cover":"https://s2.loli.net/2023/10/20/Rg2vT6xuBP4Wlie.jpg","content":"<span id=\"more\"></span>\r\n<p>AIGC项目展示 <!-- \r\n<iframe src=\"https://player.bilibili.com/player.html?aid=959380148&bvid=BV1fH4y1f7AB&cid=1291676026&p=1\" width=\"780\" height=\"480\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe> --></p>\r\n<div\r\nstyle=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\">\r\n<iframe src=\"https://player.bilibili.com/player.html?aid=959380148&amp;bvid=BV1fH4y1f7AB&amp;cid=1291676026&amp;p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\">\r\n</iframe>\r\n</div>\r\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=\"330\" height=\"86\" src=\"https://music.163.com/outchain/player?type=2&amp;id=479408221&amp;auto=1&amp;height=66\">\r\n</iframe>\r\n<h1 id=\"一aigc技术\">一、AIGC技术</h1>\r\n<p>这里收集了关于AIGC的各种精选教程和资源，既适合初学者也适合进阶AI爱好者。</p>\r\n<h2 id=\"目录\">📜 目录</h2>\r\n<ul>\r\n<li><a href=\"#-入门\">👋 入门</a></li>\r\n<li><a href=\"#-大语言模型\">💬 大语言模型</a>\r\n<ul>\r\n<li><a href=\"#-提示工程\">💡 提示工程</a></li>\r\n<li><a href=\"#-大语言模型实践\">🔧 大语言模型实践</a></li>\r\n<li><a href=\"#-大语言模型理论\">🔬 大语言模型理论</a></li>\r\n</ul></li>\r\n<li><a href=\"#-ai绘画\">🎨 AI绘画</a>\r\n<ul>\r\n<li><a href=\"#-艺术基础与ai绘画技巧\">🧑‍🎨 艺术基础与AI绘画技巧</a></li>\r\n<li><a href=\"#-stable-diffusion原理与应用\">🌊 Stable\r\nDiffusion原理与应用</a></li>\r\n</ul></li>\r\n<li><a href=\"#-ai音频\">🔊 AI音频</a></li>\r\n<li><a href=\"#-多模态\">🌈 多模态</a></li>\r\n<li><a href=\"#-深度学习\">🧠 深度学习</a></li>\r\n<li><a href=\"#-ai系统\">💻 AI系统</a></li>\r\n<li><a href=\"#-其他\">🗂 其他</a></li>\r\n</ul>\r\n<h2 id=\"入门\">👋 入门</h2>\r\n<ul>\r\n<li><a href=\"https://www.deeplearning.ai/courses/ai-for-everyone/\">AI\r\nfor Everyone - 吴恩达</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.youtube.com/playlist?list=PLwRdpYzPkkn302_rL5RrXvQE8j0jLP02j\">Practical\r\nAI for Teachers and Students - 沃顿商学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://microsoft.github.io/AI-For-Beginners/\">Artificial\r\nIntelligence for Beginners - 微软</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a\r\nhref=\"https://www.cloudskillsboost.google/journeys/118\">Generative AI\r\nlearning path - 谷歌</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h2 id=\"提示工程\">💡 提示工程</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\">ChatGPT\r\nPrompt Engineering for Developers - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/\">Building\r\nSystems with the ChatGPT API - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\">LangChain\r\nfor LLM Application Development - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/Video-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/\">LangChain:\r\nChat with Your Data - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.coursera.org/learn/prompt-engineering?utm_medium=sem&amp;utm_source=gg&amp;utm_campaign=B2C_EMEA_prompt-engineering_vanderbilt_FTCOF_learn_country-GB-country-UK&amp;campaignid=20462816306&amp;adgroupid=157715342052&amp;device=c&amp;keyword=prompt%20engineering%20coursera&amp;matchtype=b&amp;network=g&amp;devicemodel=&amp;adposition=&amp;creativeid=670151312123&amp;hide_mobile_promo&amp;gclid=Cj0KCQjwuZGnBhD1ARIsACxbAVg8RCaUF0lwFyVnMuP7T7bHoH0jST0XXhQ3S1vmDxtZc8O1WlJ8FXQaAtG-EALw_wcB\">Prompt\r\nEngineering for ChatGPT - 范德堡大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://learnprompting.org/\">Learn Prompting</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"https://www.pinecone.io/learn/series/langchain/\">LangChain\r\nAI Handbook - James Briggs, Francisco Ingham</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/书籍-%2391672c\" /></li>\r\n</ul>\r\n<h2 id=\"大语言模型实践\">🔧 大语言模型实践</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/\">LLM\r\nBootcamp - The Full Stack</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/finetuning-large-language-models/\">Finetuning\r\nLarge Language Models - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h2 id=\"大语言模型理论\">🔬 大语言模型理论</h2>\r\n<ul>\r\n<li><a href=\"https://stanford-cs324.github.io/winter2023/\">CS324 -\r\nAdvances in Foundation Models - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" />\r\n<ul>\r\n<li>斯坦福大学关于大模型的新课，主要材料是一些notes，介绍了大语言模型的基础知识、能力范围、训练部署以及一些大模型相关的问题（数据安全、法律、危害等），总体来说比较简单，适合入门。2023年的版本对课纲进行了更新，增加了关于图像-文本和多模态的大模型内容。</li>\r\n</ul></li>\r\n<li><a href=\"https://self-supervised.cs.jhu.edu/sp2023/index.html\">CS\r\n601.471/671 NLP: Self-supervised Models - 约翰霍普金斯大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" />\r\n<ul>\r\n<li>JHU也是NLP大牛校，这门课难度适中，课程主页上各类资源还挺多的，建议大家看一看。</li>\r\n</ul></li>\r\n<li><a href=\"https://web.stanford.edu/class/cs224n/\">CS224N: Natural\r\nLanguage Processing with Deep Learning - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>这门课Christopher\r\nManning在斯坦福开了很多年，很经典的课程。前面是NLP的基础知识，后面几节课会涉及到大语言模型。</li>\r\n</ul></li>\r\n<li><a href=\"https://web.stanford.edu/~jurafsky/slp3/\">Speech and\r\nLanguage Processing - Dan Jurafsky and James H. Martin</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/书籍-%2391672c\" />\r\n<ul>\r\n<li>最经典的NLP教材，本来计划在大概三四年前就完稿的，但是由于近几年NLP领域发展实在太快，作者干脆就不设DDL了，一直在持续更新中。</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://www.cs.princeton.edu/courses/archive/fall22/cos597G/\">COS\r\n597G (Fall 2022): Understanding Large Language Models - 普林斯顿大学</a>\r\n<img src=\"https://img.shields.io/badge/Level-困难-red\" />\r\n<ul>\r\n<li>Danqi\r\nChen的课，课程难度较高，主要材料是PPT和相关的论文，适合深入LLM某个方向的同学。</li>\r\n</ul></li>\r\n</ul>\r\n<h2 id=\"ai绘画\">🎨 AI绘画</h2>\r\n<h3 id=\"艺术基础与ai绘画技巧\">🧑‍🎨 艺术基础与AI绘画技巧</h3>\r\n<ul>\r\n<li><a\r\nhref=\"https://www.niji.academy/work/lecture\">系列讲座:每周一个关于艺术基础的有趣话题\r\n- Niji Academy</a> <a\r\nhref=\"https://mp.weixin.qq.com/s/CxEv5NQF_wzAtqXnuNbKog\">[中文版]</a>\r\n<img src=\"https://img.shields.io/badge/Level-简单-green\" /></li>\r\n<li><a\r\nhref=\"https://ciweicui.feishu.cn/docx/DPbidgdBeoNw55xKjO6c7ao3nbc\">AIGCTalk-Midjourney学习手册</a>\r\n<img src=\"https://img.shields.io/badge/Level-简单-green\" /></li>\r\n<li><a\r\nhref=\"https://space.bilibili.com/630876766/channel/collectiondetail?sid=1045607\">【Midjourney】保姆级AI绘画创作系列教学课程\r\n- 莱森</a> <img src=\"https://img.shields.io/badge/Level-简单-green\" />\r\n<img src=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h3 id=\"stable-diffusion原理与应用\">🌊 Stable Diffusion原理与应用</h3>\r\n<ul>\r\n<li><a\r\nhref=\"https://space.bilibili.com/12566101/channel/seriesdetail?sid=2706990\">【AI绘画】Stable\r\nDiffusion 系列教程</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>秋葉aaaki大神喂饭级别Stable Diffusion 系列教程</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/how-diffusion-models-work/\">How\r\nDiffusion Models Work - DeepLearning.AI</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.bilibili.com/video/BV14c411J7f2/?vd_source=a4218e1e16a294070cadf4eefa94fa32\">扩散模型\r\n- Diffusion Model - 李宏毅</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>偏宏观，比较通俗易懂</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://www.bilibili.com/video/BV1Re4y1s7uV/?p=1&amp;vd_source=a4218e1e16a294070cadf4eefa94fa32\">Diffusion扩散模型\r\n- 唐宇迪</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" />\r\n<ul>\r\n<li>唐宇迪老师讲stable diffusion和dalle推理讲的比较清楚</li>\r\n</ul></li>\r\n<li><a\r\nhref=\"https://github.com/huggingface/diffusion-models-class\">Hugging\r\nFace Diffusion Models Course</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n</ul>\r\n<h2 id=\"ai音频\">🔊 AI音频</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://huggingface.co/learn/audio-course/chapter0/introduction\">Hugging\r\nFace Audio Course</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"http://web.stanford.edu/class/cs224s/\">CS224S: Spoken\r\nLanguage Processing - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n</ul>\r\n<h2 id=\"多模态\">🌈 多模态</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://cmu-multicomp-lab.github.io/mmml-tutorial/icml2023/\">Tutorial\r\non MultiModal Machine Learning (ICML 2023) - 卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://cmu-multicomp-lab.github.io/mmml-course/fall2022/\">11-777:\r\nMultiModal Machine Learning (Fall 2022) - 卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://cmu-multicomp-lab.github.io/adv-mmml-course/spring2022/\">11-877:\r\nAdvanced Topics in MultiModal Machine Learning (Fall 2022) -\r\n卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /></li>\r\n</ul>\r\n<h2 id=\"深度学习\">🧠 深度学习</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://www.youtube.com/playlist?list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1\">Neural\r\nNetworks/Deep Learning - StatQuest</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://www.3blue1brown.com/topics/neural-networks\">Neural\r\nNetworks - 3Blue1Brown</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-简单-green\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://karpathy.ai/zero-to-hero.html\">Neural Networks:\r\nZero to Hero - Andrej Karpathy</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://course.fast.ai/\">Practical Deep Learning for Coders\r\n- fast.ai</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/courses/deep-learning-specialization/\">Deep\r\nLearning Specialization - 吴恩达</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"http://introtodeeplearning.com/\">6.S191: Introduction to\r\nDeep Learning - 麻省理工学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://web.stanford.edu/class/cs25/\">CS25: Transformers\r\nUnited V2 - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deepmind.com/learning-resources/deep-learning-lecture-series-2020\">Deep\r\nLearning Lecture Series 2020 - DeepMind x 伦敦大学学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a\r\nhref=\"https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021\">Reinforcement\r\nLearning Lecture Series 2021 - DeepMind x 伦敦大学学院</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n</ul>\r\n<h2 id=\"ai系统\">💻 AI系统</h2>\r\n<ul>\r\n<li><a href=\"https://ucbrise.github.io/cs294-ai-sys-sp22/\">AI-Sys-Sp22\r\nMachine Learning Systems - 加州大学伯克利分校</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"https://dlsyscourse.org/\">Deep Learning Systems: Algorithms\r\nand Implementation - Tianqi Chen, Zico Kolter</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /> <img\r\nsrc=\"https://img.shields.io/badge/视频-blue\" /></li>\r\n<li><a href=\"https://stanford-cs329s.github.io/\">CS 329S: Machine\r\nLearning Systems Design - 斯坦福大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-中等-yellow\" /></li>\r\n<li><a href=\"https://www.cs.cmu.edu/~zhihaoj2/15-849/\">15-849: Machine\r\nLearning Systems - 卡耐基梅隆大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /></li>\r\n<li><a\r\nhref=\"https://www.cs.princeton.edu/courses/archive/spring21/cos598D/general.html\">Computer\r\nScience 598D - Systems and Machine Learning - 普林斯顿大学</a> <img\r\nsrc=\"https://img.shields.io/badge/Level-困难-red\" /></li>\r\n</ul>\r\n<h1 id=\"二中国大模型列表\">二、中国大模型列表</h1>\r\n<p>参考来自：https://github.com/wgwang/LLMs-In-China/tree/main</p>\r\n<h2 id=\"大模型列表\">大模型列表</h2>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 0%\" />\r\n<col style=\"width: 4%\" />\r\n<col style=\"width: 30%\" />\r\n<col style=\"width: 2%\" />\r\n<col style=\"width: 3%\" />\r\n<col style=\"width: 0%\" />\r\n<col style=\"width: 58%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th style=\"text-align: left;\">序号</th>\r\n<th style=\"text-align: left;\">公司</th>\r\n<th style=\"text-align: left;\">大模型</th>\r\n<th style=\"text-align: left;\">省市</th>\r\n<th style=\"text-align: left;\">类别</th>\r\n<th style=\"text-align: left;\">官网</th>\r\n<th style=\"text-align: left;\">说明</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">1</td>\r\n<td style=\"text-align: left;\">百度</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://yiyan.baidu.com\">文心一言</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">有APP，衍生<a\r\nhref=\"https://01.baidu.com/\">灵医Bot</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">2</td>\r\n<td style=\"text-align: left;\">智谱华章</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://chatglm.cn/\">清言</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">有APP，开源小模型<a\r\nhref=\"https://github.com/THUDM/ChatGLM-6B\">ChatGLM-6B</a>和<a\r\nhref=\"https://github.com/THUDM/ChatGLM2-6B\">ChatGLM2-6B</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">3</td>\r\n<td style=\"text-align: left;\">百川智能</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://chat.baichuan-ai.com/\">百川</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">开源小模型<a\r\nhref=\"https://github.com/baichuan-inc/baichuan-7B\">baichuan-7B</a>和<a\r\nhref=\"https://github.com/baichuan-inc/Baichuan-13B\">Baichuan-13B</a>，<a\r\nhref=\"https://github.com/baichuan-inc/Baichuan2\">baichuan-2</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">4</td>\r\n<td style=\"text-align: left;\">达观数据</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"http://www.datagrand.com/products/aigc/\">曹植</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://aigc.datagrand.com/\">试用需账号</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">5</td>\r\n<td style=\"text-align: left;\">上海人工智能实验室</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://intern-ai.org.cn/\">书生</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">开源小模型<a\r\nhref=\"https://github.com/InternLM/InternLM\">书生·浦语</a>，<a\r\nhref=\"https://github.com/openmedlab\">OpenMEDLab浦医</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">6</td>\r\n<td style=\"text-align: left;\">科大讯飞</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://xinghuo.xfyun.cn\">星火</a></td>\r\n<td style=\"text-align: left;\">安徽合肥</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://xinghuo.xfyun.cn/desk\">试用需账号</a>,有APP</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">7</td>\r\n<td style=\"text-align: left;\">稀宇科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://api.minimax.chat/\">ABAB</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">GLOW虚拟社交,MiniMax</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">8</td>\r\n<td style=\"text-align: left;\">商汤科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://techday.sensetime.com/\">日日新</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">9</td>\r\n<td style=\"text-align: left;\">春田知韵（抖音）</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.doubao.com/chat/\">豆包</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">开源多模态7B小模型<a\r\nhref=\"https://bubo-gpt.github.io/\">BuboGPT</a>，豆包是云雀的聊天机器人</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">10</td>\r\n<td style=\"text-align: left;\">中国科学院自动化研究所</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://gitee.com/zidongtaichu/multi-modal-models\">紫东·太初</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">紫东太初2.0号称100B参数，全模态</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">11</td>\r\n<td style=\"text-align: left;\">阿里云</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://tongyi.aliyun.com/\">通义千问</a></td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://tongyi.aliyun.com\">试用需账号</a>,开源小模型<a\r\nhref=\"https://github.com/QwenLM/Qwen-7B\">Qwen-7B</a>和<a\r\nhref=\"https://huggingface.co/Qwen/Qwen-7B-Chat\">Qwen-7B-Chat</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">12</td>\r\n<td style=\"text-align: left;\">华为</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://openi.pcl.ac.cn/PCL-Platform.Intelligence/PanGu-Alpha\">盘古</a>,<a\r\nhref=\"https://www.nature.com/articles/s41586-023-06185-3\">盘古气象</a>,<a\r\nhref=\"https://arxiv.org/pdf/2303.10845.pdf\">盘古-Σ</a></td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">华为+鹏城,<a\r\nhref=\"https://www.huaweicloud.com/product/pangu.html\">华为云盘古</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">13</td>\r\n<td style=\"text-align: left;\">复旦大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/OpenLMLab/MOSS\">MOSS</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://moss.fastnlp.top/\">试用需账号</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">14</td>\r\n<td style=\"text-align: left;\">智源人工智能研究院</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila\">悟道·天鹰</a>,<a\r\nhref=\"https://github.com/baaivision/Emu\">悟道·EMU</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">悟道3.0,视界视觉，AQUILA天鹰座，<a\r\nhref=\"https://model.baai.ac.cn/model-detail/100098\">Aquila-7B</a>,<a\r\nhref=\"https://model.baai.ac.cn/model-detail/100101\">AquilaChat-7B</a>,<a\r\nhref=\"https://model.baai.ac.cn/model-detail/100102\">AquilaCode-7B-NV</a>,<a\r\nhref=\"https://model.baai.ac.cn/model-detail/100099\">AquilaCode-7B-TS</a>,<a\r\nhref=\"https://huggingface.co/BAAI\">HuggingFace</a>,<a\r\nhref=\"https://huggingface.co/BAAI/Emu\">EMU</a>基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">15</td>\r\n<td style=\"text-align: left;\">浙江大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/CMKRG/QiZhenGPT\">启真</a>,<a\r\nhref=\"https://github.com/syw1996/TableGPT\">TableGPT</a>,<a\r\nhref=\"https://github.com/zhihaiLLM/wisdomInterrogatory\">智海-录问</a>,<a\r\nhref=\"\">智海-三乐</a>,<a\r\nhref=\"https://github.com/HICAI-ZJU/PromptProtein\">PromptProtein</a></td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">垂直</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td\r\nstyle=\"text-align: left;\">医学大模型提供基于LLaMA-7B、CaMA-13B和ChatGLM-6B\r\n三个版本,用于PromptProtein的<a\r\nhref=\"https://github.com/HICAI-ZJU/OpenProtein\">模型</a>，法律大模型智海-录问基于<a\r\nhref=\"https://mp.weixin.qq.com/s/3PrA60M2T_lyCI25UXhIxg\">Baichuan-7B</a>，智海-三乐基于Qwen-7B</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">16</td>\r\n<td style=\"text-align: left;\">OpenBMB</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://live.openbmb.org/\">CPM</a>,<a\r\nhref=\"https://github.com/OpenBMB/CPM-Bee\">CPM-Bee</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://modelbest.cn/\">面壁智能</a>,<a\r\nhref=\"https://huggingface.co/openbmb/cpm-bee-10b\">CPM-Bee-10B</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">17</td>\r\n<td style=\"text-align: left;\">元象科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/xverse-ai/XVERSE-13B\">XVERSE-13B</a></td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://huggingface.co/xverse/XVERSE-13B\">模型下载</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">18</td>\r\n<td style=\"text-align: left;\">腾讯</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://hunyuan.tencent.com/\">混元</a></td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">19</td>\r\n<td style=\"text-align: left;\">云知声</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://shanhai.unisound.com/\">山海</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">20</td>\r\n<td style=\"text-align: left;\">东北大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/neukg/TechGPT\">TechGPT</a>,<a\r\nhref=\"https://github.com/NEU-DataMining/PICA\">PICA</a></td>\r\n<td style=\"text-align: left;\">辽宁沈阳</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">TechGPT-&gt;BELLE-&gt;<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>，图谱构建和阅读理解问答;PICA-&gt;ChatGLM2-6B情感大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">21</td>\r\n<td style=\"text-align: left;\">IDEA研究院</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://fengshenbang-lm.com/\">封神榜MindBot</a>,<a\r\nhref=\"https://huggingface.co/IDEA-CCNL/Ziya-Coding-15B-v1\">ziya-coding</a></td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1\">姜子牙</a>系列模型\r\n,ziya-coding代码大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">22</td>\r\n<td style=\"text-align: left;\">贝壳</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/LianjiaTech/BELLE\">BELLE</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">垂直</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于BLOOMZ或<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>的多个模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">23</td>\r\n<td style=\"text-align: left;\">360</td>\r\n<td style=\"text-align: left;\"><a href=\"https://ai.360.cn/\">智脑</a>,<a\r\nhref=\"https://github.com/360CVGroup/SEEChat\">一见</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">24</td>\r\n<td style=\"text-align: left;\">哈尔滨工业大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese\">本草</a>,<a\r\nhref=\"https://github.com/hit-scir/huozi\">活字</a></td>\r\n<td style=\"text-align: left;\">黑龙江哈尔滨</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">医学，本草基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>；另有基于\r\nChatGLM 的<a\r\nhref=\"https://github.com/SCIR-HI/Med-ChatGLM\">Med-ChatGLM</a>，活字基于BLOOM-7B</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">25</td>\r\n<td style=\"text-align: left;\">北京大学信息工程学院</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/PKU-YuanGroup/ChatLaw\">ChatLaw</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">法律</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://huggingface.co/JessyTsu1/ChatLaw-13B\">ChatLaw-13B</a>基于Ziya-LLaMA-13B-v1-&gt;LLaMA,<a\r\nhref=\"https://huggingface.co/JessyTsu1/ChatLaw-33B\">ChatLaw-33B</a>基于Anima33B-&gt;Guanaco-&gt;<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">26</td>\r\n<td style=\"text-align: left;\">港中文深圳</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/FreedomIntelligence/HuatuoGPT\">华佗</a>，<a\r\nhref=\"https://github.com/FreedomIntelligence/LLMZoo\">凤凰</a></td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td\r\nstyle=\"text-align: left;\">香港中文大学（深圳）和深圳市大数据研究院，医学,<a\r\nhref=\"https://www.huatuogpt.cn/\">Demo</a>,华佗和凤凰都基于BLOOMZ</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">27</td>\r\n<td style=\"text-align: left;\">中国科学院计算技术研究所</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/ictnlp/BayLing\">百聆</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>，权重Diff下载<a\r\nhref=\"https://huggingface.co/ICTNLP/bayling-7b-diff\">7B</a>和<a\r\nhref=\"https://huggingface.co/ICTNLP/bayling-13b-diff\">13B</a>,<a\r\nhref=\"http://nlp.ict.ac.cn/bayling/demo/\">demo</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">28</td>\r\n<td style=\"text-align: left;\">好未来</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.mathgpt.com/\">MathGPT</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">学而思</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">29</td>\r\n<td style=\"text-align: left;\">晓多科技+国家超算成都中心</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://xpt.xiaoduoai.com\">晓模型XPT</a></td>\r\n<td style=\"text-align: left;\">四川成都</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://xpt.xiaoduoai.com/\">试用申请</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">30</td>\r\n<td style=\"text-align: left;\">网易有道</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://aicenter.youdao.com/\">子曰</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">推荐<a\r\nhref=\"https://read.youdao.com/\">有道速读</a>,读论文的利器</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">31</td>\r\n<td style=\"text-align: left;\">中国科学院成都计算机应用研究所</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese\">聚宝盆</a></td>\r\n<td style=\"text-align: left;\">四川成都</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>的金融大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">32</td>\r\n<td style=\"text-align: left;\">华南理工大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/scutcyr/BianQue\">扁鹊</a>,<a\r\nhref=\"https://github.com/scutcyr/SoulChat\">灵心SoulChat</a></td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">33</td>\r\n<td style=\"text-align: left;\">虎博科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/TigerResearch/TigerBot\">TigerBot</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于<a\r\nhref=\"https://mp.weixin.qq.com/s/ia-yrmXbnlooRA3K1hoTwQ\">BLOOM</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">34</td>\r\n<td style=\"text-align: left;\">度小满</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://huggingface.co/xyz-nlp/XuanYuan2.0\">轩辕</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于<a\r\nhref=\"https://mp.weixin.qq.com/s/ia-yrmXbnlooRA3K1hoTwQ\">BLOOM</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">35</td>\r\n<td style=\"text-align: left;\">北京交通大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/DUOMO/TransGPT\">致远</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">交通</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://huggingface.co/DUOMO-Lab/TransGPT-v0\">TransGPT・致远</a>，基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>-7B</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">36</td>\r\n<td style=\"text-align: left;\">恒生电子</td>\r\n<td style=\"text-align: left;\">LightGPT</td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://arxiv.org/abs/2307.07306\">与浙大合作的NL2SQL</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">37</td>\r\n<td style=\"text-align: left;\">上海交通大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/davendw49/k2\">K2</a>,<a\r\nhref=\"https://mp.weixin.qq.com/s/3eON8L4b7-d-1URwgdR6Bg\">白玉兰</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">K2:地球科学，白玉兰:科学</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://k2.acemap.info/\">Demo</a>，GeoLLaMA，基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>，<a\r\nhref=\"https://huggingface.co/daven3/k2_it_adapter\">HuggingFace</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">38</td>\r\n<td style=\"text-align: left;\">左手医生</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/Tv9nIG_9K-Lf5AKatjichA\">左医GPT</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">医疗，<a\r\nhref=\"https://gpt.zuoshouyisheng.com/\">试用需Key</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">39</td>\r\n<td style=\"text-align: left;\">上海科技大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/xionghonglin/DoctorGLM\">DoctorGLM</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">医学大模型，<a\r\nhref=\"https://arxiv.org/pdf/2304.01097.pdf\">论文</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">40</td>\r\n<td style=\"text-align: left;\">华东师范大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/xP-qm5YUj8fZD9YQ7t08NQ\">EmoGPT</a>,<a\r\nhref=\"https://github.com/icalk-nlp/EduChat\">EduChat</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">EmoGPT是上海市心理健康与危机干预重点实验室与镜象科技公司合作完成,\r\n教学教育大模型EduChat基于BELLE（BELLE基于LLaMA）</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">41</td>\r\n<td style=\"text-align: left;\">艾写科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/lyogavin/Anima\">Anima</a></td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">营销</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于Guanaco-&gt;基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>，使用QLoRA</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">42</td>\r\n<td style=\"text-align: left;\">澳门理工大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/WangRongsheng/XrayGLM\">XrayGLM</a>,<a\r\nhref=\"https://github.com/WangRongsheng/IvyGPT\">IvyGPT</a></td>\r\n<td style=\"text-align: left;\">澳门</td>\r\n<td style=\"text-align: left;\">医疗</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td\r\nstyle=\"text-align: left;\">IvyGPT基于ChatGLM2，XrayGLM基于VisualGLM-6B</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">43</td>\r\n<td style=\"text-align: left;\">北京语言大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/blcuicall/taoli\">桃李</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>,北语+清华+东北、北京交大</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">44</td>\r\n<td style=\"text-align: left;\">中工互联</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/ANsZeqj4V_NeVCquwX-aSQ\">智工</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">与复旦NLP实验室联合，工业领域</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">45</td>\r\n<td style=\"text-align: left;\">创业黑马</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/lYqCe9skc0MOSzmmTiGAug\">天启</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">创投</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">创业黑马与360合作,科创服务行业</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">46</td>\r\n<td style=\"text-align: left;\">追一科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/cYVh6K6edmColgMEOaGFKg\">博文Bowen</a></td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">47</td>\r\n<td style=\"text-align: left;\">智慧眼</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/lid0nUBwXEdoUhnw_guteA\">砭石</a></td>\r\n<td style=\"text-align: left;\">湖南长沙</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">医疗领域</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">48</td>\r\n<td style=\"text-align: left;\">香港科技大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://huggingface.co/OptimalScale\">罗宾Robin</a></td>\r\n<td style=\"text-align: left;\">香港</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于<a\r\nhref=\"https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA\">LLaMA</a>,<a\r\nhref=\"https://github.com/OptimalScale/LMFlow\">港科大开源LMFlow</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">49</td>\r\n<td style=\"text-align: left;\">昆仑万维</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/SkyWorkAIGC\">天工</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">与奇点智源联合研发</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">50</td>\r\n<td style=\"text-align: left;\">智媒开源研究院</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/IMOSR/Media-LLaMA\">智媒</a></td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">基于LLaMA，面向自媒体</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">51</td>\r\n<td style=\"text-align: left;\">医疗算网</td>\r\n<td style=\"text-align: left;\">Uni-talk</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">上海联通+华山医院+上海超算中心+华为</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">52</td>\r\n<td style=\"text-align: left;\">蚂蚁集团</td>\r\n<td style=\"text-align: left;\">贞仪,<a\r\nhref=\"https://huggingface.co/codefuse-ai\">CodeFuse</a></td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">CodeFuse代码大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">53</td>\r\n<td style=\"text-align: left;\">硅基智能</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/XNu3UrSKm4jy1ayJJ6-HMg\">炎帝</a></td>\r\n<td style=\"text-align: left;\">江苏南京</td>\r\n<td style=\"text-align: left;\">文旅</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">54</td>\r\n<td style=\"text-align: left;\">西湖心辰</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://xinchenai.com/\">西湖</a></td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">55</td>\r\n<td style=\"text-align: left;\">国家超级计算天津中心</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/A9jnnL3-LjcDLsDD2PCa6g\">天河天元</a></td>\r\n<td style=\"text-align: left;\">天津</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">56</td>\r\n<td style=\"text-align: left;\">星环科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/6rYmk58OypU_Wwu0L7-nTw\">无涯、求索</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">无涯——金融；求索——大数据分析</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">57</td>\r\n<td style=\"text-align: left;\">清博智能</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/Et-nVHjxDP3W-PFWmDo3YQ\">先问</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">农业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">基于结构化数据</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">58</td>\r\n<td style=\"text-align: left;\">智子引擎</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://chatimg.aixiaoqingxu.com/\">元乘象</a></td>\r\n<td style=\"text-align: left;\">江苏南京</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">59</td>\r\n<td style=\"text-align: left;\">拓世科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://tskjgroup.com/article_news?id=822\">拓世</a></td>\r\n<td style=\"text-align: left;\">江西南昌</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">60</td>\r\n<td style=\"text-align: left;\">循环智能</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.rcrai.com/product/ai/pangu\">盘古</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">循环智能,清华大学,华为</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">61</td>\r\n<td style=\"text-align: left;\">慧言科技+天津大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/FCnXXmT0jRfk4tTRIAK9FA\">海河·谛听</a></td>\r\n<td style=\"text-align: left;\">天津</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">62</td>\r\n<td style=\"text-align: left;\">第四范式</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.4paradigm.com/product/SageGPT.html\">式说</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">63</td>\r\n<td style=\"text-align: left;\">拓尔思</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/beQardxjpner6vvk_LTOJA\">拓天</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">TRSGPT</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">64</td>\r\n<td style=\"text-align: left;\">出门问问</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://write.mobvoi.com/\">序列猴子</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">营销</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">65</td>\r\n<td style=\"text-align: left;\">数说故事</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/Tt3dcwefIvdlyB_IwaFYRQ\">SocialGPT</a></td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">社交</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">66</td>\r\n<td style=\"text-align: left;\">云从科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.cloudwalk.com/news/show/id/178\">从容</a></td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">67</td>\r\n<td style=\"text-align: left;\">浪潮信息</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://air.inspur.com/\">源</a></td>\r\n<td style=\"text-align: left;\">山东济南</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/Shawn-Inspur/Yuan-1.0\">源</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">68</td>\r\n<td style=\"text-align: left;\">中国农业银行</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/CXyZRIqhwrcGAKxzUC-qgg\">小数ChatABC</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">69</td>\r\n<td style=\"text-align: left;\">麒麟合盛</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.apusai.com/\">天燕AiLMe</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">运维</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">70</td>\r\n<td style=\"text-align: left;\">台智云</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://tws.twcc.ai/afs/\">福尔摩斯FFM</a></td>\r\n<td style=\"text-align: left;\">台湾</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">华硕子公司</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">71</td>\r\n<td style=\"text-align: left;\">医联科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.medlinker.com/news/198\">medGPT</a></td>\r\n<td style=\"text-align: left;\">四川成都</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">72</td>\r\n<td style=\"text-align: left;\">电信智科</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/ntd0z5CJOY6peou4bOVJqA\">星河</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通信</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">通用视觉，中国电信</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">73</td>\r\n<td style=\"text-align: left;\">深思考人工智能</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.dongni.ai/\">Dongni</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">74</td>\r\n<td style=\"text-align: left;\">文因互联</td>\r\n<td style=\"text-align: left;\">文因</td>\r\n<td style=\"text-align: left;\">安徽合肥</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">金融大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">75</td>\r\n<td style=\"text-align: left;\">印象笔记</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/O3nRSKBM29bCWKuRRi_PBg\">大象GPT</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">76</td>\r\n<td style=\"text-align: left;\">中科闻歌</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/IGYV3t3JRlq4quvNJmZ4vA\">雅意</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">77</td>\r\n<td style=\"text-align: left;\">澜舟科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.langboat.com/portal/mengzi-model\">孟子</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">78</td>\r\n<td style=\"text-align: left;\">京东</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.jdcloud.com/cn/news/detail/1235\">言犀</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">商业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">79</td>\r\n<td style=\"text-align: left;\">香港中文大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/OpenRobotLab/PointLLM\">PointLLM</a></td>\r\n<td style=\"text-align: left;\">香港</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\">港中文+上海AI实验室+浙大</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">80</td>\r\n<td style=\"text-align: left;\">清华大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.nature.com/articles/s41586-023-06184-4\">NowcastNet</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/MwJWjCLNqJM3lZ33RwK4Bg\">气象,临近预报大模型</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">81</td>\r\n<td style=\"text-align: left;\">鹏城实验室</td>\r\n<td style=\"text-align: left;\">鹏城·脑海</td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">Peng Cheng Mind</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">82</td>\r\n<td style=\"text-align: left;\">宇视科技</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/H8FsrEyJsIijy0Cowyu3GQ\">梧桐</a></td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">运维</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">AIoT行业</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">83</td>\r\n<td style=\"text-align: left;\">智臻智能</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/MZO2tvun05WnJkSe0seJnw\">华藏</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">小i机器人</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">84</td>\r\n<td style=\"text-align: left;\">美亚柏科</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/D3ki3G4Q7QZPAVJ8iwTvDg\">天擎</a></td>\r\n<td style=\"text-align: left;\">福建厦门</td>\r\n<td style=\"text-align: left;\">安全</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">公共安全</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">85</td>\r\n<td style=\"text-align: left;\">山东大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/irlab-sdu/fuzi.mingcha\">夫子•明察</a></td>\r\n<td style=\"text-align: left;\">山东济南</td>\r\n<td style=\"text-align: left;\">司法</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td\r\nstyle=\"text-align: left;\">山东大学+浪潮云+中国政法大学，基于ChatGLM，无监督司法语料（各类判决文书、法律法规等）与有监督司法微调数据（包括法律问答、类案检索）训练而成</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">86</td>\r\n<td style=\"text-align: left;\">数慧时空</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/KYB-noOt7gB0l5hh-rwfkQ\">长城</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">地球科学</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">自然资源，遥感</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">87</td>\r\n<td style=\"text-align: left;\">佳都科技</td>\r\n<td style=\"text-align: left;\">佳都知行</td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">交通</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">交通领域</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">88</td>\r\n<td style=\"text-align: left;\">知乎</td>\r\n<td style=\"text-align: left;\">知海图</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">知乎和面壁科技合作</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">89</td>\r\n<td style=\"text-align: left;\">网易伏羲</td>\r\n<td style=\"text-align: left;\">玉言</td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">90</td>\r\n<td style=\"text-align: left;\">清睿智能</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/FFRfzwoXBM2dGs9O7F-Z5A\">ArynGPT</a></td>\r\n<td style=\"text-align: left;\">江苏苏州</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">91</td>\r\n<td style=\"text-align: left;\">微盟</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://wai.weimob.com/\">WAI</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">商业</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">92</td>\r\n<td style=\"text-align: left;\">西北工业大学+华为</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.nwpu.edu.cn/info/1198/65828.htm\">秦岭·翱翔</a></td>\r\n<td style=\"text-align: left;\">陕西西安</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">流体力学大模型,湍流+流场</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">93</td>\r\n<td style=\"text-align: left;\">奇点智源</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://openapi.singularity-ai.com/\">天工智力</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://openapi.singularity-ai.com/index.html#/documentIndex\">瑶光和天枢</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">94</td>\r\n<td style=\"text-align: left;\">联汇科技</td>\r\n<td style=\"text-align: left;\">欧姆</td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://om.linker.cc/\">OmModel欧姆多模态（视觉语言）大模型</a></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">95</td>\r\n<td style=\"text-align: left;\">中国联通</td>\r\n<td style=\"text-align: left;\">鸿湖</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通信</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">96</td>\r\n<td style=\"text-align: left;\">思必驰</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/FxLw5UfJpYS1tCPDMkhvXA\">DFM-2</a></td>\r\n<td style=\"text-align: left;\">江苏苏州</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">97</td>\r\n<td style=\"text-align: left;\">理想科技</td>\r\n<td style=\"text-align: left;\">大道Dao</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">运维</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">运维大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">98</td>\r\n<td style=\"text-align: left;\">电科太极</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/8ci7g7R9j3pxkQC4UOLh2A\">小可</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">党政企行业应用</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">99</td>\r\n<td style=\"text-align: left;\">中国移动</td>\r\n<td style=\"text-align: left;\">九天</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通信</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">100</td>\r\n<td style=\"text-align: left;\">中国电信</td>\r\n<td style=\"text-align: left;\">TeleChat</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">通信</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">101</td>\r\n<td style=\"text-align: left;\">容联云</td>\r\n<td style=\"text-align: left;\">赤兔</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">客服，营销</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">102</td>\r\n<td style=\"text-align: left;\">云天励飞</td>\r\n<td style=\"text-align: left;\">天书</td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">103</td>\r\n<td style=\"text-align: left;\">乐言科技</td>\r\n<td style=\"text-align: left;\">乐言</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">104</td>\r\n<td style=\"text-align: left;\">沪渝人工智能研究院</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/RtcdWGrfIW5unyvxVplCSg\">兆言</a></td>\r\n<td style=\"text-align: left;\">重庆</td>\r\n<td style=\"text-align: left;\">科研</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">也称：上海交通大学重庆人工智能研究院</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">105</td>\r\n<td style=\"text-align: left;\">中央广播电视总台</td>\r\n<td style=\"text-align: left;\">央视听</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">央视听媒体大模型CMG Media GPT</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">106</td>\r\n<td style=\"text-align: left;\">超对称技术公司</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://bbt.ssymmetry.com/\">乾元</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">107</td>\r\n<td style=\"text-align: left;\">蜜度</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/aHSw9Kxib3Zj84qDGn3Dyg\">文修</a></td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">智能校对</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">108</td>\r\n<td style=\"text-align: left;\">中国电子云</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/qNoTD4BY2DX5ziSe1ZPSLw\">星智</a></td>\r\n<td style=\"text-align: left;\">湖北武汉</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">政务大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">109</td>\r\n<td style=\"text-align: left;\">理想汽车</td>\r\n<td style=\"text-align: left;\">MindGPT</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">110</td>\r\n<td style=\"text-align: left;\">阅文集团</td>\r\n<td style=\"text-align: left;\">妙笔</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">文旅</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">网文大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">111</td>\r\n<td style=\"text-align: left;\">携程</td>\r\n<td style=\"text-align: left;\">问道</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">文旅</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">旅游行业大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">112</td>\r\n<td style=\"text-align: left;\">实在智能</td>\r\n<td style=\"text-align: left;\">塔斯</td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">TARS</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">113</td>\r\n<td style=\"text-align: left;\">瑞泊</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"http://xraybot.com/col.jsp?id=103\">VIDYA</a></td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">114</td>\r\n<td style=\"text-align: left;\">有连云</td>\r\n<td style=\"text-align: left;\">麒麟</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">115</td>\r\n<td style=\"text-align: left;\">维智科技</td>\r\n<td style=\"text-align: left;\">CityGPT</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">公共服务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">城市大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">116</td>\r\n<td style=\"text-align: left;\">用友</td>\r\n<td style=\"text-align: left;\">YonGPT</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">企业服务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">117</td>\r\n<td style=\"text-align: left;\">天云数据</td>\r\n<td style=\"text-align: left;\">Elpis</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">证券法律法规</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">118</td>\r\n<td style=\"text-align: left;\">孩子王</td>\r\n<td style=\"text-align: left;\">KidsGPT</td>\r\n<td style=\"text-align: left;\">江苏南京</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">119</td>\r\n<td style=\"text-align: left;\">企查查</td>\r\n<td style=\"text-align: left;\">知彼阿尔法</td>\r\n<td style=\"text-align: left;\">江苏苏州</td>\r\n<td style=\"text-align: left;\">商业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">120</td>\r\n<td style=\"text-align: left;\">今立方</td>\r\n<td style=\"text-align: left;\">12333</td>\r\n<td style=\"text-align: left;\">福建厦门</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">人社领域</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">121</td>\r\n<td style=\"text-align: left;\">阳光保险集团</td>\r\n<td style=\"text-align: left;\">正言</td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">122</td>\r\n<td style=\"text-align: left;\">中科创达</td>\r\n<td style=\"text-align: left;\">魔方Rubik</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">123</td>\r\n<td style=\"text-align: left;\">聆心智能</td>\r\n<td style=\"text-align: left;\">CharacterGLM</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">游戏</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">124</td>\r\n<td style=\"text-align: left;\">大经中医</td>\r\n<td style=\"text-align: left;\">岐黄问道</td>\r\n<td style=\"text-align: left;\">江苏南京</td>\r\n<td style=\"text-align: left;\">医疗</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">125</td>\r\n<td style=\"text-align: left;\">蒙牛</td>\r\n<td style=\"text-align: left;\">MENGNIU.GPT</td>\r\n<td style=\"text-align: left;\">内蒙古呼和浩特</td>\r\n<td style=\"text-align: left;\">食品</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">126</td>\r\n<td style=\"text-align: left;\">快商通</td>\r\n<td style=\"text-align: left;\">汉朝</td>\r\n<td style=\"text-align: left;\">福建厦门</td>\r\n<td style=\"text-align: left;\">营销</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">127</td>\r\n<td style=\"text-align: left;\">众合科技</td>\r\n<td style=\"text-align: left;\">UniChat</td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">交通</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">128</td>\r\n<td style=\"text-align: left;\">金蝶</td>\r\n<td style=\"text-align: left;\">苍穹</td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">企业服务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">129</td>\r\n<td style=\"text-align: left;\">云问科技</td>\r\n<td style=\"text-align: left;\">云中问道</td>\r\n<td style=\"text-align: left;\">江苏南京</td>\r\n<td style=\"text-align: left;\">营销</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">与西安未来AI计算中心联合发布</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">130</td>\r\n<td style=\"text-align: left;\">天壤智能</td>\r\n<td style=\"text-align: left;\">小白</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">131</td>\r\n<td style=\"text-align: left;\">小米</td>\r\n<td style=\"text-align: left;\">MiLM-6B</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">商业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">132</td>\r\n<td style=\"text-align: left;\">长虹</td>\r\n<td style=\"text-align: left;\">长虹超脑</td>\r\n<td style=\"text-align: left;\">四川绵阳</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">133</td>\r\n<td style=\"text-align: left;\">开普云</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.kaipuyun.cn/kp/c100630/kaiwu.shtml\">开悟</a></td>\r\n<td style=\"text-align: left;\">广东东莞</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✔</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">134</td>\r\n<td style=\"text-align: left;\">赛灵力科技</td>\r\n<td style=\"text-align: left;\">达尔文</td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">医学</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">赛灵力,清华珠三角研究院,赛业生物,大湾区科技创新服务中心</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">135</td>\r\n<td style=\"text-align: left;\">航旅纵横</td>\r\n<td style=\"text-align: left;\">千穰大模型</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">民航</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">航旅纵横APP上需要PLUS会员才能使用</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">136</td>\r\n<td style=\"text-align: left;\">奇安信</td>\r\n<td style=\"text-align: left;\">Q-GPT</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">信息安全</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">137</td>\r\n<td style=\"text-align: left;\">车之谷</td>\r\n<td style=\"text-align: left;\">叆谷</td>\r\n<td style=\"text-align: left;\">山东青岛</td>\r\n<td style=\"text-align: left;\">汽车</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">汽车后服务加油站场景</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">138</td>\r\n<td style=\"text-align: left;\">索贝时代</td>\r\n<td style=\"text-align: left;\">明眸</td>\r\n<td style=\"text-align: left;\">四川成都</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">139</td>\r\n<td style=\"text-align: left;\">海尔</td>\r\n<td style=\"text-align: left;\">HomeGPT</td>\r\n<td style=\"text-align: left;\">山东青岛</td>\r\n<td style=\"text-align: left;\">智能家居</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">140</td>\r\n<td style=\"text-align: left;\">马上消费</td>\r\n<td style=\"text-align: left;\">天镜</td>\r\n<td style=\"text-align: left;\">重庆</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">零售金融</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">141</td>\r\n<td style=\"text-align: left;\">白海科技</td>\r\n<td style=\"text-align: left;\">白聚易</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">营销</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">营销传播专家多模态预训练模型IMC-GPT（白聚易）</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">142</td>\r\n<td style=\"text-align: left;\">二元工业</td>\r\n<td style=\"text-align: left;\">妆舟</td>\r\n<td style=\"text-align: left;\">江苏苏州</td>\r\n<td style=\"text-align: left;\">日化</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">回答化妆、护肤和服饰搭配等问题，日化行业从业人员提供从产品开发、行业服务到品牌建设等指导</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">143</td>\r\n<td style=\"text-align: left;\">格创东智</td>\r\n<td style=\"text-align: left;\">章鱼智脑</td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">工业制造</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">工业智能大模型引擎底座——章鱼智脑OctopusGPT</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">144</td>\r\n<td style=\"text-align: left;\">创业邦</td>\r\n<td style=\"text-align: left;\">BangChat</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">创投</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">产业、企业和投资行业</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">145</td>\r\n<td style=\"text-align: left;\">新华三H3C</td>\r\n<td style=\"text-align: left;\">百业灵犀</td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">146</td>\r\n<td style=\"text-align: left;\">作业帮</td>\r\n<td style=\"text-align: left;\">银河</td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">147</td>\r\n<td style=\"text-align: left;\">电科数字</td>\r\n<td style=\"text-align: left;\">智弈</td>\r\n<td style=\"text-align: left;\">上海</td>\r\n<td style=\"text-align: left;\">水利</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">148</td>\r\n<td style=\"text-align: left;\">绿盟</td>\r\n<td style=\"text-align: left;\">风云卫</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">网络安全</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">NSFGPT</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">149</td>\r\n<td style=\"text-align: left;\">江苏欧软</td>\r\n<td style=\"text-align: left;\">WISE</td>\r\n<td style=\"text-align: left;\">江苏苏州</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">WISE工业大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">150</td>\r\n<td style=\"text-align: left;\">创新奇智</td>\r\n<td style=\"text-align: left;\">奇智孔明</td>\r\n<td style=\"text-align: left;\">山东青岛</td>\r\n<td style=\"text-align: left;\">工业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">工业大模型AInno-15B，ChatRobot，ChatBI，ChatDoc</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">151</td>\r\n<td style=\"text-align: left;\">大汉软件</td>\r\n<td style=\"text-align: left;\">星汉</td>\r\n<td style=\"text-align: left;\">江苏南京</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">“星汉”Galaxy大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">152</td>\r\n<td style=\"text-align: left;\">零点有数</td>\r\n<td style=\"text-align: left;\">零点楷模</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">政务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">153</td>\r\n<td style=\"text-align: left;\">国农生猪大数据中心</td>\r\n<td style=\"text-align: left;\">PIGGPT</td>\r\n<td style=\"text-align: left;\">重庆</td>\r\n<td style=\"text-align: left;\">农业</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">154</td>\r\n<td style=\"text-align: left;\">微脉</td>\r\n<td style=\"text-align: left;\">CareGPT</td>\r\n<td style=\"text-align: left;\">浙江杭州</td>\r\n<td style=\"text-align: left;\">医疗</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">155</td>\r\n<td style=\"text-align: left;\">吉大正元</td>\r\n<td style=\"text-align: left;\">昆仑</td>\r\n<td style=\"text-align: left;\">吉林长春</td>\r\n<td style=\"text-align: left;\">信息安全</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">156</td>\r\n<td style=\"text-align: left;\">武汉大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.ithome.com/0/695/295.htm\">CheeseChat</a></td>\r\n<td style=\"text-align: left;\">湖北武汉</td>\r\n<td style=\"text-align: left;\">教育</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">内测招募，仅限武汉大学在校师生申请</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">157</td>\r\n<td style=\"text-align: left;\">方正电子</td>\r\n<td style=\"text-align: left;\">魔方</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">聚焦媒体市场需求</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">158</td>\r\n<td style=\"text-align: left;\">似然实验室</td>\r\n<td style=\"text-align: left;\">TraderGPT</td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">金融</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">金融持仓分析大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">159</td>\r\n<td style=\"text-align: left;\">网易智企</td>\r\n<td style=\"text-align: left;\">商河</td>\r\n<td style=\"text-align: left;\">广东广州</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">客服领域行业大模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">160</td>\r\n<td style=\"text-align: left;\">深圳供电局</td>\r\n<td style=\"text-align: left;\">祝融2.0</td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">电力</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">电力行业首个多模态预训练大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">161</td>\r\n<td style=\"text-align: left;\">万兴科技</td>\r\n<td style=\"text-align: left;\">天幕</td>\r\n<td style=\"text-align: left;\">西藏拉萨</td>\r\n<td style=\"text-align: left;\">媒体</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">以视频创意应用为核心</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">162</td>\r\n<td style=\"text-align: left;\">惟远智能</td>\r\n<td style=\"text-align: left;\">千机百智</td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">客服</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">163</td>\r\n<td style=\"text-align: left;\">兔展智能</td>\r\n<td style=\"text-align: left;\">兔灵</td>\r\n<td style=\"text-align: left;\">广东深圳</td>\r\n<td style=\"text-align: left;\">营销</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">164</td>\r\n<td style=\"text-align: left;\">中国科学技术大学</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://arxiv.org/pdf/2308.11592.pdf\">UniDoc</a></td>\r\n<td style=\"text-align: left;\">安徽合肥</td>\r\n<td style=\"text-align: left;\">通用</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">中科大&amp;字节,统一的文字-图像理解大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">165</td>\r\n<td style=\"text-align: left;\">钢谷网</td>\r\n<td style=\"text-align: left;\">谷蚁</td>\r\n<td style=\"text-align: left;\">陕西西安</td>\r\n<td style=\"text-align: left;\">电商</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\">钢铁行业电商</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">166</td>\r\n<td style=\"text-align: left;\">浪潮海岳</td>\r\n<td style=\"text-align: left;\">inGPT</td>\r\n<td style=\"text-align: left;\">山东济南</td>\r\n<td style=\"text-align: left;\">企业服务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">167</td>\r\n<td style=\"text-align: left;\">木卫四科技</td>\r\n<td style=\"text-align: left;\">蝴蝶</td>\r\n<td style=\"text-align: left;\">北京</td>\r\n<td style=\"text-align: left;\">汽车</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">168</td>\r\n<td style=\"text-align: left;\">汇通达网络</td>\r\n<td style=\"text-align: left;\">汇通达</td>\r\n<td style=\"text-align: left;\">江苏南京</td>\r\n<td style=\"text-align: left;\">企业服务</td>\r\n<td style=\"text-align: left;\">✘</td>\r\n<td\r\nstyle=\"text-align: left;\">下沉市场零售行业企业客户的交易和服务的互联网平台,农村电商服务</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"国外大模型\">国外大模型</h2>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 14%\" />\r\n<col style=\"width: 56%\" />\r\n<col style=\"width: 29%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th style=\"text-align: left;\">公司</th>\r\n<th style=\"text-align: left;\">大模型</th>\r\n<th style=\"text-align: left;\">说明</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">OpenAI</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://chat.openai.com/chat\">ChatGPT</a></td>\r\n<td style=\"text-align: left;\">ChatGPT-4支持Plugins，Code\r\nInterpreter</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">微软</td>\r\n<td style=\"text-align: left;\"><a href=\"https://bing.com/chat\">Bing\r\nChat</a></td>\r\n<td style=\"text-align: left;\">搜索增强，有三种模式</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">Google</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://ai.google/discover/palm2\">PaLM2</a>,<a\r\nhref=\"https://bard.google.com/\">Bard</a>,<a\r\nhref=\"https://mp.weixin.qq.com/s/IpDC3qv0xHhZAY5JgRKlvg\">Gemini</a></td>\r\n<td style=\"text-align: left;\">Bard支持图片内容识别，包括OCR等</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">Anthropic</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://claude.ai/\">Claude</a></td>\r\n<td style=\"text-align: left;\">Claude\r\n2,支持读入pdf、txt、csv等文件进行分析、总结和问答等</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">Meta</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/facebookresearch/llama\">LLaMA</a>,<a\r\nhref=\"https://huggingface.co/meta-llama\">LLaMA-2</a>, CodeLLaMA</td>\r\n<td\r\nstyle=\"text-align: left;\">最强开源开放大模型，月活用户小于7亿的组织和个人可随意商用</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">Stability AI</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://github.com/Stability-AI/StableLM\">StableLM</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">Amazon</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://aws.amazon.com/cn/bedrock/titan/\">Titan</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">Bloomberg</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/\">BloombergGPT</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">MosaicML</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://www.mosaicml.com/blog/mpt-7b\">MPT</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">Intel</td>\r\n<td style=\"text-align: left;\">Aurora genAI</td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">UC Berkeley, Microsoft Research</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://gorilla.cs.berkeley.edu/\">Gorilla</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">inflection.ai</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://inflection.ai/inflection-1\">Inflection-1</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">xAI</td>\r\n<td style=\"text-align: left;\"></td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://mp.weixin.qq.com/s/SJvuRIPG8K0Hg15gbqCN4w\">从OpenAI\r\n到xAI</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">cohere</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://cohere.com/\">Cohere</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">Scale AI</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://scale.com/\">Scale</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: left;\">character ai</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://beta.character.ai/\">Character</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: left;\">Colossal-AI</td>\r\n<td style=\"text-align: left;\"><a\r\nhref=\"https://chat.colossalai.org/\">ColossalChat</a></td>\r\n<td style=\"text-align: left;\"></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h1 id=\"三aigc视频会议访谈\">三、AIGC视频会议&amp;访谈</h1>\r\n<h2 id=\"智源社区\">智源社区</h2>\r\n<p><strong>【论文分享】</strong>【AugGPT：利用ChatGPT进行文本数据增强\r\n】[<a href=\"https://event.baai.ac.cn/activities/664\">link</a>]</p>\r\n<p><strong>【论文分享】</strong>【ChatGPT的鲁棒性探究——对抗性和分布外泛化的视角\r\n】[<a href=\"https://event.baai.ac.cn/activities/657\">link</a>]</p>\r\n<p><strong>【论文分享】</strong>【传统检索模型和大语言模型在信息搜索中的应用和对比\r\n】[<a href=\"https://event.baai.ac.cn/activities/656\">link</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2209.10063\">paper</a>]，[<a\r\nhref=\"https://github.com/wyu97/GenRead\">code</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/24380\">blog</a>]</p>\r\n<h2 id=\"访谈视频\">访谈&amp;视频</h2>\r\n<p><strong>【访谈】</strong>【OpenAI 的核心研发人员 Jack Rae 在参加\r\nStanford MLSys Seminar 的访谈时进行了一个名为 Compression for\r\nAGI的主题分享 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/hQmvltuMlClBonM6UJmtLg\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【万字长文：想训大模型？这里有一份避坑指南】[<a\r\nhref=\"https://mp.weixin.qq.com/s/yX5B1ZzV7vewQs1-ezHIQg\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【微软Bing版ChatGPT表明想做人类，并且对纽约时报专栏作家表达爱意】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485854&amp;idx=1&amp;sn=011e0ef0f2c69cd48d042495b2a47eb3&amp;chksm=ced54a7af9a2c36c29fec6301236685d443bde94681ec3f669408d953ae92bb54b686aeab9f8&amp;token=447941009&amp;lang=zh_CN#rd\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【Midjourney创始人David\r\nHolz关于生成式AI的访谈】[<a\r\nhref=\"https://mp.weixin.qq.com/s/jMyuSYu8ACk2peu_OfZK0w\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【OpenAI创始人：GPT-4的研究起源和构建心法】[<a\r\nhref=\"https://mp.weixin.qq.com/s/hO1ZdqgOjpA328luobQ9eg\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【ABC News\r\n专访OpenAI首席执行官萨姆·奥尔特曼：AI风险和重塑社会的问题】[<a\r\nhref=\"%5BOpenAI%20CEO%20Sam%20Altman%20says%20AI%20will%20reshape%20society,%20acknowledges%20risks:%20&#39;A%20little%20bit%20scared%20of%20this%5D(https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122)\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【OpenAI联合创始人Ilya\r\nSutskever等专访：开源人工智能是不明智的】[<a\r\nhref=\"https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【OpenAI董事长、CTO Greg Brockman专访\r\n：GPT-4 并不完美，不过人无完人】[<a\r\nhref=\"https://techcrunch.com/2023/03/15/interview-with-openais-greg-brockman-gpt-4-isnt-perfect-but-neither-are-you/\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【图灵奖获得者 Yoshua Bengio 认为 ChatGPT\r\n是一个“警钟”】[<a\r\nhref=\"https://mp.weixin.qq.com/s/2-QoJHKWxiS63vEjX9OOGQ\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【《麻省理工科技评论》对 ChatGPT\r\n幕后团队，进行了一次深入的独家专访】[<a\r\nhref=\"https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【口述历史，探析ChatGPT的创造历程，ChatGPT内部故事】[<a\r\nhref=\"https://mp.weixin.qq.com/s/RAdIxzdgs3elUiozB8cH8g\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【对话ChatGPT之父！AI会改变什么？不会改变什么？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zNuOmVeVKP335iJ4RNJqNw\">访谈记录</a>]</p>\r\n<p><strong>【访谈】</strong>【对话OpenAI研究科学家：他们是如何让GPT4更像人的？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iJImioHXxelCxUsETSxuXw\">访谈记录</a>]</p>\r\n<p><strong>【视频】</strong>【邱锡鹏教授介绍以ChatGPT为核心的大规模语言模型的相关知识及未来的发展方向\r\n】[<a href=\"https://www.bilibili.com/video/BV1Xb411X7c3/\">B站</a>]</p>\r\n<h2 id=\"llm体验效果专业评估\">LLM体验效果&amp;专业评估</h2>\r\n<p><strong>【LLM效果对比】</strong>【360智脑_VS_讯飞星火】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486609&amp;idx=2&amp;sn=7fedb8ab37588d43968fdec2d7e5fcdd&amp;chksm=ced54f75f9a2c663b9a2671f2548e2940730735605356cc0ffe72bc737470136a40032c80bfe&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【阿里通义千问_VS_讯飞星火】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486534&amp;idx=1&amp;sn=6f36d41b618790cba62e63eb25bb033b&amp;chksm=ced54fa2f9a2c6b4a901528f87a7e74628dfd79d835f4cdea1ee4dea442f339adfd2736b2305&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【Bard_VS_Baize-7B_VS_文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486317&amp;idx=1&amp;sn=ea3cc745d2991b8c657325392ce68f71&amp;chksm=ced54889f9a2c19f3c2f85d8d7af7fff366027f79d1f4a5b2c650fea1b5dee9efde0b7c992ca&amp;token=1173964254&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【Bard_VS_Bing_VS_ChatGPT】[<a\r\nhref=\"https://www.theverge.com/2023/3/24/23653377/ai-chatbots-comparison-bard-bing-chatgpt-gpt-4\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【Bard_VS_文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486260&amp;idx=1&amp;sn=a41224fee7ed4cb4a48eb40a420d7479&amp;chksm=ced548d0f9a2c1c6f4930f30447468f9f01bb2af6031368e302b13a6354fc4bca6636e3b297e&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【ChatGPT_VS_GPT4】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485952&amp;idx=2&amp;sn=e54a62e358bf7aee3c007d59600fd452&amp;chksm=ced549e4f9a2c0f2868eb8877c14fbe287a469e63b09774cefcb9edc4c0601016f6d36561973&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【OpenAssistant_VS_百度文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486413&amp;idx=2&amp;sn=3816e5a4bccceee5e2af868166b18897&amp;chksm=ced54829f9a2c13fb787b7a7e3c2aa0799eb7ff6d124f6847349346146900e05684ceb8cc7f7&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言新闻发布会内容复现】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486081&amp;idx=1&amp;sn=034480a8b00778cb6a4f2b5ea4214974&amp;chksm=ced54965f9a2c0733ff09fbff4953da484180f48545da3d9b476f1e7375c162f9e8d4eaa0afd&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言_VS_ChatGLM-6B】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486081&amp;idx=2&amp;sn=fd87305419158d66dd4b05b57bee1324&amp;chksm=ced54965f9a2c073ba1badfedbc6610036455cd769a3c8ee3445f7fbff9364b5624091be9914&amp;token=666852558&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言 VS GPT-4：20道问答PK】[<a\r\nhref=\"https://mp.weixin.qq.com/s/l1pTPlohMmiYEMc4x6QKhw\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【文心一言 vs GPT-4实测！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/uO8N3RpcrYU8rV1RkwBxzQ\">blog</a>]</p>\r\n<p><strong>【LLM效果对比】</strong>【讯飞星火_VS_文心一言】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486490&amp;idx=1&amp;sn=c8d756f7f26a4e35f8b67ae485efabce&amp;chksm=ced54ffef9a2c6e8d66f8b744d6af524e320d5aec384d142621cee53fd2150f2c7db1fa7596a&amp;token=1282379489&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【一文看遍各行业对ChatGPT的专业评估】[<a\r\nhref=\"https://mp.weixin.qq.com/s/2JryWW33j9udOpi3dK5X9g\">blog</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【ChatGPT关于推理、幻觉和交互的多任务、多语言、多通道评估\r\n】[<a href=\"https://arxiv.org/abs/2302.04023\">paper</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【如何评价 OpenAI 的超级对话模型\r\nChatGPT ？】[<a\r\nhref=\"https://www.zhihu.com/question/570189639\">paper</a>]</p>\r\n<p><strong>【ChatGPT专业评估】</strong>【用ChatGPT参加计算机科学考试】[<a\r\nhref=\"https://arxiv.org/abs/2303.09461\">paper</a>]</p>\r\n<p><strong>【LLM知识评估】</strong>【C-Eval：构造中文大模型的知识评估基准】[<a\r\nhref=\"https://cevalbenchmark.com/\">主页</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/4560jl7ctWmHz3xGVIKkRw\">paper</a>]，[<a\r\nhref=\"https://github.com/SJTU-LIT/ceval\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/4560jl7ctWmHz3xGVIKkRw\">blog</a>]</p>\r\n<p><strong>【MLLM幻觉评估】</strong>【多模态大模型的幻觉问题与评估】[<a\r\nhref=\"https://mp.weixin.qq.com/s/s0z-mAyjAaqvNcaTg2VFEA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2305.10355\">paper</a>]，[<a\r\nhref=\"https://github.com/RUCAIBox/POPE\">code</a>]</p>\r\n<p><strong>【各大大模型评测】</strong>【粗看大模型ChatGLM、MOSS、Bloomz在中文垂域评测中的性能表现：医学、法律、心理学、教育等四大类试题下的测试报告介绍】[<a\r\nhref=\"https://arxiv.org/pdf/2304.12986.pdf\">paper</a>]，[<a\r\nhref=\"github.com/Felixgithub2017/MMCU\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Hq6bn_4vD559TMQxx806tg\">blog</a>]</p>\r\n<p><strong>【国内大模型评测】</strong>【评测国内各种对标 ChatGPT\r\n的大语言模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Oe1Rc0kXjMOD2G_Sqambow\">blog</a>]，[<a\r\nhref=\"https://github.com/dongrixinyu/JioNLP/wiki/LLM%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86\">code</a>]</p>\r\n<p><strong>【大模型排行榜】</strong>【OpenLLM大模型排行榜】[<a\r\nhref=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\">主页</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/t1Th8iFOGoyuqqysUiIcXQ\">blog</a>]，[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/642996275\">最新进展blog</a>]</p>\r\n<p><strong>【大模型排行榜】</strong>【斯坦福发布LLM排行榜AlpacaEval，微软WizardLM登顶开源模型第一】[<a\r\nhref=\"https://mp.weixin.qq.com/s/7X8pRaexWJ4c0kVswawU1A\">blog</a>]，[<a\r\nhref=\"https://tatsu-lab.github.io/alpaca_eval\">主页</a>]，[<a\r\nhref=\"https://github.com/tatsu-lab/alpaca_eval\">code</a>]</p>\r\n<h2 id=\"llm垂直领域大模型\">LLM垂直领域大模型</h2>\r\n<h3 id=\"法律\">法律</h3>\r\n<p>【再看基于LLaMA的最新微调模型变体：CaMA、ExpertLLaMA以及第四个中文法律微调模型LexiLaw】[<a\r\nhref=\"https://mp.weixin.qq.com/s/FYWmMH2ndN5XfWvwI9dcUA\">blog</a>]</p>\r\n<p>【基于中文法律知识的大语言模型——LaWGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s/dI839IF0hdBTAfOBUg7Pfw\">blog</a>]</p>\r\n<h3 id=\"医疗\">医疗</h3>\r\n<p>【AD-AutoGPT：用于阿尔茨海默病信息流行病学的自主GPT】[<a\r\nhref=\"https://arxiv.org/abs/2306.10095\">paper</a>]</p>\r\n<p>【MedQA-ChatGLM - 基于真实医疗对话数据在ChatGLM上进行微调】[<a\r\nhref=\"http://github.com/WangRongsheng/MedQA-ChatGLM\">code</a>]，[<a\r\nhref=\"https://www.wangrs.co/MedQA-ChatGLM/\">主页</a>]</p>\r\n<p>【谷歌医疗大模型登Nature，Med-PaLM重磅揭秘！AI医生成绩比肩人类】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Qf4Ts7UKJNzkW1Tfy-b0Zg\">blog</a>]，[<a\r\nhref=\"https://www.nature.com/articles/s41586-023-06291-2\">paper</a>]</p>\r\n<p>【PULSE：中文医疗大语言模型】[<a\r\nhref=\"https://huggingface.co/OpenMEDLab/PULSE-7bv5\">code</a>]</p>\r\n<h3 id=\"金融\">金融</h3>\r\n<p>【FinGPT：一个「专用于金融领域」的开源大语言模型（LLM）框架，源码公开！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/A9euFin675nxGGciiX6rJQ\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2306.06031v1.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/ai4finance-foundation/fingpt\">code</a>]</p>\r\n<h3 id=\"环境\">环境</h3>\r\n<p>【清华&amp;中国气象局大模型登Nature：预报时效首次达3小时】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Aygm03CdA0zFNf9F3_JU5A\">blog</a>]，[<a\r\nhref=\"https://www.nature.com/articles/s41586-023-06184-4\">paper</a>]</p>\r\n<h3 id=\"网络安全\">网络安全</h3>\r\n<p>【专用于网络攻击的模型FraudGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s/OtLNybsbxDlbVb-cs4Zk8g\">blog</a>]</p>\r\n<h3 id=\"交通\">交通</h3>\r\n<p>【北交大开源交通大模型TransGPT·致远，可免费商用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/WvzyjHqI0lOGIyPlCIFNQg\">blog</a>]，[<a\r\nhref=\"https://github.com/DUOMO/TransGPT\">code</a>]</p>\r\n<h3 id=\"其他\">其他</h3>\r\n<p>【南洋理工开源海外中文大语言模型Panda LLM |\r\n探索数据因素和训练策略如何影响大模型性能表现】[<a\r\nhref=\"https://arxiv.org/pdf/2305.03025v1.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/dandelionsllm/pandallm\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/IsWSPAvwgT263wjO7TYTZQ\">blog</a>]</p>\r\n<h2 id=\"llm文本检测\">LLM文本检测</h2>\r\n<p><strong>【论文&amp;代码】</strong>【美国麻省大学&amp;谷歌研究院：改写文本可以避开AI生成文本的检测器，但检索则是一种有效的防御】[<a\r\nhref=\"https://papers.labml.ai/api/v1/redirect/pdf?paper_key=2cfe8cecc9f211edb95839eec3084ddd\">paper</a>]，[<a\r\nhref=\"https://github.com/martiansideofthemoon/ai-detection-paraphrases\">code</a>]</p>\r\n<p><strong>【论文】</strong>【人工智能生成的文本能被可靠地检测出来吗？】[<a\r\nhref=\"https://arxiv.org/pdf/2303.11156.pdf\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486128&amp;idx=3&amp;sn=e5ea32b7d7cb4c8c41f29a9ea15ac3ac&amp;chksm=ced54954f9a2c0425a65761f1766550f6b90857da0106f6fd55f3c6773fbdbd1fc45bbb9369a&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【DetectGPT（斯坦福大学）：利用概率曲率检测文本是否大模型生成】[<a\r\nhref=\"https://arxiv.org/abs/2301.11305\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485713&amp;idx=2&amp;sn=805caf25603cf15dbf71949f85b9d041&amp;chksm=ced54af5f9a2c3e3e0dffd728592fd7ab8f738869e94240daba4fad9f6ac90a2f76a6b458e3f&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://ericmitchell.ai/detectgpt/\">code&amp;data</a>]</p>\r\n<p><strong>【论文】</strong>【Detecting LLM-Generated-Text综述】[<a\r\nhref=\"https://github.com/datamllab/The-Science-of-LLM-generated-Text-Detection\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485747&amp;idx=1&amp;sn=5e5029a70c54c08f6f8c40631962b1e1&amp;chksm=ced54ad7f9a2c3c184ccb123199510bb09470e054fb5cb887e70bac204927b65e296f8921db1&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【一个专为<strong>教育</strong>者打造的全新\r\nAI 检测模型】[<a\r\nhref=\"https://gptzero.substack.com/p/gptzerox\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【OpenAI重磅发布官方「ChatGPT检测器」】[<a\r\nhref=\"https://mp.weixin.qq.com/s/EcZE7TgHspf22rPRWhAybw\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【斯坦福最新研究：不要过度依赖GPT生成内容，其检测器可能存在不利于非母语英语写作者的偏见】[<a\r\nhref=\"https://arxiv.org/abs/2304.02819\">paper</a>]</p>\r\n<h2 id=\"llm长文本解决方案\">LLM长文本解决方案</h2>\r\n<p><strong>【苏剑林】</strong>【Transformer升级之路：一种全局长度外推的新思路】[<a\r\nhref=\"https://mp.weixin.qq.com/s/YJ647EUfzWaJsGoMdgsguA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT能写长篇小说了，ETH提出RecurrentGPT实现交互式超长文本生成】[<a\r\nhref=\"https://arxiv.org/abs/2305.13304\">paper</a>]，[<a\r\nhref=\"https://github.com/aiwaves-cn/RecurrentGPT\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/5UVTwSWgoz7uhozMeps3EQ\">blog</a>]，[<a\r\nhref=\"https://www.aiwaves.org/recurrentgpt\"\r\ntitle=\"长篇小说写作\">demo1</a>]，[<a\r\nhref=\"https://www.aiwaves.org/interactivefiction\"\r\ntitle=\"交互式小说\">demo2</a>]</p>\r\n<p><strong>【博客】</strong>【语言大模型100K上下文窗口的秘诀】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_i0eQgYNSLJydv3qOTqr-Q\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【RoPE可能是LLM时代的Resnet】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BVm1XC7r1yzOiWIrEbWg3A\">blog</a>]</p>\r\n<h2 id=\"llm可控性与安全\">LLM可控性与安全</h2>\r\n<p><strong>【可控性】</strong>【微软提出Control-GPT：用GPT-4实现可控文本到图像生成！】[<a\r\nhref=\"https://arxiv.org/abs/2305.18583\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/U3eWeGOEt9nhW-Xwbuah9w\">blog</a>]</p>\r\n<p><strong>【可控性】</strong>【AIGC如何安全可控?中山大学等最新《AIGC中对隐私和安全的挑战及其补救措施：探索隐私计算、区块链潜在应用》全面阐述】[<a\r\nhref=\"https://www.zhuanzhi.ai/paper/0dd95e1d5aae9eb2e60aabf36a107482\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/V8QjMQSO2tX6PFx_LfLIEA\">blog</a>]</p>\r\n<p><strong>【可控性】</strong>【ControlVideo:\r\n可控的Training-free的文本生成视频】[<a\r\nhref=\"https://mp.weixin.qq.com/s/CAH6u-MT3cFM359d5_Xpxg\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2305.13077.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/YBYBZhang/ControlVideo\">code</a>]</p>\r\n<p><strong>【安全】</strong>【大模型切脑后变身PoisonGPT，虚假信息案例】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27736\">blog</a>]，[<a\r\nhref=\"https://colab.research.google.com/drive/16RPph6SobDLhisNzA5azcP-0uMGGq10R?usp=sharing&amp;ref=blog.mithrilsecurity.io\">code</a>]</p>\r\n<p><strong>【安全】</strong>【ChatGPT羊驼家族全沦陷！CMU博士击破LLM护栏，人类毁灭计划脱口而出】[<a\r\nhref=\"https://mp.weixin.qq.com/s/298nwP98UdRNybV2Fuo6Wg\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2307.15043\">paper</a>]，[<a\r\nhref=\"https://github.com/llm-attacks/llm-attacks\">code</a>]</p>\r\n<h2 id=\"llm训练微调优化以及部署\">LLM训练、微调、优化以及部署</h2>\r\n<p><strong>【LLM学习网站】</strong>【训练、微调、优化和部署大模型最新技术LLM\r\nLearning Lab】[<a\r\nhref=\"https://lightning.ai/pages/llm-learning-lab/\">官网</a>]</p>\r\n<h3 id=\"llm训练\">LLM训练</h3>\r\n<p><strong>【LLM训练】</strong>【DeepSpeed的Tutorials】[<a\r\nhref=\"https://www.deepspeed.ai\">主页</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/xpNQtl7hPs3fy9S7VRbIkg\">DeepSpeed\r\nGetting Starte</a>]</p>\r\n<p><strong>【LLM训练】</strong>【如何使用 Megatron-LM 训练语言模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/QPg6gOWGbQDezTl8OFZU3g\">blog</a>]</p>\r\n<p><strong>【LLM训练】</strong>【Muti Query Attention 和 Attention with\r\nLinear Bias（附源码）】[<a\r\nhref=\"https://mp.weixin.qq.com/s/GXMwnbWLce9Aq4alEHCHJA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/1911.02150.pdf\">paper</a>]</p>\r\n<h3 id=\"llm微调\">LLM微调</h3>\r\n<p><strong>【LLM微调】</strong>【PEFT:\r\n在低资源硬件上对十亿规模模型进行参数高效微调 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/x2mQBE0pfTv8w3Czp8JkDg\">blog</a>]</p>\r\n<p><strong>【LLM微调】</strong>【大语言模型（LLM）微调技术笔记】[<a\r\nhref=\"https://github.com/ninehills/ninehills.github.io/issues/92\">code</a>]</p>\r\n<p><strong>【LLM微调】</strong>【大模型LLM-微调经验分享&amp;总结】[<a\r\nhref=\"https://github.com/liucongg/ChatGLM-Finetuning\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/pkBvL0k7sZWaW6jMlSSIZA\">blog</a>]</p>\r\n<p><strong>【LLM微调】</strong>【LoRA：卷完图像生成领域，卷文本生成领域的东西，到时是个啥？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/emLpTAOhr8khO1hTgQhU9w\">blog</a>]，[<a\r\nhref=\"https://github.com/microsoft/LoRA\">code</a>]</p>\r\n<p><strong>【LLM微调】</strong>【Washington大学2023年5月新提出一种高效的微调方法QLoRA，通过降低显存使用，实现在单个48GB\r\nGPU上对65B参数的大模型进行微调，只需微调12个小时就可以达到97%的ChatGPT水平。同时只用int4就可以保持fp16精度的效果。】[<a\r\nhref=\"https://arxiv.org/pdf/2305.14314.pdf\">paper</a>]</p>\r\n<p><strong>【LLM微调】</strong>【华盛顿大学提出全新量化和微调方法，在DB-GPT上享受33B参数的LLM】[<a\r\nhref=\"https://mp.weixin.qq.com/s/A3flqm2FeOn0WQr5mrD1-Q\">blog</a>]</p>\r\n<p><strong>【LLM微调】</strong>【陈丹琦团队提出低内存高效零阶优化器MeZO，单卡A100可训练300亿参数模型】[<a\r\nhref=\"https://arxiv.org/abs/2305.17333\">paper</a>]，[<a\r\nhref=\"https://github.com/princeton-nlp/MeZO\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/JteUpY4fEbENQFvReRLPJg\">blog</a>]</p>\r\n<h3 id=\"llm优化\">LLM优化</h3>\r\n<p><strong>【LLM优化】</strong>【LLM，压缩即泛化，泛化即智能】[<a\r\nhref=\"https://mp.weixin.qq.com/s/tSj9npIPg8IlYr2jbtg-Og\">blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【LLM-Pruner: 剪枝+少量数据+少量训练 =\r\n高效的LLM压缩】[<a\r\nhref=\"https://mp.weixin.qq.com/s/feqFfy4n31eztoZfodMieQ\">blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【邱锡鹏团队提出新优化器LOMO｜650亿参数，8块GPU全参数微调】[<a\r\nhref=\"https://mp.weixin.qq.com/s/339iXf2bimusfq6zQmFpWw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2306.09782\">paper</a>]</p>\r\n<p><strong>【LLM优化】</strong>【伯克利开源LLM推理与服务库：GPU减半、吞吐数十倍猛增】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27505\">中文blog</a>]，[<a\r\nhref=\"https://vllm.ai/?continueFlag=24b2e01413fd53e24a2779b4a664ca16\">英文blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【LLM\r\nAccelerator：使用参考文本无损加速大语言模型推理】[<a\r\nhref=\"https://mp.weixin.qq.com/s/H1JaQZ9-m2gkZaIwzJTTtg\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2304.04487.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/microsoft/LMOps\">code</a>]</p>\r\n<p><strong>【LLM优化】</strong>【大模型推理性能优化之KV Cache解读】[<a\r\nhref=\"https://mp.weixin.qq.com/s/ydjcUOF9iUM581hUTSXPdw\">blog</a>]</p>\r\n<p><strong>【LLM优化】</strong>【CAME：大模型训练成本降低近一半】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iUXu_Pfsop0bq7ktoXTY4A\">blog</a>]</p>\r\n<h3 id=\"llm部署\">LLM部署</h3>\r\n<p><strong>【LLM部署】</strong>【工程实践！以LLAMA为例的大模型部署方案】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zGkkekFqKsnM66uQwfUPcw\">blog</a>]</p>\r\n<p><strong>【LLM部署】</strong>【大模型部署框架FastLLM解析，支持X86/Arm/CUDA\r\n3种架构的硬件！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/j19QdlFvblcABXzB7Vi5wg\">blog</a>]，[<a\r\nhref=\"https://github.com/ztxz16/fastllm\">code</a>]</p>\r\n<h2 id=\"llm博客论文以及代码\">LLM博客、论文以及代码</h2>\r\n<p><strong>【综述】</strong>【中文大语言模型汇总：医疗、法律、金融、教育、数学微调，\r\n目前已1.1K星】[<a\r\nhref=\"https://github.com/HqWu-HITCS/Awesome-Chinese-LLM\">code</a>]</p>\r\n<p><strong>【综述】</strong>【大型语言模型综述全新出炉：从T5到GPT-4最全盘点，国内20余位研究者联合撰写】[<a\r\nhref=\"https://arxiv.org/abs/2303.18223\">paper</a>]</p>\r\n<p><strong>【综述】</strong>【大语言模型综述全新出炉：51页论文带你盘点LLM领域专业化技术】[<a\r\nhref=\"https://arxiv.org/abs/2305.18703\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/0DrowrTIgXsBhj3sYu6Aog\">blog</a>]</p>\r\n<p><strong>【综述】</strong>【AIGC综述:\r\n从GAN到ChatGPT的生成式人工智能简史】[<a\r\nhref=\"https://arxiv.org/abs/2303.04226v1\">paper</a>]</p>\r\n<p><strong>【综述】</strong>【大模型综述来了！一文带你理清全球AI巨头的大模型进化史】[<a\r\nhref=\"https://arxiv.org/pdf/2304.13712.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/Mooler0410/LLMsPracticalGuide\">code</a>]</p>\r\n<p><strong>【复旦大学】</strong>【复旦大学教授肖仰华：ChatGPT\r\n浪潮下，面向大模型如何做数据治理？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/od24PYvFLUJe4NQxjvsbMw\">blog</a>]</p>\r\n<p><strong>【谷歌】</strong>【面向决策的基础模型: 问题、方法与机会】[<a\r\nhref=\"https://arxiv.org/abs/2303.04129\">paper</a>]</p>\r\n<p><strong>【谷歌】</strong>【较大语言模型上下文学习的方式有所不同】[<a\r\nhref=\"https://arxiv.org/abs/2303.03846\">paper</a>]</p>\r\n<p><strong>【谷歌】</strong>【通用语音识别大模型已经支持100+语言】[<a\r\nhref=\"https://mp.weixin.qq.com/s/fHr2vL-w4JtYt5utcZrbsw\">blog</a>]</p>\r\n<p><strong>【谷歌】</strong>【发布5620亿参数多模态模型PaLM-E，机器人操控再上台阶】[<a\r\nhref=\"https://arxiv.org/abs/2303.03378\">paper</a>]，[<a\r\nhref=\"https://palm-e.github.io/\">blog</a>]，[<a\r\nhref=\"https://twitter.com/DannyDriess/status/1632904675124035585\">twitter</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/yZt3sEQPzVjnIvqXsNOnPA\">video</a>]</p>\r\n<p><strong>【Huawei】</strong>【PanGu-Σ:\r\n稀疏异构计算万亿参数语言模型研究参数语言模型】[<a\r\nhref=\"https://arxiv.org/abs/2303.10845\">paper</a>]</p>\r\n<p><strong>【剑桥大学】</strong>【奖励聊天机器人在现实世界中与数以百万计的用户进行互动】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06135.pdf\">paper</a>]</p>\r\n<p><strong>【LeCun】</strong>【人工智能系统最终是否需要以现实为基础，而不仅仅是从语言中学习？】[<a\r\nhref=\"https://spectrum.ieee.org/ai-hallucination\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【大型语言模型是否需要感官基础来理解意义和理解？】[<a\r\nhref=\"https://drive.google.com/file/d/1BU5bV3X5w65DwSMapKcsr0ZvrMRU_Nbi/view\">slices</a>]</p>\r\n<p><strong>【LeCun】</strong>【ChatGPT是「外星人」，所以才会胡说八道】[<a\r\nhref=\"https://www.noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&amp;utm_medium=noemasocial\">paper</a>]，[<a\r\nhref=\"https://twitter.com/ylecun/status/1633459264508542978\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【AI聊天机器人并不关注用户的社交属性】[<a\r\nhref=\"https://www.noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&amp;utm_medium=noemasocial\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【LeCun和马库斯齐喷ChatGPT：大语言模型果然是邪路？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/5e0aTSEAym9rF5QxRndLgQ\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【ChatGPT无法实现通用人工智能，但ALM技术路线也许可以】[<a\r\nhref=\"https://mp.weixin.qq.com/s/MEdl3zmiYJU1iFsTXmibng\">blog</a>]</p>\r\n<p><strong>【LeCun】</strong>【「增强语言模型」的综述 】[<a\r\nhref=\"https://arxiv.org/abs/2302.07842\">paper</a>]</p>\r\n<p><strong>【LeCun】</strong>【自回归LLM的缺陷之一，大语言模型必须知道的8个要点】[<a\r\nhref=\"https://cims.nyu.edu/~sbowman/eightthings.pdf\">paper</a>]</p>\r\n<p><strong>【MIT】</strong>【从词模型到世界模型：从自然语言到思维概率语言的转变】[<a\r\nhref=\"https://arxiv.org/abs/2306.12672\">paper</a>]</p>\r\n<p><strong>【李开复】</strong>【AI进入2.0时代，所有应用都会被重写一遍\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zV8Y9RQnIoExwa1mmarZmA\">blog</a>]</p>\r\n<p><strong>【纽约大学】</strong>【提出ILF（从语言反馈中模仿学习）：利用语言反馈大规模训练语言模型】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16755.pdf\">paper</a>]</p>\r\n<p><strong>【OpenAI】</strong>【GPT就是GPT：大模型对劳动力市场影响潜力的早期研究】[<a\r\nhref=\"https://arxiv.org/pdf/2303.10130.pdf\">paper</a>]</p>\r\n<p><strong>【OpenAI】</strong>【ABC News\r\n专访OpenAI首席执行官萨姆·奥尔特曼：AI风险和重塑社会的问题】[<a\r\nhref=\"https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【最新发布通用人工智能路线图！AGI比想象中来得更快！】[<a\r\nhref=\"https://openai.com/blog/planning-for-agi-and-beyond/\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【Sam\r\nAltman 担心“潜在的可怕的”人工智能工具以及“未来的人们如何看待我们” 】[<a\r\nhref=\"https://finance.yahoo.com/news/openai-ceo-sam-altman-frets-165250285.html\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【The Age of\r\nAI：拾象大模型及OpenAI投资思考】[<a\r\nhref=\"https://mp.weixin.qq.com/s/AxX-Q7njegNTAxMkYFwsfA\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【为什么ChatGPT用强化学习而非监督学习？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/4USDakdomupWuwwhex6fMg\">blog</a>]</p>\r\n<p><strong>【OpenNLPLab】</strong>【为什么ChatGPT用强化学习而非监督学习？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/UZ9ZTdI0zOXp8OOQ3FK_1A\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2307.14995\">paper</a>]，[<a\r\nhref=\"https://github.com/OpenNLPLab/TransnormerLLM\">codel</a>]</p>\r\n<p><strong>【PWC】</strong>【ChatGPT和生成式AI的11大安全趋势】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_RAx3vAx1ykQTJTEEoc37w\">blog</a>]</p>\r\n<p><strong>【人大】</strong>【人大最新大语言模型综述，51页全面回顾大语言模型】[<a\r\nhref=\"https://arxiv.org/pdf/2303.18223.pdf\">paper</a>]</p>\r\n<p><strong>【清华大学】</strong>【张学工教授：AI技术前沿——从ChatGPT到更多突破】[<a\r\nhref=\"https://mp.weixin.qq.com/s/oeZd52BYKU3hhauZZ0eirQ\">blog</a>]</p>\r\n<p><strong>【斯坦福】</strong>【研究大语言模型反映了谁的观点？】[<a\r\nhref=\"https://arxiv.org/pdf/2303.17548.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/tatsu-lab/opinions_qa\">code</a>]</p>\r\n<p><strong>【斯坦福】</strong>【大模型及其公平使用】[<a\r\nhref=\"https://arxiv.org/pdf/2303.15715.pdf\">paper</a>]</p>\r\n<p><strong>【斯坦福】</strong>【构建大模型生态系统图，用于跟踪大模型的足迹】[<a\r\nhref=\"https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=home\">blog</a>]</p>\r\n<p><strong>【斯坦福】</strong>【斯坦福报告：基础模型的机遇与风险】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iEwvkqMT7KEqmnHk8NVz6w\">blog</a>]</p>\r\n<p><strong>【微软】</strong>【一种新的大语言模型NLG评估框架】[<a\r\nhref=\"https://arxiv.org/abs/2303.16634\">paper</a>]</p>\r\n<p><strong>【微软】</strong>【低代码LLM: LLM的可视化编程】[<a\r\nhref=\"https://arxiv.org/abs/2304.08103\">paper</a>]</p>\r\n<p><strong>【微软】</strong>【微软提出LLMA:大型语言模型的无损加速,可以无损地加速带有引用的大型语言模型\r\n(LLM) 推理】[<a\r\nhref=\"https://arxiv.org/pdf/2304.04487.pdf\">paper</a>]</p>\r\n<p><strong>【微软 &amp;\r\nMeta】</strong>【ART：大型语言模型的自动多步骤推理和工具使用】[<a\r\nhref=\"https://arxiv.org/pdf/2303.09014.pdf\">paper</a>]</p>\r\n<p><strong>【EleutherAI&amp;耶鲁大学】</strong>【提出Pythia：\r\n跨越训练和扩展的大型语言模型分析套件】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01373.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/EleutherAI/pythia\">code</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT的底层逻辑】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Rv5htsD2x7TmD-E42RL6Vg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【智慧信息的压缩：模型智能的涌现之道】[<a\r\nhref=\"https://mp.weixin.qq.com/s/hQmvltuMlClBonM6UJmtLg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【拨动大模型的琴弦｜Delta Tuning 成果登上\r\nNature子刊封面！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/m3fNselWKQ2m5XnBe79fQQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大型人工智能模型中出现的不可预测的能力】[<a\r\nhref=\"%5Bhttps://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/%20%5D(https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316)\">blog</a>\r\n)]</p>\r\n<p><strong>【博客】</strong>【为什么现在的大语言模型（LLM）都是Decoder-only的架构？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/ZsHX-M9pisUvG9vqfzdzTQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大型语言模型的涌现能力】[<a\r\nhref=\"https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大型语言模型成本分析】[<a\r\nhref=\"https://hub.baai.ac.cn/view/24047\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【超越ChatGPT：大模型的智能极限 】[<a\r\nhref=\"https://yaofu.notion.site/e1cd16d1fae84f87aeddf872c838e07c\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Nature：AI模型越大越好吗? 】[<a\r\nhref=\"https://www.nature.com/articles/d41586-023-00641-w\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【一场关于ChatGPT话语权的深度思考：人类会在大模型中迷失自我吗？】[<a\r\nhref=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/RPiIh5cbxzXl5uMo_BVFMg\">blog译文</a>]</p>\r\n<p><strong>【博客】</strong>【马斯克强调的TruthGPT 是什么】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_nSYK63DvqE7ZJyJz6NeEA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【对话式AI搜索的技术路线猜想】[<a\r\nhref=\"https://mp.weixin.qq.com/s/AIIu4rRi1WZRQn3oHtuwdg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【AI走过多少路，才迎来了ChatGPT？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/WWc39HtuV-TrbwFybX112Q\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【如何负责任地创建、发布和共享生成式 AI】[<a\r\nhref=\"https://www.technologyreview.com/2023/02/27/1069166/how-to-create-release-and-share-generative-ai-responsibly/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型时代的“Linux”生态，开启人工智能新十年】[<a\r\nhref=\"https://mp.weixin.qq.com/s/sUmA3nSSVfNQFBgSjiSn0g\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【揭秘ChatGPT背后的AI“梦之队”：90后科研“后浪”展示强大创新能力｜智谱研究报告】[<a\r\nhref=\"https://mp.weixin.qq.com/s/sncE01utzu_-r3dLFYU5QA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【In-Context Learning玩法大全 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/sC3Xq1QQmtC8Tz84oRRwcw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【一文理解“上下文学习”----大语言模型突现能力】[<a\r\nhref=\"https://mp.weixin.qq.com/s/0kchPu20nwCKCXk4PZBkOg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【回应吴军老师 |\r\n\"ChatGPT不算新技术革命\"】[<a\r\nhref=\"https://mp.weixin.qq.com/s/dZldwGaYnUcDlB4nUpASMg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Poe向所有开发者推出Poe\r\nAPI，以便广泛获取基于LLM的服务】[<a\r\nhref=\"https://github.com/poe-platform/api-bot-tutorial\">code</a>]</p>\r\n<p><strong>【博客】</strong>【【LLM系列之底座模型对比】LLaMA、Palm、GLM、BLOOM、GPT模型结构对比】[<a\r\nhref=\"https://mp.weixin.qq.com/s/UkifGP2OXxGWeMV7Jm4zWQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型实践总结】[<a\r\nhref=\"https://mp.weixin.qq.com/s/FPweLbvDrCnIzb5PETHMLQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【【LLM系列之GPT】GPT（Generative\r\nPre-trained Transformer）生成式预训练模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1Bpt5MG6mbZCYAXDJmIr3A\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【【LLM系列之Tokenizer】如何科学地训练一个LLM分词器】[<a\r\nhref=\"https://mp.weixin.qq.com/s/4_P2G2Q0YmunQh7DwDas3w\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型词表扩充必备工具SentencePiece】[<a\r\nhref=\"https://mp.weixin.qq.com/s/qQMZ1s7lt-LLkQKx7HIDMw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【大模型知识&amp;推理评估基准】[<a\r\nhref=\"https://mp.weixin.qq.com/s/P0ohd5DpwJOkL8DFVC4qoA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文说清大模型在自动驾驶领域的应用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/5tSwRz-fI4ccLPEn2KrgqA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【一文速览大语言模型在推荐系统中的应用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/RdRLKjzbTWCATmtRMfxW0Q\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【NAACL &amp;\r\nACL：大模型的两种知识继承方案】[<a\r\nhref=\"https://aclanthology.org/2022.naacl-main.288/\">方案一</a>]，[<a\r\nhref=\"https://aclanthology.org/2022.acl-long.151/\">方案二</a>]</p>\r\n<p><strong>【博客】</strong>【a16Z：大模型应用程序的新兴架构】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27506\">中文blog</a>]，[<a\r\nhref=\"https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/\">英文blog</a>]</p>\r\n<p><strong>【论文】</strong>【RetNet：MSRA提出Transformer全新替代大模型基础架构，推理速度8倍提升，内存占用减少70%】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247686895&amp;idx=2&amp;sn=9a2763953d209a29e5d0b03e8b75a912&amp;chksm=e8dead9ddfa9248bea848d16358c5a3eabf11cdd13b5aa96033f3ab2b6dc1ee089bedc73c332&amp;token=1541731120&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2307.08621\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【大模型微调指南：当GPU资源不足时的有效解决方案】[<a\r\nhref=\"https://arxiv.org/pdf/2303.15647.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【<strong>TaskMatrix.AI: Completing Tasks by\r\nConnecting Foundation Models with Millions of APIs</strong> 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16434.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【<strong>AnnoLLM: Making Large Language\r\nModels to Be Better Crowdsourced Annotators</strong> 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16854.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【南加州大学:大语言模型统计偏好的挑战和危险】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03738.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【卡内基·梅隆大学 |\r\n语言生成模型可能造成危害：那么我们能做些什么呢？】[<a\r\nhref=\"https://arxiv.org/pdf/2210.07700.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【鹏程实验室等最新《大规模多模态预训练模型》全面综述】[<a\r\nhref=\"https://arxiv.org/abs/2302.10035\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【预训练基础模型综合调研：从 BERT 到 ChatGPT\r\n的历史 】[<a href=\"https://arxiv.org/abs/2302.09419\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【洛桑联邦理工学院提出REFINER框架，用于微调大规模语言模型】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01904.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【LLM-Adapters：\r\n用于大型语言模型的参数高效微调的适配器系列】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01933.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【大型语言模型的涌现记忆和可预测记忆】[<a\r\nhref=\"https://arxiv.org/abs/2304.11158\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【机器心理学：使用心理学方法研究大型语言模型中的涌现能力和行为】[<a\r\nhref=\"https://arxiv.org/abs/2303.13988v1\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Chameleon：使用大型语言模型进行即插即用的组合推理】[<a\r\nhref=\"https://arxiv.org/abs/2304.09842\">paper</a>]</p>\r\n<p><strong>【代码】</strong>【大型语言模型相关文献资源列表】[<a\r\nhref=\"https://github.com/RUCAIBox/LLMSurvey\">code</a>]</p>\r\n<h2 id=\"llm数据集\">LLM数据集</h2>\r\n<p>【<strong>COIG-PC</strong>】【智源研究院发布国内首个大规模、可商用中文开源指令数据集COIG：最大规模中文多任务指令集，上新千个中文数据集】[<a\r\nhref=\"https://mp.weixin.qq.com/s/PvJa8dPHk6aGEv1G1B3PUw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2304.07987.pdf\">paper</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/BAAI/COIG-PC\">COIG-PC数据下载地址</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/BAAI/COIG\">COIG数据下载地址</a>]</p>\r\n<p>【<strong>Instruct/Prompt\r\nTuning可用数据</strong>】【总结当前开源可用的Instruct/Prompt\r\nTuning数据】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vDbTJo3F7sy3-NY8xxg8jw\">blog</a>]</p>\r\n<p>【<strong>MiniGPT-4</strong>】【GPT-4平替版：MiniGPT-4，支持图像理解和对话，现已开源】[<a\r\nhref=\"https://drive.google.com/file/d/1nJXhoEcy3KTExr17I7BXqY5Y9Lx_-n-9/view\">dataset</a>]</p>\r\n<p>【<strong>Multimodal\r\nC4</strong>】【多模态C4：一个开放的、10亿规模的、与文本交错的图像语料库】[<a\r\nhref=\"https://arxiv.org/abs/2304.06939\">paper</a>]，[<a\r\nhref=\"https://github.com/allenai/mmc4\">code</a>]</p>\r\n<p>【<strong>Mind2Web</strong>】【Mind2Web:\r\n首个全面衡量大模型上网能力的数据集】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vge4CJbBfLXFIYYyNC12Hw\">blog</a>]</p>\r\n<p>【<strong>OpenAssistant\r\nConversations</strong>】【该数据集是一个由人工生成、人工注释的助理式对话语料库，覆盖了广泛的主题和写作风格，由\r\n161443 条消息组成，分布在 66497 个会话树中，使用 35\r\n种不同的语言。该语料库是全球众包工作的产物，涉及超过 13500\r\n名志愿者。为了证明 OpenAssistant Conversations\r\n数据集的有效性，该研究还提出了一个基于聊天的助手\r\nOpenAssistant，其可以理解任务、与第三方系统交互、动态检索信息。】[<a\r\nhref=\"https://huggingface.co/datasets/OpenAssistant/oasst1\">dataset</a>]，[<a\r\nhref=\"https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view\">paper</a>]，[<a\r\nhref=\"https://github.com/LAION-AI/Open-Assistant\">code</a>]</p>\r\n<p>【<strong>Panda LLM</strong>】【为了让Panda\r\nLLM在中文数据集上获得强大的性能，作者使用了强大的指令微调instruction-tuning技术，将LLaMA基础模型在五个开源的中文数据集进行混合训练，其中包括来自各种语言领域的1530万个样本，例如维基百科语料，新闻语料，百科问答语料，社区问答语料，和翻译语料。】[<a\r\nhref=\"https://mp.weixin.qq.com/s/IsWSPAvwgT263wjO7TYTZQ\">blog</a>]</p>\r\n<p>【<strong>RedPajama</strong>】【RedPajama开源项目｜复制超过1.2万亿个令牌的LLaMA训练数据集】[<a\r\nhref=\"https://www.together.xyz/blog/redpajama\">原始blog</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25485\">中文blog</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T\">dataset</a>]，[<a\r\nhref=\"https://github.com/togethercomputer/RedPajama-Data\">code</a>]</p>\r\n<h2 id=\"prompt工程\">Prompt工程</h2>\r\n<p><strong>【博客】</strong>【OpenAI 应用人工智能研究负责人Lilian\r\nWeng新博文：关于提示工程的介绍】[<a\r\nhref=\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Prompt Engineering全面自动化】[<a\r\nhref=\"https://mp.weixin.qq.com/s/aj8Ls463jpF92ssn6Acwzg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT提示示例集合】[<a\r\nhref=\"https://prompts.chat\">地址</a>]，[<a\r\nhref=\"https://github.com/f/awesome-chatgpt-prompts/\">code</a>]，<a\r\nhref=\"https://huggingface.co/datasets/fka/awesome-chatgpt-prompts\">huggingface</a>]</p>\r\n<p><strong>【博客】</strong>【深入浅出Prompt Learning要旨及常用方法】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Wgj1ATMAkL1Gx4dsAlkJZw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT火爆，最全prompt工程指南登GitHub热榜，标星4.7k！】[<a\r\nhref=\"https://github.com/dair-ai/Prompt-Engineering-Guide\">code</a>]，<a\r\nhref=\"https://www.youtube.com/watch?v=dOxUroR57xs\">youtube</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT Prompt工程：设计、实践与思考】[<a\r\nhref=\"https://mp.weixin.qq.com/s/a8hjzZ_Rzl6pOU1PRAARJQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【全面的提示工程指南】[<a\r\nhref=\"https://www.promptingguide.ai/zh\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【指令学习综述｜ChatGPT背后的指令学习是什么】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BK30JkIlshwkdHRjaRCD2g\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2303.10475v2.pdf\">paper</a>]</p>\r\n<p><strong>【博客】</strong>【免费教你提示工程，全中文教学】[<a\r\nhref=\"https://www.learnprompt.pro/\">主页</a>]，[<a\r\nhref=\"https://github.com/LearnPrompt/LearnPrompt\">code</a>]</p>\r\n<p><strong>【博客】</strong>【吴恩达Prompt课程笔记】[<a\r\nhref=\"https://islinxu.github.io/prompt-engineering-note/\">主页</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT使用进阶，Prompt工程】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Uy_wX6DsASBDU2f_6qAy-Q\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【面向大型语言模型的<strong>提升提示集成</strong>】[<a\r\nhref=\"https://arxiv.org/abs/2304.05970\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【DTG：一种简单有效的Prompt方法，激发大模型思考判断能力！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Eio62_Hn0mML3Pfb3G36cA\">blog</a>]</p>\r\n<h2 id=\"agi开源工具博客论文\">AGI开源工具&amp;博客&amp;论文</h2>\r\n<p><strong>【工具】</strong>【Google发布统计深度学习框架平台：OpenXLA】[<a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/AGI/Google_OpenXLA.md\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【AGI的火花一作Sébastien\r\nBubeck演讲万字全文】[<a\r\nhref=\"https://mp.weixin.qq.com/s/H1RVdH0fmwM0GjfV3uvd4g\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【AGI通用智能发展的思考：是否存在足够通用的处理器？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/16TfOu4qfqlbQHpDgDUM2A\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【OpenAGI:当大语言模型遇到领域专家】[<a\r\nhref=\"https://arxiv.org/abs/2304.04370\">paper</a>]，[<a\r\nhref=\"https://github.com/agiresearch/OpenAGI\">code</a>]</p>\r\n<h2 id=\"文本生成\">文本生成</h2>\r\n<h3 id=\"chatgpt\">ChatGPT</h3>\r\n<p>从GPT3到ChatGPT模型的发展路线图</p>\r\n<figure>\r\n<img src=\"images/chatgpt-3.jpg\" alt=\"ChatGPT_family\" />\r\n<figcaption aria-hidden=\"true\">ChatGPT_family</figcaption>\r\n</figure>\r\n<h4 id=\"chatgpt-应用篇\">ChatGPT 应用篇</h4>\r\n<p><strong>【58】</strong>【从 GPT 到 ChatGPT 的演进与应用思考】[<a\r\nhref=\"https://mp.weixin.qq.com/s/3Pr82xKpZ7mAWQcxPPB1xA\">blog</a>]</p>\r\n<p><strong>【MIT &amp; 哈佛大学 】</strong>【语言模型可以预测公众舆论\r\n】[<a href=\"https://arxiv.org/pdf/2303.16779.pdf\">paper</a>]</p>\r\n<p><strong>【中科院】</strong>【ChatGPT助力芯片，传统\r\nEDA如何演变成智能EDA】[<a\r\nhref=\"https://mp.weixin.qq.com/s/JyveUDEYKLrFolfCFLqhhw\">blog</a>]</p>\r\n<p><strong>【微软】</strong>【《ChatGPT机器人:设计原则和模型能力》论文\r\n】[<a\r\nhref=\"https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/\">paper</a>]</p>\r\n<p><strong>【微软】</strong>【各种环境下的ChatGPT赋能长步机器人控制：\r\n一个案例的应用 】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03893.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts\">code</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT获得了「Wolfram」超能力】[<a\r\nhref=\"https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【OpenAI开发Plugin将 ChatGPT\r\n连接到互联网】[<a\r\nhref=\"https://techcrunch.com/2023/03/23/openai-connects-chatgpt-to-the-internet/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatAug：利用ChatGPT进行文本数据增强】[<a\r\nhref=\"https://arxiv.org/abs/2302.13007\">paper</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT 是数据隐私的另一个障碍吗】[<a\r\nhref=\"https://www.bizcommunity.com/Article/196/639/236418.html\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【基于ChatGPT的数据增强方法：ChatAug和AugGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486140&amp;idx=1&amp;sn=bba4342966c99559938824f2d747d231&amp;chksm=ced54958f9a2c04ec121b8c198d69a5a17c8b3e0a96a0cfcd8d1271bd6097a2cbf66895dd8a9&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Character.AI\r\n在ChatGPT基础上加入个性化、UGC两大武器，有比 ChatGPT\r\n更丰富的使用场景】[<a\r\nhref=\"https://mp.weixin.qq.com/s/U4R8loz1G9PYM_l6IvNF_A\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【让ChatGPT可以<strong>语音交互</strong>】[<a\r\nhref=\"https://mp.weixin.qq.com/s/H4XLCQ-kR7T28yywHJL4uA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【“ChatGPT们”的淘金时代】[<a\r\nhref=\"https://mp.weixin.qq.com/s/otdenJh5FJsCgi5ONy9JIQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【70 款 ChatGPT 插件评测（含样例分析）】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vHwAk63ukRteF1u1myrTlA\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【人大提出WebBrain：NLP新任务，通过网络数据的挖掘生成真实文章】[<a\r\nhref=\"https://arxiv.org/abs/2304.04358\">paper</a>]，[<a\r\nhref=\"https://github.com/qhjqhj00/WebBrain\">code</a>]</p>\r\n<p><strong>【医疗】</strong>【ChatGPT爆火带来思考：医学界或将迎来与AI融合的奇点？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/x8ppg6GVCAeLNpv5uJ7B7g\">blog</a>]</p>\r\n<p><strong>【教育】</strong>【论ChatGPT大语言模型在教育中的机遇与挑战\r\n】[<a\r\nhref=\"https://url39.ctfile.com/f/2501739-809898048-6394c7?p=2096\">blog</a>]</p>\r\n<p><strong>【投资】</strong>【ChatGPT在投资研究领域的应用初探及原理分析】[<a\r\nhref=\"https://mp.weixin.qq.com/s/LFPeSLeEOTb1-2YJBXclbQ\">blog</a>]</p>\r\n<p><strong>【软件】</strong>【OpenAI总裁Greg\r\nBrockman转发｜一种编译语言的调试器，利用ChatGPT旨在增强您使用GDB进行调试体验】[<a\r\nhref=\"https://github.com/pgosar/ChatGDB\">code</a>]</p>\r\n<p><strong>【软件】</strong>【不必排队等 OpenAI Plugins，OpenBMB\r\n开源大模型工具学习引擎】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25189\">blog</a>]</p>\r\n<p><strong>【其他】</strong>【分析了ChatGPT技术以及落地应用场景 】[<a\r\nhref=\"https://url39.ctfile.com/f/2501739-805099789-098b62?p=2096\">blog</a>]</p>\r\n<h4 id=\"chatgpt-工具篇\">ChatGPT 工具篇</h4>\r\n<p><strong>【工具】</strong>【ChatGPT 应用汇总及操作手册】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485794&amp;idx=1&amp;sn=6aa0500e3139b67246dd5f96007d1487&amp;chksm=ced54a86f9a2c390d86856181f1fcd09091cf84d67e81535b6d592617f49fe24349779cfa1e5&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【工具】</strong>【ChatGPT提示和技巧速查手册】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485766&amp;idx=1&amp;sn=43ad627e4e183d7a108c3c57ab0e02dc&amp;chksm=ced54aa2f9a2c3b4a2d529e4ed7c2acc7fa32e7465837045d3ec607701e0da2a55c0c557cad2&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【工具】</strong>【非常全面的ChatGPT、LLM相关资源整理分享】[<a\r\nhref=\"https://github.com/cedrickchee/chatgpt-universe\">code</a>]</p>\r\n<p><strong>【工具】</strong>【ChatGPT超全面课程】[<a\r\nhref=\"https://tested-salto-cab.notion.site/The-Ultimate-Chat-GPT-Course-69ed24a317a942d288e740419b1ad6f6\">blog</a>]</p>\r\n<p><strong>【工具】</strong>【BloombergGPT: A Large Language Model for\r\nFinance】[<a\r\nhref=\"https://papers.labml.ai/api/v1/redirect/pdf?paper_key=b0e4b03ecf5c11edb95839eec3084ddd\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【ChatPDF：一键上传PDF文件即可解读 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/S1DUJrNK5_H5krvHotOwHQ\">blog</a>]，[<a\r\nhref=\"https://www.chatpdf.com/\">试用地址</a>]</p>\r\n<p><strong>【工具】</strong>【ChatWeb：可爬取网页正文，并根据正文回答问题\r\n】[<a href=\"https://github.com/SkywalkerDarren/chatWeb\">code</a>]</p>\r\n<p><strong>【工具】</strong>【chatgpt_academic：中科院基于 ChatGPT\r\n专属定制的学术研究及日常开发工具】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25298\">blog</a>]，[<a\r\nhref=\"https://github.com/binary-husky/chatgpt_academic\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/qingxu98/gpt-academic\">demo</a>]</p>\r\n<p><strong>【工具】</strong>【Einstein GPT：SaaS 行业巨头 Salesforce\r\n宣布与 OpenAI 合作，推出 Einstein\r\nGPT，这是全球首个用于客户关系管理（CRM）的生成式 AI 产品 】[<a\r\nhref=\"https://www.salesforce.com/products/einstein/overview/?d=cta-body-promo-8\">Einstein\r\nGPT地址</a>]，[<a\r\nhref=\"https://openai.com/waitlist/slack\">试用地址</a>]</p>\r\n<p><strong>【工具】</strong>【HuggingGPT: Solving AI Tasks with ChatGPT\r\nand its Friends in HuggingFace 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.17580.pdf\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【ImpressionGPT：\r\n利用ChatGPT对放射科报告进行总结的迭代优化框架】[<a\r\nhref=\"https://arxiv.org/abs/2304.08448\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【OpenGpt：创建ChatGPT小应用的AI平台】[<a\r\nhref=\"https://open-gpt.app/\">官网</a>]，[<a\r\nhref=\"https://github.com/futantan/OpenGpt\">code</a>]</p>\r\n<p><strong>【工具】</strong>【TagGPT：腾讯提出零样本多模态标签的大语言模型TagGPT】[<a\r\nhref=\"https://arxiv.org/abs/2304.03022\">paper</a>]，[<a\r\nhref=\"https://github.com/TencentARC/TagGPT\">code</a>]</p>\r\n<p><strong>【工具】</strong>【Visual ChatGPT:\r\n在视觉模型加持下的ChatGPT，聊天生图全拿捏了。】[<a\r\nhref=\"https://arxiv.org/pdf/2303.04671.pdf\">paper</a>]</p>\r\n<p><strong>【工具】</strong>【NetGPT：用于网络流量的生成预训练Transformer模型】[<a\r\nhref=\"https://arxiv.org/pdf/2304.09513.pdf\">paper</a>]</p>\r\n<h4 id=\"chatgpt-技术篇\">ChatGPT 技术篇</h4>\r\n<p><strong>【符尧】</strong>【深度拆解GPT-3.5能力起源】[<a\r\nhref=\"https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756\">原文blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/ckd6KxeTfdQas_UCsJ7HgQ\">译文blog</a>]</p>\r\n<p><strong>【知乎】</strong>【ChatGPT发展历程、原理、技术架构详解和产业未来】[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/590655677\">blog</a>]</p>\r\n<p><strong>【斯坦福】</strong>【82页PPT ！最新ChatGPT: 提示学习,\r\n指导微调和RLHF 】[<a\r\nhref=\"https://pan.baidu.com/s/15Bs1u7z1RhCdfiR3oJ_gJQ\">blog</a>]，[提取码:chat]</p>\r\n<p><strong>【微软】</strong>【让天下没有难训练的大模型，微软亚洲研究院开源TorchScale\r\n】[<a href=\"https://github.com/microsoft/torchscale\">code</a>]</p>\r\n<p><strong>【亚马逊 】</strong>【他们提出了包含视觉特征的\r\nMultimodal-CoT，该架构在参数量小于 10 亿的情况下，在 ScienceQA\r\n基准测试中，比 GPT-3.5 高出 16 个百分点 】[<a\r\nhref=\"https://arxiv.org/abs/2302.00923\">paper</a>]，[<a\r\nhref=\"https://github.com/amazon-science/mm-cot\">code</a>]</p>\r\n<p><strong>【OpenBMB】</strong>【Nature ：生成式 AI 的前景与风险】[<a\r\nhref=\"https://mp.weixin.qq.com/s/d6t2xpdvSDCHzO2gG1N6eQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文解读：从Transformer到ChatGPT，通用人工智能曙光初现】[<a\r\nhref=\"https://mp.weixin.qq.com/s/iZyKmWgXUkPv3Phyaw4Ppg\">blog</a>]</p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Inference_Cost.md\">ChatGPT_Inference_Cost</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Official_API_Learning.md\">ChatGPT_Official_API_Learning</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Parameter_is_not_175B.md\">ChatGPT_Parameter_is_not_175B</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Road_Map_from_yao.fu.md\">ChatGPT_Road_Map_from_yao.fu</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/Lessons_Learned_from_ChatGPT_Recurrence.md\">Lessons_Learned_from_ChatGPT_Recurrence</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/LLM_Pre-training_Guide（Bloom-175B）.md\">LLM_Pre-training_Guide（Bloom-175B）</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/The_guide_of_training_LLM.md\">The_guide_of_training_LLM</a></p>\r\n<p><strong>【博客】</strong>【AI芯片制造商Cerebras发布7个基于GPT的大语言模型，现已开源】[<a\r\nhref=\"https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/\">官网地址</a>\r\n)]，[<a href=\"https://www.cerebras.net/cerebras-gpt\">GPT地址</a>]，[<a\r\nhref=\"https://huggingface.co/cerebras\">Hugging Face地址</a>]</p>\r\n<p><strong>【博客】</strong>【大模型论文周报丨GPT-4发布，谷歌开放PaLM\r\nAPI，斯坦福7B开源模型Alpaca媲美GPT-3.5】[<a\r\nhref=\"https://mp.weixin.qq.com/s/C6g_H6xfFn59IxnLpbjA1g\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【LLaMA模型Meta版泄露，GitHub获8K星】[<a\r\nhref=\"https://mp.weixin.qq.com/s/2M19WSq2YICo-3t5ibQcig\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT or Grammarly? Evaluating ChatGPT\r\non Grammatical Error Correction Benchmark 】[<a\r\nhref=\"https://arxiv.org/abs/2303.13648\">paper</a>]</p>\r\n<p><strong>【博客】</strong>【打造中国版ChatGPT，国内哪家实力最强】[<a\r\nhref=\"https://mp.weixin.qq.com/s/B-n_qz110HmhSP66NKRCiQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【复旦大学邱锡鹏教授解读ChatGPT】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485810&amp;idx=1&amp;sn=47eb672c688517d6bade2c62c7eae94f&amp;chksm=ced54a96f9a2c380ccacfbb223df52de64f2c410a91e726023a074fc98fb87fcd9f60f5a4957&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文:可能是全网最晚的ChatGPT技术总结\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/LJoxupaKflL793TCwnpyPg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT作为知识库问答系统的问答能力评测\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/xul2-SENnqxV8VehozDKHg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT作者John\r\nShulman：我们成功的秘密武器】[<a\r\nhref=\"https://www.talkrl.com/episodes/john-schulman\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/sDeBYMvAwbJr5_tj7Q20-w\">blog译文</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT 是数据隐私的另一个障碍吗】[<a\r\nhref=\"https://www.bizcommunity.com/Article/196/639/236418.html\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Hugging Face 每周速递: ChatGPT API\r\n怎么用？我们帮你搭好页面了 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/oeXgd78vFV8os2uTGZkFQQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【复旦大学教授肖仰华：ChatGPT\r\n浪潮下，面向大模型如何做数据治理？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/od24PYvFLUJe4NQxjvsbMw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【腾讯在ChatGPT的布局】[<a\r\nhref=\"https://mp.weixin.qq.com/s/rdpGZII3pu3MHr-lFm3GyQ\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【浅析ChatGPT：历史沿革、应用现状及前景展望】[<a\r\nhref=\"https://mp.weixin.qq.com/s/fQ8DmL_M3QMiFX23Tf0z7w\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT 背后的“功臣”——人类反馈强化学习RLHF\r\n技术详解】[<a\r\nhref=\"https://mp.weixin.qq.com/s/mZdZS9QNda26Ae0OIhRjFA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【万字长文解析！复现和使用GPT-3/ChatGPT，你所应该知道的】[<a\r\nhref=\"https://mp.weixin.qq.com/s/ILpbRRNP10Ef1z3lb2CqmA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【想训练ChatGPT？得先弄明白Reward\r\nModel怎么训（附源码） 】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1v4Uuc1YAZ9MRr1UWMH9xw\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【ChatGPT核心技术：强化学习PPO算法】[<a\r\nhref=\"https://mp.weixin.qq.com/s/z4oc9xQmduKMolWxztdHjA\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【解读 ChatGPT\r\n背后的技术重点：RLHF、IFT、CoT、红蓝对抗】[<a\r\nhref=\"https://mp.weixin.qq.com/s/y4ywidZ55BQLgQzJa_Wjbg\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【OpenAI ChatGPT Code Interpreter入门】[<a\r\nhref=\"https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting\">blog</a>]</p>\r\n<p><strong>【伦理】</strong>【加拿大魁北克大学教授详述：我们该拿ChatGPT怎么办？】[<a\r\nhref=\"https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【AIGC时代的ChatGPT全面综述】[<a\r\nhref=\"https://arxiv.org/abs/2304.06488\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT is a Knowledgeable but\r\nInexperienced Solver: An Investigation of Commonsense Problem in Large\r\nLanguage Models】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16421.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【GPT-3 和 GPT-3.5 系列模型的全面分析】[<a\r\nhref=\"https://arxiv.org/abs/2303.10420v1\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT Outperforms Crowd-Workers for\r\nText-Annotation Tasks】[<a\r\nhref=\"https://arxiv.org/pdf/2303.15056.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【微软&amp;佐治亚理工学院 |\r\nAdaLoRA：自适应预算分配以实现参数有效的微调】[<a\r\nhref=\"https://arxiv.org/pdf/2303.10512.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/QingruZhang/AdaLoRA\">code</a>]</p>\r\n<p><strong>【论文】</strong>【微软 | 大型语言模型的语境忠实提示法】[<a\r\nhref=\"https://arxiv.org/pdf/2303.11315.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【KAUST |\r\nChatGPT问，BLIP-2回答模型：面向丰富的视觉描述的自动提问】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06594.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/Vision-CAIR/ChatCaptioner\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT真的可以取代知识图谱问答吗？ 】[<a\r\nhref=\"https://arxiv.org/abs/2303.07992\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/cvBVgxCrreic6U6CU-YB-A\">paper翻译</a>]</p>\r\n<p><strong>【论文】</strong>【Meta &amp;\r\n斯坦福大学推出FlexGen：用单个GPU进行大型语言模型的高吞吐量生成性推理】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06865.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/FMInference/FlexGen\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT破圈的「秘密武器」：详解RLHF如何影响人类社会！\r\n】[<a href=\"https://arxiv.org/abs/2303.02891\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/DCFhefWGQS5naYwT3o6neg\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【探讨ChatGPT在对抗攻击和分布外泛化下的鲁棒性】[<a\r\nhref=\"https://arxiv.org/pdf/2302.12095.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/microsoft/robustlearn\">code</a>]</p>\r\n<p><strong>【论文】</strong>【复旦清华联合顶刊发文｜ChatGPT：潜力、前景和局限\r\n】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1D62QuxXFDXWwwRXrB-Ivw\">blog</a>]，[<a\r\nhref=\"https://link.springer.com/article/10.1631/FITEE.2300089\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【引导ChatGPT不要输出有害信息】[<a\r\nhref=\"https://arxiv.org/pdf/2302.07459.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Junnan\r\nLi大佬发表最新多模态的杰作BLIP2】[<a\r\nhref=\"https://arxiv.org/abs/2301.12597\">paper</a>]，[<a\r\nhref=\"https://github.com/salesforce/LAVIS/tree/main/projects/blip2\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/xmSy4m7NheY8iComv7grxQ\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【Instruction Tuning：无/少样本学习新范式\r\n】[<a href=\"https://arxiv.org/abs/2109.01652\">paper</a>]，[<a\r\nhref=\"https://github.com/google-research/flan\">code</a>]</p>\r\n<p><strong>【论文】</strong>【GPTScore：一种新的评估语言模型方法】[<a\r\nhref=\"https://arxiv.org/abs/2302.04166\">paper</a>]，[<a\r\nhref=\"https://github.com/jinlanfu/GPTScore\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT内核：InstructGPT，基于反馈指令的PPO强化学习】[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/589747432\">blog</a>]，[<a\r\nhref=\"https://www.bilibili.com/video/BV1hd4y187CR\">B站</a>]</p>\r\n<p><strong>【论文】</strong>【Fine-tune-CoT：小模型也能做推理，完美逆袭大模型\r\n】[<a href=\"https://arxiv.org/pdf/2212.10071.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/itsnamgyu/reasoning-teacher\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT的潜力解锁：自然语言处理中应用、优势、限制和未来方向的全面探索】[<a\r\nhref=\"https://arxiv.org/pdf/2304.02017.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【阿里巴巴&amp;清华大学|大型语言模型在算术任务中的表现如何？】[<a\r\nhref=\"https://arxiv.org/pdf/2304.02015.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/GanjinZero/math401-llm\">code</a>]</p>\r\n<p><strong>【代码】</strong>【本科生60行代码教你手搓GPT大模型 】[<a\r\nhref=\"https://github.com/jaymody/picoGPT/tree/29e78cc52b58ed2c1c483ffea2eb46ff6bdec785\">code</a>]</p>\r\n<h3 id=\"gpt4\">GPT4</h3>\r\n<h4 id=\"gpt4-官方文档\">GPT4 官方文档</h4>\r\n<p><strong>【博客】</strong>【GPT4_System_Card中文翻译】[<a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Official/GPT-4_System_Card_zh.md\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【GPT4_Technical_Report中文翻译】[<a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Official/GPT4_Technical_Report_zh.md\">blog</a>]</p>\r\n<h4 id=\"gpt4-博客篇\">GPT4 博客篇</h4>\r\n<p><strong>【博客】</strong>【【万字长文】GPT-4秘密泄露！所有的信息都在这里！从GPT-4\r\n架构、基础设施、训练数据集、成本、视觉到MoE！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/vgUKe31pykC12sUV5xyLNQ\">blog</a>]，[<a\r\nhref=\"https://www.semianalysis.com/p/gpt-4-architecture-infrastructure\">原blog</a>]</p>\r\n<p><strong>【纽约时报】</strong>【GPT-4 令人印象深刻但仍在 10\r\n个方面具有缺陷】[<a\r\nhref=\"https://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html\">blog</a>]</p>\r\n<p><strong>【Open AI】</strong>【多模态大模型GPT-4的新突破】[<a\r\nhref=\"https://hub.baai.ac.cn/view/24852\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【重磅发布GPT-4】[<a\r\nhref=\"https://openai.com/research/gpt-4\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【GPT-4 创造者 Ilya Sutskever 谈 AI 幻觉和\r\nAI 民主】[<a\r\nhref=\"https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/?sh=7743f01e1218\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【GPT-4创造者：第二次改变AI浪潮的方向】[<a\r\nhref=\"https://mp.weixin.qq.com/s/rZBEDlxFVsVXoL5YUVU3XQ\">blog</a>]</p>\r\n<p><strong>【OpenAI】</strong>【当GPT-4进入北京市2022高考考场能有什么表现？】[<a\r\nhref=\"https://mp.weixin.qq.com/s/N_j01KSuEKuVwCCD69G92g\">blog</a>]</p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Blog/GPT4_Technical_Detail.md\">GPT4技术细节</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Blog/GPT4_Technical_Summary.md\">GPT4技术关键点总结</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT_VS_GPT4/GPT4_VS_ChatGPT（from_nytimes）.md\">GPT4和ChatGPT的效果对比</a></p>\r\n<p><strong>【博客】</strong><a\r\nhref=\"https://doc.clickup.com/37456139/d/h/13q28b-324/e2a22b0c164b1f9\">The\r\nUltimate GPT-4 Guide</a></p>\r\n<h4 id=\"gpt4-论文篇\">GPT4 论文篇</h4>\r\n<p><strong>【微软】</strong>【用GPT-4进行指令调优】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03277.pdf\">paper</a>]，[<a\r\nhref=\"https://instruction-tuning-with-gpt-4.github.io/\">code</a>]</p>\r\n<p><strong>【论文】</strong>【点燃通用人工智能的火花：GPT-4的早期实验】[<a\r\nhref=\"https://arxiv.org/pdf/2303.12712.pdf\">原始paper</a>]，[<a\r\nhref=\"https://event-cdn.baai.ac.cn/file/file-browser/waTXJn85fm3FPyDXpsZ4faGk47trjjYb.pdf\">中文版paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/H1RVdH0fmwM0GjfV3uvd4g\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【GPT4All：用GPT-3.5-Turbo的大规模数据提炼训练一个助理式聊天机器人】[<a\r\nhref=\"https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/nomic-ai/gpt4all\">code</a>]</p>\r\n<p><strong>【论文】</strong>【美国东北大学：可以通过要求GPT4反思“你为什么错了？”来提高30%的性能】[<a\r\nhref=\"https://arxiv.org/abs/2303.11366\">paper</a>]，[<a\r\nhref=\"https://github.com/noahshinn024/reflexion\">code</a>]</p>\r\n<p><strong>【论文】</strong>【对ChatGPT/GPT-4研究的总结以及对大型语言模型未来的展望】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01852.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【评估日本医疗执照考试的GPT-4和ChatGPT】[<a\r\nhref=\"https://arxiv.org/pdf/2303.18027.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Amazon |\r\n深入研究LLMs与AutoGPT的结合：揭示出GPT-4惊人的人类决策能力！】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Gbz7ZVVdeTq64mj1-__aQA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/pdf/2306.02224.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/younghuman/LLMAgent\">code</a>]</p>\r\n<h3 id=\"anima\">Anima</h3>\r\n<p>【33B QLoRA大语言模型Anima的性能超越了对比的所有的中文开源模型。】[<a\r\nhref=\"https://zhuanlan.zhihu.com/p/638058537?utm_source=wechat_session&amp;utm_medium=social&amp;s_r=0\">blog</a>]，[<a\r\nhref=\"https://github.com/lyogavin/Anima\">code</a>]，[<a\r\nhref=\"https://huggingface.co/lyogavin/Anima33B\">model</a>]</p>\r\n<h3 id=\"bard\">Bard</h3>\r\n<p>【谷歌再次开放Bard访问权，向着ChatGPT发起再一次攻击】[<a\r\nhref=\"%5Bhttp://Bard.google.com%5D(http://bard.google.com/)\">报名地址</a>\r\n)]，[<a\r\nhref=\"https://twitter.com/sundarpichai/status/1638180697352593408\">blog</a>]，[<a\r\nhref=\"https://www.theverge.com/23649897/google-Bard-chatbot-search-engine\">theverge</a>]</p>\r\n<h3 id=\"baize\">Baize</h3>\r\n<p>【用ChatGPT训练羊驼：「Baize」开源，轻松构建专属模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/zxElGfclNbBwTuDG4Qrxnw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2304.01196\">paper</a>]，[<a\r\nhref=\"https://github.com/project-baize/baize/blob/main/README.md\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/project-baize/baize-lora-7B\">demo</a>]</p>\r\n<h3 id=\"baichuan以及扩展\">baichuan以及扩展</h3>\r\n<p><strong>【baichuan-7b】</strong>【王小川大模型首亮相！70亿参数霸榜，清北抢先用｜独家专访】[<a\r\nhref=\"https://mp.weixin.qq.com/s/qA_E_3dUe1sSOUM87ZgHdQ\">blog</a>]，[<a\r\nhref=\"https://huggingface.co/baichuan-inc/baichuan-7B\">Hugging\r\nFace</a>]，[<a\r\nhref=\"https://github.com/baichuan-inc/baichuan-7B\">code</a>]，[<a\r\nhref=\"https://modelscope.cn/models/baichuan-inc/baichuan-7B/summary\">Model\r\nScope</a>]，[<a\r\nhref=\"https://cevalbenchmark.com/static/leaderboard_zh.html\">C-EVAL</a>]</p>\r\n<p><strong>【firefly-baichuan-7b-qlora-sft】</strong>[使用Firefly项目中的QLoRA训练流程，在moss-003-sft-data百万多轮指令数据上进行了指令微调baichuan-7b模型]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/_eTkDGG5DmxyWeiQ6DIxBw\">blog</a>]，[<a\r\nhref=\"https://huggingface.co/YeungNLP/firefly-baichuan-7b-qlora-sft\">Hugging\r\nFace model</a>]，[<a\r\nhref=\"https://github.com/baichuan-inc/baichuan-7B\">code</a>]，[<a\r\nhref=\"https://modelscope.cn/models/baichuan-inc/baichuan-7B/summary\">Model\r\nScope</a>]，[<a\r\nhref=\"https://cevalbenchmark.com/static/leaderboard_zh.html\">C-EVAL</a>]</p>\r\n<h3 id=\"bloom\">BLOOM</h3>\r\n<p>【【LLM系列之BLOOM】BLOOM: 多语言大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_Vj-KNxS5SfuF_h7bfMb5Q\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2211.05100\">paper</a>]，[<a\r\nhref=\"https://github.com/huggingface/transformers-bloom-inference/tree/main\">code</a>]，[<a\r\nhref=\"https://huggingface.co/bigscience/bloom\">huggingface</a>]</p>\r\n<h3 id=\"biomedgpt\">BiomedGPT</h3>\r\n<p>【BiomedGPT: 统一通用的生物医学生成式预训练Transformer】[<a\r\nhref=\"https://arxiv.org/abs/2305.17100\">paper</a>]</p>\r\n<h3 id=\"claude\">Claude</h3>\r\n<p>【ChatGPT最强竞品Claude今日开放API】[<a\r\nhref=\"https://www.anthropic.com/product\">产品地址</a>]，[<a\r\nhref=\"https://www.anthropic.com/earlyaccess\">申请地址</a>]，[<a\r\nhref=\"https://console.anthropic.com/docs/api\">API说明</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Wx5q-rEwG4sROvnewGxWrw\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Yu551-z14lpiFGSOfXE2Tw\">Claude支持100k上下文</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/27790\">Claude2发布</a>]</p>\r\n<h3 id=\"claude-2\">Claude 2</h3>\r\n<p>【ChatGPT最强竞品Claude2来了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/_uIPPJHmiYaBFxtKXdwFbA\">blog</a>]</p>\r\n<h3 id=\"chatglm-6b以及扩展\">ChatGLM-6B以及扩展</h3>\r\n<p>【ChatGLM：千亿基座的对话模型开启内测 ⸺对应单卡版本开源】[<a\r\nhref=\"https://chatglm.cn/blog\">blog</a>]，[<a\r\nhref=\"https://github.com/THUDM/ChatGLM-6B.git\">code</a>]</p>\r\n<p>【chatglm+langchain+互联网，你可以将大模型接入网络了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/lO6SrEuv4-vNbL8B3G-f8g\">blog</a>]，[<a\r\nhref=\"https://github.com/LemonQu-GIT/ChatGLM-6B-Engineering/\">code</a>]</p>\r\n<p><strong>【Chinese-LangChain】</strong>【基于ChatGLM-6b+langchain实现本地化知识库检索与智能答案生成】[<a\r\nhref=\"https://github.com/yanqiangmiffy/Chinese-LangChain\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/xAsZZ_LOkr9Nj-JafSbXnA\">blog</a>]</p>\r\n<p>【ChatGLM_multi_gpu_zero_Tuning：简单高效实现多卡微调大模型】[<a\r\nhref=\"https://github.com/CSHaitao/ChatGLM_mutli_gpu_tuning\">code</a>]</p>\r\n<p>【浅尝prompt咒语设计：one-shot微调chatglm-6b实践信息抽取】[<a\r\nhref=\"https://mp.weixin.qq.com/s/l7lCbdJ9XGzLPTb3zKDAzQ\">blog</a>]</p>\r\n<p>【ChatGLM-6B模型结构组件源码阅读】[<a\r\nhref=\"https://mp.weixin.qq.com/s/r7KEJmrpJZmY7KBP4veS6A\">blog</a>]</p>\r\n<p>【基于1万亿token开源大模型Falcon，超越650亿的LLaMA，可商用】[<a\r\nhref=\"https://mp.weixin.qq.com/s/jbRRjG2ferhFPWsMtCaJyg\">blog1</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Vy_xWBuZU0AaaPMCIhKIyw\">blog2</a>]</p>\r\n<h3 id=\"chatyuan\">ChatYuan</h3>\r\n<p>【ChatYuan：基于PromptCLUE-large的中文对话开源大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485655&amp;idx=1&amp;sn=ad80d8a17d4aaab90b17a79b638c712d&amp;chksm=ced54b33f9a2c225ce292b4e3d5725a668d0bfc9fe0be610c847b31b61714ecf75c06dac1cb5&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<h3 id=\"copilot-x\">Copilot X</h3>\r\n<p>【GitHub Copilot X编辑器发布，大大提升编码速度】[<a\r\nhref=\"https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/\">blog</a>]</p>\r\n<h3 id=\"colossalai\">ColossalAI</h3>\r\n<p>【穷孩子如何体验ColossalAI SFT（Colab篇）】[<a\r\nhref=\"https://mp.weixin.qq.com/s/NS4yySeYd7QUYb7CB9V0lA\">blog</a>]</p>\r\n<h3 id=\"cpm-bee\">CPM-Bee</h3>\r\n<p>【中文基座模型CPM-Bee开源了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BO4cDB9KRSODZw3TvZpUAA\">blog</a>]，[<a\r\nhref=\"https://github.com/OpenBMB/CPM-Bee\">code</a>]，[<a\r\nhref=\"https://huggingface.co/openbmb/cpm-bee-10b\">HuggingFace</a>]</p>\r\n<h3 id=\"chatdb\">ChatDB</h3>\r\n<p>【清华大学和北京智源人工智能研究院的研究者们提出了ChatDB：用数据库作为符号性记忆模块来增强大语言模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/o3j1vNLHlJ6qTea219A4Qw\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2306.03901\">paper</a>]，[<a\r\nhref=\"https://chatdatabase.github.io\">主页</a>]，[<a\r\nhref=\"https://github.com/huchenxucs/ChatDB\">code</a>]</p>\r\n<h3 id=\"dolly\">Dolly</h3>\r\n<p>【声称它\r\n\"<strong>像ChatGPT一样神奇</strong>\"，但只需要<strong>使用一台机器</strong>在<strong>不到三个小时的时间里</strong>训练的数据少得多。】[<a\r\nhref=\"https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html\">blog</a>]，[<a\r\nhref=\"https://www.databricks.com\">Databricks Inc地址</a>]</p>\r\n<h3 id=\"dolly2.0\">Dolly2.0</h3>\r\n<p>【Databricks的dolly-v2-12b，是一个在Databricks机器学习平台上训练的指令跟随型大型语言模型】[<a\r\nhref=\"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\">blog_en</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25434\">blog_zh</a>]</p>\r\n<h3 id=\"deepspeed-chat\">DeepSpeed-Chat</h3>\r\n<p>【DeepSpeed对话：易于使用、快速而实惠的RLHF训练，在各种规模下训练ChatGPT模型】[<a\r\nhref=\"https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat\">code</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25414\">blog</a>]</p>\r\n<h3 id=\"frugalgpt\">FrugalGPT</h3>\r\n<p>【斯坦福提出FrugalGPT｜性能媲美GPT4，成本降低98%】[<a\r\nhref=\"https://arxiv.org/pdf/2305.05176.pdf\">paper</a>]，[<a\r\nhref=\"https://www.reddit.com/r/singularity/comments/13dnfd7/frugalgpt_can_match_the_performance_of_the_best/\">blog</a>]</p>\r\n<h3 id=\"gpt3.5\">GPT3.5</h3>\r\n<p>【GPT3.5试用地址 】[<a\r\nhref=\"https://platform.openai.com/playground\">试用地址</a>]</p>\r\n<h3 id=\"jittorllms\">JittorLLMs</h3>\r\n<p>【笔记本没有显卡也能跑大模型，具有高性能、配置要求低、中文支持好、可移植等特点】[<a\r\nhref=\"https://github.com/Jittor/JittorLLMs\">code</a>]</p>\r\n<h3 id=\"llm-as-controller\">LLM as Controller</h3>\r\n<p>【LLM as Controller—无限拓展LLM的能力边界】[<a\r\nhref=\"https://mp.weixin.qq.com/s/jeb7ugGC6zxsOsfE-w-I0A\">blog</a>]</p>\r\n<h3 id=\"metagpt\">MetaGPT</h3>\r\n<p>【MetaGPT：多角色元编程框架】[<a\r\nhref=\"https://github.com/geekan/MetaGPT\">code</a>]</p>\r\n<h3 id=\"minigpt-4\">MiniGPT-4</h3>\r\n<p>【类似GPT-4图像理解与对话能力的AI大模型，已开源】[<a\r\nhref=\"https://minigpt-4.github.io/\">主页</a>]，[<a\r\nhref=\"https://github.com/Vision-CAIR/MiniGPT-4/blob/main/MiniGPT_4.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/Vision-CAIR/MiniGPT-4\">code</a>]，[<a\r\nhref=\"https://youtu.be/__tftoxpBAw\">video</a>]，[<a\r\nhref=\"https://drive.google.com/file/d/1nJXhoEcy3KTExr17I7BXqY5Y9Lx_-n-9/view\">dataset</a>]，[<a\r\nhref=\"https://6b89c70eb5e14dca33.gradio.live/\">Demo</a>]，[<a\r\nhref=\"https://b2517615b965687635.gradio.live/\">Demo1</a>]，[<a\r\nhref=\"https://c8de8ff74b6a6c6a9b.gradio.live/\">Demo2</a>]，[<a\r\nhref=\"https://0a111504e072685259.gradio.live/\">Demo3</a>]，[<a\r\nhref=\"https://90bc0bac96e6457e8f.gradio.live/\">Demo4</a>]</p>\r\n<h3 id=\"moss\">MOSS</h3>\r\n<p>【FudanNLP团队最新成果，借助RLHF实现人类对齐的MOSS-RLHF来了】[<a\r\nhref=\"https://mp.weixin.qq.com/s/BjXtnEEVCQiPOy-_qCNM4g\">blog</a>]，[<a\r\nhref=\"https://openlmlab.github.io/MOSS-RLHF/\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/togethercomputer/OpenChatKit\">测试链接</a>]，[<a\r\nhref=\"https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B\">模型权重</a>]，[<a\r\nhref=\"https://laion.ai/blog/oig-dataset/\">数据集</a>]</p>\r\n<h3 id=\"openchatkit\">OpenChatKit</h3>\r\n<p>【ChatGPT开源平替OpenChatKit：参数量200亿，在4300万条指令上微调而成】[<a\r\nhref=\"https://mp.weixin.qq.com/s/9Av3nhJLrcYAsBW9vVGjTw\">blog</a>]，[<a\r\nhref=\"https://github.com/togethercomputer/OpenChatKit\">code</a>]，[<a\r\nhref=\"https://openlmlab.github.io/MOSS-RLHF/paper/SecretsOfRLHFPart1.pdf\">技术报告</a>]</p>\r\n<h3 id=\"openassistant\">OpenAssistant</h3>\r\n<p>【ChatGPT全球最大开源平替OpenAssistant，基于Pythia和LLaMA微调而来，主要用于训练人类标注的数据，支持35种语言，免费可用RLHF数据】[<a\r\nhref=\"https://open-assistant.io/chat\">官网</a>]，[<a\r\nhref=\"https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view\">paper</a>]，[<a\r\nhref=\"https://github.com/LAION-AI/Open-Assistant\">code</a>]，[<a\r\nhref=\"https://huggingface.co/datasets/OpenAssistant/oasst1\">dataset</a>]，[<a\r\nhref=\"https://youtu.be/ddG2fM9i4Kk\">youtube</a>]</p>\r\n<h3 id=\"webcpm\">WebCPM</h3>\r\n<p>【首个联网支持中文问答开源模型WebCPM】[<a\r\nhref=\"https://arxiv.org/abs/2305.06849\">paper</a>]，[<a\r\nhref=\"https://github.com/thunlp/WebCPM\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/m4zsF2HDFHSKc23Oq0O98w\">blog</a>]</p>\r\n<h3 id=\"llama以及扩展\">LLaMA以及扩展</h3>\r\n<p><strong>【LLaMA】</strong>【Meta开放小模型LLaMA，性能超过GPT-3】[<a\r\nhref=\"https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/\">paper</a>]，[<a\r\nhref=\"https://github.com/facebookresearch/llama\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485822&amp;idx=1&amp;sn=b365d93a0a08769aef77f34069da1422&amp;chksm=ced54a9af9a2c38cd5779284b5e9ae573846153e7dc00961dc163664a657d6a3fa5c8c14c7d2&amp;token=447941009&amp;lang=zh_CN#rd\">blog1</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/fGNuTcYE8QI9_JKS9LcQ7w\">blog2</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/B9Ue0ihUGAFjT_X__R2u8Q\">详聊LLaMA大模型的技术细节</a>]</p>\r\n<p><strong>【LLaMA 2】【LLaMA 2技术细节详细介绍！】</strong>[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247486800&amp;idx=1&amp;sn=9b629ca41b9f6b4feedad94363a17253&amp;chksm=ced54eb4f9a2c7a2a5b20c182981b4323b18509f2ca8f482c2a8cdbb29bf570488bdcd280eb6&amp;token=882149695&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/UnzhBJjZfPXsaSu8gNnosw\">在 Hugging Face\r\n上玩转LLaMA 2</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/Mee7sMq_bxLpIOOr91li9A\">伯克利AI博士详解Llama\r\n2的技术细节</a>]，[<a\r\nhref=\"https://github.com/michael-wzhu/Chinese-LlaMA2\">Chinese-LlaMA2</a>]</p>\r\n<p><strong>【llama2.c】</strong>【OpenAI联创Karpathy爱上羊驼：纯C代码实现婴儿Llama2，MacBook可运行，已揽1.6k星】[<a\r\nhref=\"https://mp.weixin.qq.com/s/VVR6N1duJM5vAU5cY9FrDQ\">blog</a>]，[<a\r\nhref=\"https://github.com/karpathy/llama2.c\">code</a>]</p>\r\n<p><strong>【LLaMA评测】</strong>[<a\r\nhref=\"https://mp.weixin.qq.com/s/kImwfWWtXMmEDVOhJZ4dJg\">blog</a>]</p>\r\n<p><strong>【Alpaca】</strong>【斯坦福发布了一个由LLaMA\r\n7B微调的模型Alpaca（羊驼），训练3小时，性能比肩GPT-3.5】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485890&amp;idx=1&amp;sn=2d1414fc3751353c31b946b3e954a465&amp;chksm=ced54a26f9a2c330082e8c0014c96a6d9bef62e3581875031f203268a11fad09645a75b482b0&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]，[<a\r\nhref=\"https://crfm.stanford.edu/2023/03/13/alpaca.html\">官网</a>]，[<a\r\nhref=\"https://crfm.stanford.edu/alpaca\">model</a>]，[<a\r\nhref=\"https://github.com/tatsu-lab/stanford_alpaca\">code</a>]</p>\r\n<p><strong>【Alpaca-CoT】</strong>【Alpaca-CoT：多接口统一的轻量级LLM指令微调平台】[<a\r\nhref=\"https://github.com/PhoebusSi/Alpaca-CoT\">code</a>]，[<a\r\nhref=\"https://sota.jiqizhixin.com/project/alpaca-cot\">官网</a>]</p>\r\n<p><strong>【BiLLa】</strong>【BiLLa 是开源的推理能力增强的中英双语\r\nLLaMA 模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/8KDpDC6Fkb_61gFfkcT8TQ\">blog</a>]，[<a\r\nhref=\"https://github.com/Neutralzz/BiLLa\">code</a>]</p>\r\n<p><strong>【CaMA】</strong>【一种支持中英语言的LLaMA模型】[<a\r\nhref=\"https://github.com/zjunlp/CaMA\">code</a>]</p>\r\n<p><strong>【ChatLLaMA】</strong>【初创公司 Nebuly\r\nAI在LLaMA基础上加入RLHF 开源 ChatLLaMA 训练方法】[<a\r\nhref=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama\">code</a>]</p>\r\n<p><strong>【ColossalAI】</strong>【完整复现ChatGPT全流程】[<a\r\nhref=\"https://github.com/hpcaitech/ColossalAI\">code</a>]</p>\r\n<p><strong>【ColossalChat】</strong>【用于克隆 ChatGPT 和完整 RLHF\r\n管道的开源解决方案】[<a\r\nhref=\"https://github.com/hpcaitech/ColossalAI\">code</a>]，[<a\r\nhref=\"https://syncedreview.com/2023/03/29/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline/\">blog</a>]</p>\r\n<p><strong>【CAMEL】</strong>【从LLaMA衍生并适应临床的模型】[<a\r\nhref=\"https://github.com/starmpcc/CAMEL\">code</a>]，[<a\r\nhref=\"https://starmpcc.github.io/CAMEL/\">blog</a>]</p>\r\n<p><strong>【草本（原华驼）】</strong>【让LLaMA模型成为中医专家】[<a\r\nhref=\"https://arxiv.org/pdf/2304.06975v1.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/TYpc_63qDlR6MwscxCKKhA\">blog1</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/iuQANmwCS7AXQRik7HwQPg\">blog2</a>]</p>\r\n<p><strong>【DB-GPT】</strong>【基于vicuna-13b和FastChat的开源实验项目】[<a\r\nhref=\"https://github.com/csunny/DB-GPT\">code</a>]</p>\r\n<p><strong>【DeepSpeed-Chat】</strong>【最强ChatGPT训练框架，一键完成RLHF训练！\r\n】[<a\r\nhref=\"https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/kVEBUF20u4SUsHelF39o8Q\">blog</a>]</p>\r\n<p><strong>【ExpertLLaMA】</strong>【一个使用ExpertPrompting构建的开源聊天机器人，其能力达到ChatGPT的96%。】[<a\r\nhref=\"https://github.com/OFA-Sys/ExpertLLaMA\">code</a>]</p>\r\n<p><strong>【FreedomGPT】</strong>【FreedomGPT使用Electron 和\r\nReact构建，它是一个桌面应用程序，允许用户在他们的本地机器上运行LLaMA。】[<a\r\nhref=\"https://freedomgpt.com/\">官网地址</a>]</p>\r\n<p><strong>【FLAN】</strong>【【LLM系列之FLAN】Scaling\r\nInstruction-Finetuned Language Models】[<a\r\nhref=\"https://mp.weixin.qq.com/s/5jEJH6UBHrk_ILbrLsd6TQ\">blog</a>]</p>\r\n<p><strong>【GoGPT/GoGPT2】</strong>【基于Llama/Llama\r\n2训练的底座大模型,再扩充词表+继续预训练】[<a\r\nhref=\"https://github.com/yanqiangmiffy/GoGPT\">GoGPT code</a>]，[<a\r\nhref=\"https://huggingface.co/golaxy/gogpt2-7b\">GoGPT2 code</a>]</p>\r\n<p><strong>【Koala】</strong>【加州大学BAIR团队提出Koala：学术研究的对话模型】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25284\">blog_zh</a>]，[<a\r\nhref=\"https://bair.berkeley.edu/blog/2023/04/03/koala/\">blog_en</a>]</p>\r\n<p><strong>【LLaMA-Adapter】</strong>【<strong>LLaMA-Adapter</strong>，一种用于微调指令遵循<a\r\nhref=\"https://github.com/facebookresearch/llama\">LLaMA</a>模型的轻量级自适应方法，使用<a\r\nhref=\"https://github.com/tatsu-lab/stanford_alpaca\">Stanford\r\nAlpaca</a>提供的 52K 数据。】[<a\r\nhref=\"https://arxiv.org/pdf/2303.16199.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/ZrrSkywalker/LLaMA-Adapter\">code</a>]</p>\r\n<p><strong>【LaVIN】</strong>【MMA方案让羊驼模型实现多模态：训练时间减少71.4%，成本节省99.9%】[<a\r\nhref=\"https://arxiv.org/pdf/2305.15023.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/luogen1996/LaVIN\">code</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/MRLYk1b7VJ_b6OmJ9mzkdw\">blog</a>]</p>\r\n<p><strong>【lit-llama】</strong>【基于nanoGPT的LLaMA语言模型，支持量化、LoRA微调和预训练】[<a\r\nhref=\"https://github.com/Lightning-AI/lit-llama\">code</a>]</p>\r\n<p><strong>【LlamaIndex】</strong>【面向QA 系统的全新文档摘要索引】[<a\r\nhref=\"https://mp.weixin.qq.com/s/1zvXlcGfVdxU8_Pj5f2E1g\">blog</a>]</p>\r\n<p><strong>【llama.cpp】</strong>【量化130亿参数LLaMA模型的llama.cpp，推理仅需4GB内存】[<a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485875&amp;idx=1&amp;sn=a4e09d31802c087f1f47bd292e380c19&amp;chksm=ced54a57f9a2c341935b81aa27824dfa740beb7ce33289e0cb5190b5910040c0904371b7e8a0&amp;token=447941009&amp;lang=zh_CN#rd\">blog</a>]</p>\r\n<p><strong>【llama.cpp优化版】</strong>【Edge AI 变得更快|在 C/C++\r\n中移植 Facebook 的 LLaMA 模型】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25307\">blog</a>]</p>\r\n<p><strong>【LIMA】</strong>【使用 LoRA 技术对 LLaMA 65B\r\n大模型进行微调及推理】[<a\r\nhref=\"https://mp.weixin.qq.com/s?search_click_id=7213828026277652651-1688375605291-1083947599&amp;__biz=MjM5ODExNDA2MA==&amp;mid=2449961473&amp;idx=2&amp;sn=f080fa7b1b5657db9872724caee56519&amp;chksm=b13c7462864bfd741f0f061b87187f2cde36b68020cfe3402717a6858563311cb642eb340989&amp;rd2werd=1&amp;key=ea1d916ce49bb536ce48f3aba8e329d1e1aa6fdcda4f73580b0a5adbd624721e6a974570fd6ef2823ecfa6c95e2dc09179b51e440e9179f79d0ba01f62cf795d6c697f95bf05a28904f4172b11e1ce873a2d7a0e85c74d509e916176aacb43657fd11a6de7611d65bd4ae82315835aa138a423887a219f2971c6a525679fd805&amp;ascene=65&amp;uin=MTkwNzA5OTA4Mw%3D%3D&amp;devicetype=iMac+MacBookPro13%2C2+OSX+OSX+12.6.7+build(21G651)&amp;version=13080109&amp;nettype=WIFI&amp;lang=zh_CN&amp;countrycode=CN&amp;fontScale=100&amp;exportkey=n_ChQIAhIQ0Z339%2BFUk%2Bp0YpfMQjB%2BhxKDAgIE97dBBAEAAAAAANJyNCKr%2F3UAAAAOpnltbLcz9gKNyK89dVj0q5AacL9r2sPbvlDuJo6SwYSJ2wbfYGvc3EDxuk%2BMQS0vl8RLluMN%2Fuh9u2LxBZTHTiuQct62Bjib68qd1EvB8CgGKMV34B5%2BKHCutInPzdE9Uac6dxp0VYtd%2BJnEwljL8jf7mWZdwTkPdEZl1P0OEb3HFzczXelqDR3h7D2xEVmQuFHGIeVi7iPOHMT0AWhhGLdbrVhCKbPT3%2BX9FPOLjJSql2UD95dTmSzZKqdvOIMGpD5t%2F98jDuMUojr9HUMdvljQ1XkiJVnd%2FbqSsLS3S5t7E%2Ftjmjb9g7IxWkY%3D&amp;acctmode=0&amp;pass_ticket=mJ3t3nBN%2BXhKCYp9bzJSkTl%2B9PwobzvYen%2F5Kv4kpcj1Lig98d0DXbcAyqBW0vaB&amp;wx_header=0\">blog</a>]</p>\r\n<p><strong>【PaLM】</strong>【【LLM系列之PaLM】PaLM: Scaling Language\r\nModeling with Pathways】[<a\r\nhref=\"https://mp.weixin.qq.com/s/MT1xCsJp98BM-lkuOKJF-A\">blog</a>]</p>\r\n<p><strong>【StackLLaMA】</strong>【使用 RLHF 训练 LLaMA 的实践指南】[<a\r\nhref=\"https://hub.baai.ac.cn/view/25341\">blog_zh</a>]，[<a\r\nhref=\"https://huggingface.co/blog/stackllama\">blog_en</a>]</p>\r\n<p><strong>【Vicuna】</strong>【通过对从ShareGPT收集的用户共享对话进行微调的LLaMA训练，Vicuna-13B达到了OpenAI\r\nChatGPT和Google Bard 90%*以上的质量 】[<a\r\nhref=\"https://vicuna.lmsys.org/\">Vicuna官网地址</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25328\">blog</a>]</p>\r\n<h2 id=\"图像视频生成\">图像、视频生成</h2>\r\n<p><strong>【博客】</strong>【Genmo\r\nChat】【这是一款创造性的copilot，使用GPT-4和一大套生成人工智能工具创建并编辑您需要的任何视频或图像。\r\n】[<a href=\"https://www.genmo.ai/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【BlenderGPT】【<strong>一款基于GPT-4的扩展程序BlenderGPT开源，这是一个由GPT3/4驱动的全能AI编辑助手，为Blender提供支持</strong>\r\n】[<a href=\"https://github.com/gd3kr/BlenderGPT\">code</a>]</p>\r\n<p><strong>【博客】</strong>【Firefly】【Adobe制造了一个人工智能图像生成器--并表示它没有窃取艺术家的作品来做这件事\r\n】[<a\r\nhref=\"https://www.theverge.com/2023/3/21/23648315/adobe-firefly-ai-image-generator-announced\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Bing Image Creator】【微软推出Bing Image\r\nCreator，用户可根据文本提示创建图片】[<a\r\nhref=\"https://techcrunch.com/2023/03/21/microsoft-brings-openais-dall-e-image-creator-to-the-new-bing/\">blog</a>]</p>\r\n<p><strong>【博客】</strong>【Hugging Face\r\n现已支持使用达摩院text-to-video模型从文本生成视频】[<a\r\nhref=\"https://modelscope.cn/models/damo/text-to-video-synthesis/summary\">模型地址</a>]</p>\r\n<p><strong>【论文】</strong>【最新女娲大模型，中科院提出NUWA-XL：扩散模型中的扩散，生成超长视频】[<a\r\nhref=\"https://arxiv.org/pdf/2303.12346.pdf\">paper</a>]，[<a\r\nhref=\"https://msra-nuwa.azurewebsites.net/#/\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【艾伦AI研究院 &amp; 华盛顿大学 |\r\nCHAMPAGNE：从大规模的网络视频中学习真实世界的对话】[<a\r\nhref=\"https://arxiv.org/pdf/2303.09713.pdf\">paper</a>]，[<a\r\nhref=\"https://seungjuhan.me/champagne\">code</a>]</p>\r\n<p><strong>【论文】</strong>【用AI直接复现你在想什么，Stable\r\nDiffusion逼真复现图像】[<a\r\nhref=\"https://sites.google.com/view/stablediffusion-with-brain/\">paper</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/gIwj2eqNph8jHWOhYYEXIg\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【Stable\r\nDiffusion公司新作Gen-1：基于扩散模型的视频合成新模型，加特效杠杠的！】[<a\r\nhref=\"https://arxiv.org/pdf/2302.03011\">paper</a>]，[<a\r\nhref=\"https://research.runwayml.com/gen1\">site</a>]</p>\r\n<p><strong>【论文】</strong>【使用Diffusers 实现 ControlNet\r\n高速推理】[<a\r\nhref=\"https://mp.weixin.qq.com/s/k8rE9GrF97E-0TKJhih9kw\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【文生图引入ControlNet，深度、边缘信息全能复用\r\n】[<a href=\"https://arxiv.org/pdf/2302.05543.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/lllyasviel/ControlNet\">code</a>]</p>\r\n<p><strong>【论文】</strong>【ChatGPT｜可用于AI绘画，效果飞升47% 】[<a\r\nhref=\"https://arxiv.org/abs/2302.12192\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【智源研究院提出SegGPT：\r\n一个用于分割上下文中所有事物的通用模型】[<a\r\nhref=\"https://arxiv.org/pdf/2304.03284.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【OpenAI开源新模型代码库Consistency\r\nModels，无需对抗训练即可快速获得高质量样本】[<a\r\nhref=\"https://arxiv.org/abs/2303.01469\">paper</a>]，[<a\r\nhref=\"https://github.com/openai/consistency_models\">code</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25445\">blog</a>]</p>\r\n<p><strong>【可控图文大模型】</strong>【伯克利&amp;微软｜用GPT-4进行可控的文本-图像生成】[<a\r\nhref=\"https://arxiv.org/abs/2305.18583\">paper</a>]</p>\r\n<h2 id=\"代码生成\">代码生成</h2>\r\n<p><strong>【综述】</strong>【代码大模型综述：中科院和MSRA调研27个LLMs，并给出5个有趣挑战】[<a\r\nhref=\"https://mp.weixin.qq.com/s/t2SMftox6546E7kvRgQMnA\">blog</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2212.09420\">paper</a>]，[<a\r\nhref=\"https://nl2code.github.io\">项目主页</a>]</p>\r\n<p><strong>【博客】</strong>【GPT-Engineer｜提需求即可生成整个代码库，已20K星】[<a\r\nhref=\"https://mp.weixin.qq.com/s/rtsVsQbh7NnTh5vjgNMJHQ\">blog</a>]，[<a\r\nhref=\"https://github.com/AntonOsika/gpt-engineer\">code</a>]</p>\r\n<p><strong>【博客】</strong>【StarCoder: 最先进的代码大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/f-WwzLcEO-ZJczI-_bZh3Q\">blog</a>]</p>\r\n<p><strong>【论文】</strong>【北京大学：具有大语言模型的自我规划代码生成】[<a\r\nhref=\"https://arxiv.org/pdf/2303.06689.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【谷歌提出Self-Debugging:教导大型语言模型进行自我调试】[<a\r\nhref=\"https://arxiv.org/pdf/2304.05128.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【通过自我改进实现更好的代码语言模型，显著提高模型生成任务的性能】[<a\r\nhref=\"https://arxiv.org/pdf/2304.01228.pdf\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【Baldur:\r\n基于大型语言模型的完全证明生成与修复】[<a\r\nhref=\"https://arxiv.org/abs/2303.04910\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【CodeGeeX: A Pre-Trained Model for Code\r\nGeneration with Multilingual Evaluations on HumanEval-X 】[<a\r\nhref=\"https://arxiv.org/pdf/2303.17568.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/THUDM/CodeGeeX\">code</a>]</p>\r\n<p><strong>【论文】</strong>【代码模型 CodeGeeX2-6B\r\n开源，最低6GB显存，性能优于StarCoder】[<a\r\nhref=\"https://mp.weixin.qq.com/s/roQSCo-7s361P3TmJjjZjA\">blog</a>]，[<a\r\nhref=\"https://github.com/THUDM/CodeGeeX2\">code</a>]</p>\r\n<p><strong>【论文】</strong>【CodeT5+：非常灵活的、面向代码理解和生成的开放大型代码语言模型】[<a\r\nhref=\"https://arxiv.org/abs/2305.07922\">paper</a>]</p>\r\n<p>【<strong>工具</strong>】【Cursor：一个集成了 GPT-4\r\n的国内直接可以访问的，优秀而强大的免费代码生成器，可以帮助你快速编写、编辑和讨论代码。】[<a\r\nhref=\"https://www.cursor.so/\">官网地址</a>]</p>\r\n<p><strong>【论文】</strong>【MIT最新研究：利用大预言模型生成Code】[<a\r\nhref=\"https://arxiv.org/abs/2303.05510\">paper</a>]，[<a\r\nhref=\"https://github.com/shunzh/Code-AI-Tree-Search\">code</a>]，[<a\r\nhref=\"https://codeaimcts.github.io/\">项目网址</a>]</p>\r\n<p><strong>【论文】</strong>【MathPrompter:\r\n基于大型语言模型的数学推理】[<a\r\nhref=\"https://arxiv.org/abs/2303.05398\">paper</a>]</p>\r\n<p><strong>【论文】</strong>【MIT最新研究：利用大语言模型生成Code】[<a\r\nhref=\"https://arxiv.org/abs/2303.05510\">paper</a>]，[<a\r\nhref=\"https://github.com/shunzh/Code-AI-Tree-Search\">code</a>]，[<a\r\nhref=\"https://codeaimcts.github.io/\">官网地址</a>]</p>\r\n<h2 id=\"语音生成\">语音生成</h2>\r\n<p><strong>【论文】</strong>【Meta AI研究者推出MUSICGEN】[<a\r\nhref=\"https://arxiv.org/pdf/2306.05284.pdf\">paper</a>]，[<a\r\nhref=\"https://the-decoder.com/metas-open-source-ai-musicgen-turns-text-and-melody-into-new-songs/\">blog</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/facebook/MusicGen\">demo</a>]</p>\r\n<p><strong>【论文】</strong>【文字、图片一键生成逼真音效，音频界AIGC来了】[<a\r\nhref=\"https://arxiv.org/abs/2301.12661\">paper</a>]，[<a\r\nhref=\"https://text-to-audio.github.io\">code</a>]</p>\r\n<p>【<strong>论文</strong>】【音乐可视化｜利用大型语言模型和文本到图像模型帮助生成「音乐迪斯科」】[<a\r\nhref=\"https://arxiv.org/pdf/2304.08551.pdf\">paper</a>]，[<a\r\nhref=\"https://hub.baai.ac.cn/view/25517\">blog</a>]</p>\r\n<p>【<strong>论文</strong>】【MetaAI发布第一个生成的人工智能语音模型Voicebox】[<a\r\nhref=\"https://hub.baai.ac.cn/view/27492\">blog</a>]，[<a\r\nhref=\"https://research.facebook.com/file/649409006862002/paper_fixed.pdf\">paper</a>]</p>\r\n<h2 id=\"多模态生成\">多模态生成</h2>\r\n<p><strong>【BLIP-2】</strong>【高效训练多模态大模型（BLIP-2）】[<a\r\nhref=\"https://arxiv.org/abs/2301.12597\">paper</a>]，[<a\r\nhref=\"https://github.com/salesforce/LAVIS/tree/main/projects/blip2\">code</a>]，[<a\r\nhref=\"https://huggingface.co/spaces/Salesforce/BLIP2\">demo</a>]，[<a\r\nhref=\"https://huggingface.co/docs/transformers/main/en/model_doc/blip-2\">doc</a>]，[<a\r\nhref=\"https://github.com/salesforce/LAVIS\">fine-tuing</a>]，[<a\r\nhref=\"https://hf.co/spaces/Salesforce/BLIP2\">hugging face\r\nspaces</a>]</p>\r\n<p><strong>【VisCPM】</strong>【SOTA 开源中文多模态大模型】[<a\r\nhref=\"https://mp.weixin.qq.com/s/Fgfbs1vV7RF6kpyk4bfIYw\">blog</a>]，[<a\r\nhref=\"https://github.com/OpenBMB/VisCPM\">code</a>]</p>\r\n<p><strong>【HuggingFace Transformers\r\nAgents】</strong>【一键控制10万多个AI模型，HuggingFace给类ChatGPT模型们做了个「APP\r\nStore」】[<a\r\nhref=\"https://huggingface.co/docs/transformers/transformers_agents\">demo</a>]，[<a\r\nhref=\"https://mp.weixin.qq.com/s/8gyTqT1B4C2Da_6dmtaNiw\">blog</a>]</p>\r\n<p><strong>【LLaVA】</strong>【熔岩羊驼LLaVA来了：像GPT-4一样可以看图聊天，无需邀请码，在线可玩】[<a\r\nhref=\"https://arxiv.org/pdf/2304.08485.pdf\">paper</a>]，[<a\r\nhref=\"https://llava-vl.github.io/\">introduce</a>]</p>\r\n<p><strong>【UniDiffuser】</strong>【清华朱军团队开源UniDiffuser：首个基于Transformer的多模态扩散大模型！文图互生、改写全拿下！】[<a\r\nhref=\"https://ml.cs.tsinghua.edu.cn/diffusion/unidiffuser.pdf\">paper</a>]，[<a\r\nhref=\"https://github.com/thu-ml/unidiffuser\">code</a>]</p>\r\n<p><strong>【Video-LLaMA】</strong>【人机视频对话｜Video-LLaMA多模态框架，使大型语言模型具备了理解视频内容的能力】[<a\r\nhref=\"https://arxiv.org/abs/2306.02858\">paper</a>]</p>\r\n<p><strong>【X-LLM】</strong>【多模态语言训练大模型】[<a\r\nhref=\"https://x-llm.github.io/\">项目地址</a>]，[<a\r\nhref=\"https://arxiv.org/abs/2305.04160\">paper</a>]</p>\r\n<h1\r\nid=\"四构筑大语言模型应用应用开发与架构设计\">四、构筑大语言模型应用：应用开发与架构设计</h1>\r\n<p>一系列的流行的或者不流行的开源项目，涉及如下：</p>\r\n<ul>\r\n<li>LLM 能力的充分运用\r\n<ul>\r\n<li>Prompt 编写：Prompt 学习与编写模式</li>\r\n<li>Prompt 管理：Prompt 即代码</li>\r\n</ul></li>\r\n<li>LLM 下的软件开发工序及应用架构设计\r\n<ul>\r\n<li>新的交互设计：Chat 模式</li>\r\n<li>大模型友好的工序：基于 AI 2.0 （ChatGPT +\r\nCopilot）如何去设计软件开发流程</li>\r\n<li>LLM 应用架构的设计与落地：Unit Mesh</li>\r\n</ul></li>\r\n<li>面向特定场景的 LLM 应用\r\n<ul>\r\n<li>基于开源模型构建自己的模型：特定场景的模型微调 + LLMOps</li>\r\n<li>上下文工程（prompt 工程）：LLM 应用的核心</li>\r\n</ul></li>\r\n</ul>\r\n<p>围绕于上述的一系列内容，我们也在思考软件开发能给我们带来了什么。所以，我重新整理了过去半年的一些思考、文章，重新编写了这本开源电子书，希望能够帮助到大家。</p>\r\n<p>相关开源项目如下（包括但是不限于）：</p>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 21%\" />\r\n<col style=\"width: 44%\" />\r\n<col style=\"width: 6%\" />\r\n<col style=\"width: 27%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>名称</th>\r\n<th>描述</th>\r\n<th>类型</th>\r\n<th>Stars</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/prompt-engineering/understand-prompt\">理解\r\nPrompt</a></td>\r\n<td>基于编程、绘画、写作的 AI 探索与总结。</td>\r\n<td>文档</td>\r\n<td><img\r\nsrc=\"https://img.shields.io/github/stars/prompt-engineering/understand-prompt\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/prompt-engineering/prompt-patterns\">Prompt\r\n编写模式</a></td>\r\n<td>如何将思维框架赋予机器，以设计模式的形式来思考 prompt。</td>\r\n<td>文档</td>\r\n<td><img\r\nsrc=\"https://img.shields.io/github/stars/prompt-engineering/prompt-patterns\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/prompt-engineering/click-prompt\">ClickPrompt</a></td>\r\n<td>用于一键轻松查看、分享和执行您的 Prompt。</td>\r\n<td>应用</td>\r\n<td><img\r\nsrc=\"https://img.shields.io/github/stars/prompt-engineering/click-prompt\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/prompt-engineering/chat-visual-novel\">ChatVisualNovel</a></td>\r\n<td>基于 ChatGPT 的定制化视觉小说引擎</td>\r\n<td>应用</td>\r\n<td><img\r\nsrc=\"https://img.shields.io/github/stars/prompt-engineering/chat-visual-novel\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/prompt-engineering/chat-flow\">ChatFlow</a></td>\r\n<td>打造个性化 ChatGPT 流程，构建自动化之路。</td>\r\n<td>框架</td>\r\n<td><img\r\nsrc=\"https://img.shields.io/github/stars/prompt-engineering/chat-flow\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/unit-mesh/unit-mesh\">Unit Mesh</a></td>\r\n<td>基于 AI 为核心的软件 2.0 思想的软件架构。</td>\r\n<td>架构</td>\r\n<td><img src=\"https://img.shields.io/github/stars/unit-mesh/unit-mesh\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/unit-mesh/unit-minions\">Unit\r\nMinions</a></td>\r\n<td>AI 研发提效研究：自己动手训练 LoRA</td>\r\n<td>微调教程、指南、数据集</td>\r\n<td><img\r\nsrc=\"https://img.shields.io/github/stars/unit-mesh/unit-minions\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/unit-mesh/unit-runtime\">Unit\r\nRuntime</a></td>\r\n<td>一个 ChatGPT 等 AI\r\n代码的运行环境，可一键启动并实时交互，帮助您快速构建和测试 AI\r\n代码。</td>\r\n<td>基础设施</td>\r\n<td><img\r\nsrc=\"https://img.shields.io/github/stars/unit-mesh/unit-runtime\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/unit-mesh/devti\">DevTi</a></td>\r\n<td>基于 LLM\r\n的微调来提供全面智能化解决方案，助力开发人员高效完成开发任务，以实现自动化用户任务拆解、用户故事生成、自动化代码生成、自动化测试生成等等。</td>\r\n<td>微调代码</td>\r\n<td><img src=\"https://img.shields.io/github/stars/unit-mesh/devti\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/unit-mesh/auto-dev\">AutoDev</a></td>\r\n<td>一款 Intellij IDEA 的 LLM/AI 辅助编程插件。AutoDev\r\n能够与您的需求管理系统（例如 Jira、Trello、Github Issue\r\n等）直接对接。</td>\r\n<td>IDEA 插件</td>\r\n<td><img src=\"https://img.shields.io/github/stars/unit-mesh/auto-dev\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/archguard/co-mate\">ArchGuard\r\nCo-mate</a></td>\r\n<td>基于人工智能技术的架构副驾驶、设计和治理工具</td>\r\n<td>架构协同应用</td>\r\n<td><img src=\"https://img.shields.io/github/stars/archguard/co-mate\"\r\nalt=\"GitHub Repo stars\" /></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h1\r\nid=\"五promptllm论文开源数据模型aigc应用\">五、Prompt&amp;LLM论文、开源数据&amp;模型、AIGC应用</h1>\r\n<p>目录顺序如下</p>\r\n<ul>\r\n<li>国内外，垂直领域大模型</li>\r\n<li>Agent和指令微调等训练框架</li>\r\n<li>开源指令，预训练，rlhf，对话，agent训练数据梳理</li>\r\n<li>AIGC相关应用</li>\r\n<li>prompt写作指南和5星博客等资源梳理</li>\r\n<li>Prompt和LLM论文细分方向梳理</li>\r\n</ul>\r\n<p>参考来源：https://github.com/DSXiangLi/DecryptPrompt/tree/main</p>\r\n<h1 id=\"decryptprompt\">DecryptPrompt</h1>\r\n<blockquote>\r\n<p>如果LLM的突然到来让你感到沮丧，不妨读下主目录的Choose Your Weapon\r\nSurvival Strategies for Depressed AI Academics 持续更新以下内容，Star to\r\nkeep updated~</p>\r\n</blockquote>\r\n<p>目录顺序如下</p>\r\n<ol type=\"1\">\r\n<li>国内外，垂直领域大模型</li>\r\n<li>Agent和指令微调等训练框架</li>\r\n<li>开源指令，预训练，rlhf，对话，agent训练数据梳理</li>\r\n<li>AIGC相关应用</li>\r\n<li>prompt写作指南和5星博客等资源梳理</li>\r\n<li>Prompt和LLM论文细分方向梳理</li>\r\n</ol>\r\n<h2 id=\"my-blogs-chatgpt应用\">My blogs &amp; ChatGPT应用</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2215545?areaSource=&amp;traceId=\">解密Prompt系列1.\r\nTunning-Free Prompt：GPT2 &amp; GPT3 &amp; LAMA &amp;\r\nAutoPrompt</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2223355?areaSource=&amp;traceId=\">解密Prompt系列2.\r\n冻结Prompt微调LM： T5 &amp; PET &amp; LM-BFF</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2237259?areaSource=&amp;traceId=\">解密Prompt系列3.\r\n冻结LM微调Prompt: Prefix-tuning &amp; Prompt-tuning &amp;\r\nP-tuning</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2245094?areaSource=&amp;traceId=\">解密Prompt系列4.\r\n升级Instruction Tuning：Flan/T0/InstructGPT/TKInstruct</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2260697?areaSource=&amp;traceId=\">解密prompt系列5.\r\nAPE+SELF=自动化指令集构建代码实现</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2276508\">解密Prompt系列6.\r\nlora指令微调扣细节-请冷静,1个小时真不够~</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/old/2289566?areaSource=&amp;traceId=\">解密Prompt系列7.\r\n偏好对齐RLHF-OpenAI·DeepMind·Anthropic对比分析</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/old/2295783?areaSource=&amp;traceId=\">解密Prompt系列8.\r\n无需训练让LLM支持超长输入:知识库 &amp; Unlimiformer &amp; PCW &amp;\r\nNBCE</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/old/2296079?areaSource=&amp;traceId=\">解密Prompt系列9.\r\n模型复杂推理-思维链基础和进阶玩法</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/old/2298660\">解密Prompt系列10.\r\n思维链COT原理探究</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/old/2301999\">解密Prompt系列11.\r\n小模型也能COT，先天不足后天补</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2305421\">解密Prompt系列12.\r\nLLM Agent零微调范式 ReAct &amp; Self Ask</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2312674\">解密Prompt系列13.\r\nLLM Agent指令微调方案: Toolformer &amp; Gorilla</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2319879\">解密Prompt系列14.\r\nLLM Agent之搜索应用设计：WebGPT &amp; WebGLM &amp; WebCPM</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2328749\">解密Prompt系列15.\r\nLLM Agent之数据库应用设计：DIN &amp; C3 &amp; SQL-Palm &amp;\r\nBIRD</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2333495\">解密Prompt系列16.\r\nLLM对齐经验之数据越少越好？LTD &amp; LIMA &amp; AlpaGasus</a></li>\r\n<li><a\r\nhref=\"https://cloud.tencent.com/developer/article/2338592\">解密Prompt系列17.\r\nLLM对齐方案再升级 WizardLM &amp; BackTranslation &amp;\r\nSELF-ALIGN</a></li>\r\n</ul>\r\n<h2 id=\"llms\">LLMS</h2>\r\n<h3 id=\"模型评测\">模型评测</h3>\r\n<blockquote>\r\n<p>大模型评估尚未出现北极星指标，榜单排名往往和实际使用能力存在较大差异，几天没看感觉有的榜单快被玩坏了......</p>\r\n</blockquote>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 59%\" />\r\n<col style=\"width: 40%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>榜单</th>\r\n<th>结果</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://tatsu-lab.github.io/alpaca_eval/\">AlpacaEval：LLM-based\r\nautomatic evaluation</a></td>\r\n<td>开源模型王者vicuna,openchat, wizardlm</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\">Huggingface\r\nOpen LLM Leaderboard</a></td>\r\n<td>MMLU只评估开源模型，Falcon夺冠，在Eleuther\r\nAI4个评估集上评估的LLM模型榜单,vicuna夺冠</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://lmsys.org/blog/2023-05-03-arena/\">Berkley出品大模型排位赛榜有准中文榜单</a></td>\r\n<td>Elo评分机制，GPT4自然是稳居第一，GPT4&gt;Claude&gt;GPT3.5&gt;Vicuna&gt;others</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/zeno-ml/zeno-build\">CMU开源聊天机器人评测应用</a></td>\r\n<td>ChatGPT&gt;Vicuna&gt;others；在对话场景中训练可能很重要</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/zhenbench/z-bench\">Z-Bench中文真格基金评测</a></td>\r\n<td>国产中文模型的编程可用性还相对较低，大家水平差不太多，两版ChatGLM提升明显</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/FranxYao/chain-of-thought-hub\">Chain-of-thought评估</a></td>\r\n<td>GSM8k, MATH等复杂问题排行榜</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651170429&amp;idx=1&amp;sn=b98af3bd14c9f97f1aa07f0f839bb3ec&amp;scene=21#wechat_redirect\">InfoQ\r\n大模型综合能力评估</a></td>\r\n<td>面向中文，ChatGPT&gt;文心一言&gt; Claude&gt;星火</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/OpenBMB/ToolBench\">ToolBench:\r\n工具调用评估榜单</a></td>\r\n<td>工具微调模型和ChatGPT进行对比，提供评测脚本</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/THUDM/AgentBench\">AgentBench:\r\n推理决策评估榜单</a></td>\r\n<td>清华联合多高校推出不同任务环境，例如购物，家居，操作系统等场景下模型推理决策能力</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://flageval.baai.ac.cn/#/home\">FlagEval</a></td>\r\n<td>智源出品主观+客观LLM评分榜单</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://bird-bench.github.io/\">Bird-Bench</a></td>\r\n<td>更贴合真实世界应用的超大数据库，需要领域知识的NL2SQL榜单，模型追赶人类尚有时日</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"http://103.238.162.37:31622/LeaderBoard\">kola</a></td>\r\n<td>以世界知识为核心的评价基准，包括已知的百科知识和未知的近90天网络发布内容，评价知识记忆，理解，应用和创造能力</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://cevalbenchmark.com/index.html#home\">CEVAL</a></td>\r\n<td>中文知识评估，覆盖52个学科，机器评价主要为多项选择</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/haonan-li/CMMLU\">CMMLU</a></td>\r\n<td>67个主题中文知识和推理能力评估，多项选择机器评估</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h3 id=\"国外开源模型\">国外开源模型</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 48%\" />\r\n<col style=\"width: 51%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>模型链接</th>\r\n<th>模型描述</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://ai.meta.com/llama/\">LLama2</a></td>\r\n<td>Open Meta带着可商用开源的羊驼2模型来了~</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/lm-sys/FastChat\">Vicuna</a></td>\r\n<td>Alpaca前成员等开源以LLama13B为基础使用ShareGPT指令微调的模型，提出了用GPT4来评测模型效果</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/nlpxucan/WizardLM\">WizardLM</a></td>\r\n<td>微软新发布13B，登顶AlpacaEval开源模型Top3，使用ChatGPT对指令进行复杂度进化微调LLama2</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://mistral.ai/news/announcing-mistral-7b/\">Mistral7B</a></td>\r\n<td>法国“openai”开源，超过llama2当前最好7B模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/imoneoi/openchat\">OpenChat</a></td>\r\n<td>80k ShareGPT对话微调LLama-2 13B开源模型中的战斗机</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://huggingface.co/KBlueLeaf/guanaco-7B-leh\">Guanaco</a></td>\r\n<td>LLama 7B基座，在alpaca52K数据上加入534K多语言指令数据微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/facebookresearch/llama\">LLaMA</a></td>\r\n<td>Meta开源指令微调LLM，规模70 亿到 650 亿不等</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://huggingface.co/mosaicml/mpt-7b-chat\">MPT</a></td>\r\n<td>MosaicML开源的预训练+指令微调的新模型，可商用，支持84k\r\ntokens超长输入</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://huggingface.co/tiiuae/falcon-40b\">Falcon</a></td>\r\n<td>Falcon由阿联酋技术研究所在超高质量1万亿Token上训练得到1B，7B，40B开源，免费商用！土豪们表示钱什么的格局小了</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1\">RedPajama</a></td>\r\n<td>RedPajama项目既开源预训练数据后开源3B，7B的预训练+指令微调模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://bair.berkeley.edu/blog/2023/04/03/koala/\">koala</a></td>\r\n<td>使用alpaca，HC3等开源指令集+\r\nShareGPT等ChatGPT数据微调llama，在榜单上排名较高</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama\">ChatLLaMA</a></td>\r\n<td>基于RLHF微调了LLaMA</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/tatsu-lab/stanford_alpaca\">Alpaca</a></td>\r\n<td>斯坦福开源的使用52k数据在7B的LLaMA上微调得到，</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/tloen/alpaca-lora\">Alpaca-lora</a></td>\r\n<td>LORA微调的LLaMA</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/IBM/Dromedary\">Dromedary</a></td>\r\n<td>IBM self-aligned model with the LLaMA base</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/hpcaitech/ColossalAI\">ColossalChat</a></td>\r\n<td>HPC-AI Tech开源的Llama+RLHF微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/Vision-CAIR/MiniGPT-4\">MiniGPT4</a></td>\r\n<td>Vicuna+BLIP2 文本视觉融合</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://huggingface.co/trl-lib/llama-7b-se-rl-peft\">StackLLama</a></td>\r\n<td>LLama使用Stackexchange数据+SFT+RL</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://huggingface.co/cerebras/Cerebras-GPT-13B\">Cerebras</a></td>\r\n<td>Cerebras开源了1亿到130亿的7个模型，从预训练数据到参数全开源</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://palm-e.github.io\">PaLM-E</a></td>\r\n<td>谷歌多模态大模型，540B的PaLM语言模型和22B的ViT视觉模型相结合，得到562B的PaLM-E模型，在机器人应用场景有了新的突破</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://huggingface.co/databricks/dolly-v2-7b\">Dolly-v2</a></td>\r\n<td>可商用 7b指令微调开源模型在GPT-J-6B上微调</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/togethercomputer/OpenChatKit\">OpenChatKit</a></td>\r\n<td>openai研究员打造GPT-NoX-20B微调+6B审核模型过滤</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/microsoft/unilm\">MetaLM</a></td>\r\n<td>微软开源的大规模自监督预训练模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://aws.amazon.com/cn/bedrock/titan/\">Amazon\r\nTitan</a></td>\r\n<td>亚马逊在aws上增加自家大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/metaseq/tree/main/projects/OPT\">OPT-IML</a></td>\r\n<td>Meta复刻GPT3，up to 175B, 不过效果并不及GPT3</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://huggingface.co/bigscience/bloom\">Bloom</a></td>\r\n<td>BigScience出品，规模最大176B</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://huggingface.co/bigscience/bloomz\">BloomZ</a></td>\r\n<td>BigScience出品, 基于Bloom微调</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/paperswithcode/galai\">Galacia</a></td>\r\n<td>和Bloom相似，更针对科研领域训练的模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/bigscience-workshop/t-zero\">T0</a></td>\r\n<td>BigScience出品，3B~11B的在T5进行指令微调的模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/turboderp/exllama\">EXLLama</a></td>\r\n<td>Python/C++/CUDA implementation of Llama for use with 4-bit GPTQ\r\nweight</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://huggingface.co/lmsys/longchat-13b-16k\">LongChat</a></td>\r\n<td>llama-13b使用condensing rotary embedding\r\ntechnique微调的长文本模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://huggingface.co/mosaicml/mpt-30b\">MPT-30B</a></td>\r\n<td>MosaicML开源的在8Ktoken上训练的大模型</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h3 id=\"国内开源模型\">国内开源模型</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 32%\" />\r\n<col style=\"width: 68%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>模型链接</th>\r\n<th>模型描述</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/thudm/chatglm2-6b\">ChatGLM2</a></td>\r\n<td>32K长文本，FlashAttention+Multi-Query\r\nAttenion的显存优化，更强推理能力，哈哈不过很多简单问题也硬要COT，中英平行能力似乎略有下降的ChatGLM2，但是免费商用！</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/THUDM/ChatGLM-6B\">ChatGLM</a></td>\r\n<td>清华开源的、支持中英双语的对话语言模型，使用了代码训练，指令微调和RLHF。chatglm2支持超长文本，可免费商用啦！</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/FlagAlpha/Llama2-Chinese\">LLama2-chinese</a></td>\r\n<td>没等太久中文预训练微调后的llama2它来了~</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/RUC-GSAI/YuLan-Chat\">YuLan-chat2</a></td>\r\n<td>高瓴人工智能基于Llama-2中英双语继续预训练+指令微调/对话微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-7B-Reward\">ziya</a></td>\r\n<td>IDEA研究院在7B/13B llama上继续预训练+SFT+RM+PPO+HFTT+COHFT+RBRS</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/baichuan-inc/baichuan-7B\">Baichuan</a></td>\r\n<td>百川智能开源7B大模型可商用免费</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/baichuan-inc/Baichuan2\">Baichuan2</a></td>\r\n<td>百川第二代，提供了7B/13B Base和chat的版本</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://ollama.ai/library/zephyr\">zephyr-7B</a></td>\r\n<td>HuggingFace 团队基于 UltraChat 和 UltraFeedback 训练了 Zephyr-7B\r\n模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/Xwin-LM/Xwin-LM\">XWin-LM</a></td>\r\n<td>llama2 + SFT + RLHF</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/ymcui/Chinese-LLaMA-Alpaca\">Chinese-LLaMA-Alpaca</a></td>\r\n<td>哈工大中文指令微调的LLaMA</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/OpenLMLab/MOSS\">Moss</a></td>\r\n<td>为复旦正名！开源了预训练，指令微调的全部数据和模型。可商用</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/QwenLM/Qwen-7B\">Qwen-7B</a></td>\r\n<td>阿里开源，可商用，通义千文7B模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/InternLM/InternLM\">IntenrLM</a></td>\r\n<td>书生浦语在过万亿 token 数据上训练的多语千亿参数基座模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/FlagAI-Open/Aquila2/blob/main/README_CN.md\">Aquila2</a></td>\r\n<td>智源更新Aquila2模型系列包括全新34B</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila\">Aquila</a></td>\r\n<td>智源开源7B大模型可商用免费</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/thunlp/UltraChat\">UltraLM系列</a></td>\r\n<td>面壁智能开源UltraLM13B，奖励模型UltraRM，和批评模型UltraCM</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://www.moonshot.cn/?ref=aihub.cn\">kimi Chat</a></td>\r\n<td>Moonshot上线超长文本LLM 可输入20W上文需要申请试用</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/dandelionsllm/pandallm\">PandaLLM</a></td>\r\n<td>LLAMA2上中文wiki继续预训练+COIG指令微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/xverse-ai/XVERSE-13B\">XVERSE</a></td>\r\n<td>据说中文超越llama2的元象开源模型13B模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/Neutralzz/BiLLa\">BiLLa</a></td>\r\n<td>LLama词表扩充预训练+预训练和任务1比1混合SFT+指令样本SFT三阶段训练</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/FreedomIntelligence/LLMZoo\">Phoenix</a></td>\r\n<td>港中文开源凤凰和奇美拉LLM，Bloom基座，40+语言支持</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://huggingface.co/GanjinZero/wombat-7b-delta\">Wombat-7B</a></td>\r\n<td>达摩院开源无需强化学习使用RRHF对齐的语言模型, alpaca基座</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/TigerResearch/TigerBot\">TigerBot</a></td>\r\n<td>虎博开源了7B 180B的模型以及预训练和微调语料</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a\r\nhref=\"https://github.com/LC1332/Luotuo-Chinese-LLM\">Luotuo</a></td>\r\n<td>中文指令微调的LLaMA，和ChatGLM</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/OpenBuddy/OpenBuddy\">OpenBuddy</a></td>\r\n<td>Llama 多语言对话微调模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/Facico/Chinese-Vicuna\">Chinese\r\nVincuna</a></td>\r\n<td>LLama 7B基座，使用Belle+Guanaco数据训练</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/CVI-SZU/Linly\">Linly</a></td>\r\n<td>Llama\r\n7B基座，使用belle+guanaco+pclue+firefly+CSL+newscommentary等7个指令微调数据集训练</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/yangjianxin1/Firefly\">Firefly</a></td>\r\n<td>中文2.6B模型，提升模型中文写作，古文能力，待开源全部训练代码，当前只有模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/project-baize/baize-chatbot\">Baize</a></td>\r\n<td>使用100k self-chat对话数据微调的LLama</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/LianjiaTech/BELLE\">BELLE</a></td>\r\n<td>使用ChatGPT生成数据对开源模型进行中文优化</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a\r\nhref=\"https://github.com/search?q=chatyuan&amp;type=repositories\">Chatyuan</a></td>\r\n<td>chatgpt出来后最早的国内开源对话模型，T5架构是下面PromptCLUE的衍生模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/clue-ai/PromptCLUE\">PromptCLUE</a></td>\r\n<td>多任务Prompt语言模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://www.alice-mind.com/portal#/\">PLUG</a></td>\r\n<td>阿里达摩院发布的大模型，提交申请会给下载链接</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://baai.ac.cn/\">CPM2.0</a></td>\r\n<td>智源发布CPM2.0</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><a href=\"https://github.com/THUDM/GLM-130B\">GLM</a></td>\r\n<td>清华发布的中英双语130B预训练模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><a href=\"https://github.com/ictnlp/BayLing\">BayLing</a></td>\r\n<td>基于LLama7B/13B，增强的语言对齐的英语/中文大语言模型</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h3 id=\"垂直领域模型进展\">垂直领域模型&amp;进展</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 1%\" />\r\n<col style=\"width: 38%\" />\r\n<col style=\"width: 60%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>领域</th>\r\n<th>模型链接</th>\r\n<th>模型描述</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a href=\"https://medgpt.co/home/zh\">MedGPT</a></td>\r\n<td>医联发布的</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td>MedPalm</td>\r\n<td>Google在Faln-PaLM的基础上通过多种类型的医疗QA数据进行prompt-tuning指令微调得到，同时构建了MultiMedQA</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/Kent0n-Li/ChatDoctor\">ChatDoctor</a></td>\r\n<td>110K真实医患对话样本+5KChatGPT生成数据进行指令微调</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese\">Huatuo</a> <a\r\nhref=\"https://github.com/SCIR-HI/Med-ChatGLM\">Med-ChatGLM</a></td>\r\n<td>医学知识图谱和chatgpt构建中文医学指令数据集+医学文献和chatgpt构建多轮问答数据</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-medical.md\">Chinese-vicuna-med</a></td>\r\n<td>Chinese-vicuna在cMedQA2数据上微调</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a href=\"https://github.com/BioFM/OpenBioMed\">OpenBioMed</a></td>\r\n<td>清华AIR开源轻量版BioMedGPT,\r\n知识图谱&amp;20+生物研究领域多模态预训练模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/xionghonglin/DoctorGLM\">DoctorGLM</a></td>\r\n<td>ChatDoctor+MedDialog+CMD 多轮对话+单轮指令样本微调GLM</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/MediaBrain-SJTU/MedicalGPT-zh\">MedicalGPT-zh</a></td>\r\n<td>自建的医学数据库ChatGPT生成QA+16个情境下SELF构建情景对话</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a href=\"https://github.com/chaoyi-wu/PMC-LLaMA\">PMC-LLaMA</a></td>\r\n<td>医疗论文微调Llama</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a href=\"https://github.com/openmedlab/PULSE\">PULSE</a></td>\r\n<td>Bloom微调+继续预训练</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/CogStack/OpenGPT/tree/main\">NHS-LLM</a></td>\r\n<td>Chatgpt生成的医疗问答，对话，微调模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/michael-wzhu/ShenNong-TCM-LLM\">神农医疗大模型</a></td>\r\n<td>以中医知识图谱的实体为中心生成的中医知识指令数据集11w+，微调LLama-7B</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td>岐黄问道大模型</td>\r\n<td>3个子模型构成，已确诊疾病的临床治疗模型+基于症状的临床诊疗模型+中医养生条理模型，看起来是要ToB落地</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/SupritYoung/Zhongjing\">Zhongjing</a></td>\r\n<td>基于Ziya-LLama+医疗预训练+SFT+RLHF的中文医学大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a href=\"https://github.com/qiuhuachuan/smile\">MeChat</a></td>\r\n<td>心理咨询领域，通过chatgpt改写多轮对话56k</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a href=\"https://github.com/scutcyr/SoulChat\">SoulChat</a></td>\r\n<td>心理咨询领域中文长文本指令与多轮共情对话数据联合指令微调\r\nChatGLM-6B</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>医疗</td>\r\n<td><a href=\"https://github.com/X-D-Lab/MindChat\">MindChat</a></td>\r\n<td>MindChat-Baichuan-13B,Qwen-7B,MindChat-InternLM-7B使用不同基座在模型安全，共情，人类价值观对其上进行了强化</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>医疗</td>\r\n<td><a\r\nhref=\"https://github.com/FudanDISC/DISC-MedLLM\">DISC-MedLLM</a></td>\r\n<td>疾病知识图谱构建QA对+QA对转化成单论对话+真实世界数据重构+人类偏好数据筛选，SFT微调baichuan</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>法律</td>\r\n<td><a href=\"https://github.com/LiuHC0428/LAW-GPT\">LawGPT-zh</a></td>\r\n<td>利用ChatGPT清洗CrimeKgAssitant数据集得到52k单轮问答+我们根据中华人民共和国法律手册上最核心的9k法律条文，利用ChatGPT联想生成具体的情景问答+知识问答使用ChatGPT基于文本构建QA对</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>法律</td>\r\n<td><a href=\"https://github.com/pengxiao-song/LaWGPT\">LawGPT</a></td>\r\n<td>基于llama+扩充词表二次预训练+基于法律条款构建QA指令微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>法律</td>\r\n<td><a href=\"https://github.com/AndrewZhe/lawyer-llama\">Lawyer\r\nLlama</a></td>\r\n<td>法律指令微调数据集：咨询+法律考试+对话进行指令微调</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>法律</td>\r\n<td><a href=\"https://github.com/CSHaitao/LexiLaw\">LexiLaw</a></td>\r\n<td>法律指令微调数据集：问答+书籍概念解释，法条内容进行指令微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>法律</td>\r\n<td><a href=\"https://chatlaw.cloud/\">ChatLaw</a></td>\r\n<td>北大推出的法律大模型，应用形式很新颖类似频道内流一切功能皆融合在对话形式内</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>法律</td>\r\n<td><a\r\nhref=\"https://github.com/zhihaiLLM/wisdomInterrogatory\">录问模型</a></td>\r\n<td>在baichuan基础上40G二次预训练+100K指令微调，在知识库构建上采用了Emb+意图+关键词联想结合的方案</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a href=\"https://finchat.io/\">FinChat.io</a></td>\r\n<td>使用最新的财务数据，电话会议记录，季度和年度报告，投资书籍等进行训练</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>金融</td>\r\n<td><a href=\"https://github.com/CogStack/OpenGPT\">OpenGPT</a></td>\r\n<td>领域LLM指令样本生成+微调框架</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a\r\nhref=\"https://github.com/ssymmetry/BBT-FinCUGE-Applications/tree/main\">乾元BigBang金融2亿模型</a></td>\r\n<td>金融领域预训练+任务微调</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>金融</td>\r\n<td><a\r\nhref=\"https://huggingface.co/xyz-nlp/XuanYuan2.0\">度小满千亿金融大模型</a></td>\r\n<td>在Bloom-176B的基础上进行金融+中文预训练和微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a href=\"https://www.ltxtrading.com/bondgpt\">bondGPT</a></td>\r\n<td>GPT4在细分债券市场的应用开放申请中</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>金融</td>\r\n<td><a\r\nhref=\"https://www.cnbc.com/2023/05/25/jpmorgan-develops-ai-investment-advisor.html\">IndexGPT</a></td>\r\n<td>JPMorgan在研的生成式投资顾问</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a\r\nhref=\"https://mp.weixin.qq.com/s/vLvxvi2nOywkjt7ppiFC2g\">恒生LightGPT</a></td>\r\n<td>金融领域继续预训练+插件化设计</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>金融</td>\r\n<td><a\r\nhref=\"https://finance.sina.com.cn/jjxw/2023-07-03/doc-imyzmaut2132017.shtml\">知彼阿尔法</a></td>\r\n<td>企查查商查大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a href=\"https://www.alphabox.top\">AlphaBox</a></td>\r\n<td>熵简科技发布大模型金融应用，多文档问答+会议转录+文档编辑</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>金融</td>\r\n<td><a href=\"http://www.datagrand.com/products/aigc/\">曹植</a></td>\r\n<td>达观发布金融大模型融合data2text等金融任务，赋能报告写作</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a\r\nhref=\"https://github.com/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese\">聚宝盆</a></td>\r\n<td>基于 LLaMA\r\n系基模型经过中文金融知识指令精调/指令微调(Instruct-tuning)\r\n的微调模型</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>金融</td>\r\n<td><a href=\"https://github.com/chancefocus/PIXIU\">PIXIU</a></td>\r\n<td>整理了多个金融任务数据集加入了时间序列数据进行指令微调</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a href=\"https://chat.funddb.cn/\">ChatFund</a></td>\r\n<td>韭圈儿发布的第一个基金大模型，看起来是做了多任务指令微调，和APP已有的数据功能进行了全方位的打通，从选基，到持仓分析等等</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>金融</td>\r\n<td><a\r\nhref=\"https://github.com/AI4Finance-Foundation/FinGPT\">FinGPT</a></td>\r\n<td>金融传统任务微调 or chatgpt生成金融工具调用</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>金融</td>\r\n<td><a href=\"https://github.com/TongjiFinLab/CFGPT\">CFGPT</a></td>\r\n<td>金融预训练+指令微调+RAG等检索任务增强</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>编程</td>\r\n<td><a\r\nhref=\"https://github.com/bigcode-project/starcoder\">Starcoder</a></td>\r\n<td>80种编程语言+Issue+Commit训练得到的编程大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>编程</td>\r\n<td><a href=\"https://github.com/cubenlp/ChatSQL\">ChatSQL</a></td>\r\n<td>基于ChatGLM实现NL2sql</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>编程</td>\r\n<td><a\r\nhref=\"http://keg.cs.tsinghua.edu.cn/codegeex/index_zh.html\">codegeex</a></td>\r\n<td>13B预训练+微调多语言变成大模型</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>编程</td>\r\n<td><a href=\"https://github.com/THUDM/CodeGeeX2\">codegeex2</a></td>\r\n<td>Chatglm2的基础上CodeGeeX2-6B 进一步经过了 600B 代码数据预训练</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>编程</td>\r\n<td><a\r\nhref=\"https://stability.ai/blog/stablecode-llm-generative-ai-coding\">stabelcode</a></td>\r\n<td>560B token多语言预训练+ 120,000 个 Alpaca指令对齐</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>编程</td>\r\n<td><a href=\"https://github.com/defog-ai/sqlcoder\">SQLCoder</a></td>\r\n<td>在StarCoder的基础上微调15B超越gpt3.5</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>数学</td>\r\n<td><a href=\"https://www.mathgpt.com/\">MathGPT</a></td>\r\n<td>是好未来自主研发的，面向全球数学爱好者和科研机构，以解题和讲题算法为核心的大模型。</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>数学</td>\r\n<td><a href=\"https://tiger-ai-lab.github.io/MAmmoTH/\">MammoTH</a></td>\r\n<td>通过COT+POT构建了MathInstruct数据集微调llama在OOD数据集上超越了WizardLM</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>数学</td>\r\n<td><a href=\"https://github.com/meta-math/MetaMath\">MetaMath</a></td>\r\n<td>模型逆向思维解决数学问题，构建了新的MetaMathQA微调llama2</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>交通</td>\r\n<td><a href=\"https://github.com/DUOMO/TransGPT\">TransGPT</a></td>\r\n<td>LLama-7B+34.6万领域预训练+5.8万条领域指令对话微调（来自文档问答）</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>交通</td>\r\n<td><a\r\nhref=\"https://github.com/lijlansg/TrafficGPT/tree/main\">TrafficGPT</a></td>\r\n<td>ChatGPT+Prompt实现规划，调用交通流量领域专业TFM模型，TFM负责数据分析，任务执行，可视化等操作</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>科技</td>\r\n<td><a href=\"https://github.com/gmftbyGMFTBY/science-llm\">Mozi</a></td>\r\n<td>红睡衣预训练+论文QA数据集 + ChatGPT扩充科研对话数据</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>天文</td>\r\n<td><a href=\"https://github.com/Yu-Yang-Li/StarGLM\">StarGLM</a></td>\r\n<td>天文知识指令微调，项目进行中后期考虑天文二次预训练+KG</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>写作</td>\r\n<td><a\r\nhref=\"https://www.zhihu.com/question/613058630\">阅文-网文大模型介绍</a></td>\r\n<td>签约作者内测中，主打的内容为打斗场景，剧情切换，环境描写，人设，世界观等辅助片段的生成</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>写作</td>\r\n<td><a\r\nhref=\"https://github.com/search?q=MediaGPT&amp;type=repositories\">MediaGPT</a></td>\r\n<td>LLama-7B扩充词表+指令微调，指令来自国内媒体专家给出的在新闻创作上的80个子任务</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>电商</td>\r\n<td><a href=\"https://github.com/Alibaba-NLP/EcomGPT\">EcomGPT</a></td>\r\n<td>电商领域任务指令微调大模型，指令样本250万，基座模型是Bloomz</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"tool-and-library\">Tool and Library</h2>\r\n<h3 id=\"推理框架\">推理框架</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 64%\" />\r\n<col style=\"width: 35%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>工具描述</th>\r\n<th>链接</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>FlexFlow：模型部署推理框架</td>\r\n<td>https://github.com/flexflow/FlexFlow</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>Medusa：针对采样解码的推理加速框架，可以和其他策略结合</td>\r\n<td>https://github.com/FasterDecoding/Medusa</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>FlexGen: LLM推理 CPU Offload计算架构</td>\r\n<td>https://github.com/FMInference/FlexGen</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>VLLM：超高速推理框架Vicuna，Arena背后的无名英雄，比HF快24倍，支持很多基座模型</td>\r\n<td>https://github.com/vllm-project/vllm</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Streamingllm:\r\n新注意力池Attention方案，无需微调拓展模型推理长度，同时为推理提速</td>\r\n<td>https://github.com/mit-han-lab/streaming-llm</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h3 id=\"指令微调预训练rlhf框架\">指令微调，预训练，rlhf框架</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 60%\" />\r\n<col style=\"width: 40%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>工具描述</th>\r\n<th>链接</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>LoRA：Low-Rank指令微调方案</td>\r\n<td>https://github.com/tloen/alpaca-lora</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>peft：parameter-efficient prompt tunnging工具集</td>\r\n<td>https://github.com/huggingface/peft</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>RL4LMs：AllenAI的RL工具</td>\r\n<td>https://github.com/allenai/RL4LMs</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>RLLTE：港大，大疆等联合开源RLLTE开源学习框架</td>\r\n<td>https://github.com/RLE-Foundation/rllte</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>trl：基于Transformer的强化训练框架</td>\r\n<td>https://github.com/lvwerra/trl</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>trlx：分布式训练trl</td>\r\n<td>https://github.com/CarperAI/trlx</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>北大开源河狸项目可复现RLHF，支持多数LLM，提供RLHF数据</td>\r\n<td>https://github.com/PKU-Alignment/safe-rlhf</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>RL4LMs：AllenAI的RL工具</td>\r\n<td>https://github.com/allenai/RL4LMs</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>LMFlow：港科大实验室开源的大模型微调框架，支持以上多数开源模型的指令微调和RLHF</td>\r\n<td>https://github.com/OptimalScale/LMFlow</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>hugNLP:基于Huggingface开发继承Prompt技术，预训练和是指输入等多种方案</td>\r\n<td>https://github.com/wjn1996/HugNLP</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Deepspeed：针对RL训练和推理的整合优化</td>\r\n<td>https://github.com/microsoft/DeepSpeed</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>Uerpy:预训练框架支持lm,mlm,unilm等</td>\r\n<td>https://github.com/dbiir/UER-py</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>TecentPretrain: Uerpy的重构版本支持llama预训练</td>\r\n<td>https://github.com/Tencent/TencentPretrain/tree/main</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>lamini: 整合指令数据生成，SFT，RLHF的工具库</td>\r\n<td>https://github.com/lamini-ai/lamini/</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Chain-of-thought-hub：模型推理能力评估平台</td>\r\n<td>https://github.com/FranxYao/chain-of-thought-hub</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>EasyEdit：浙大开源支持多种模型，多种方案的模型知识精准编辑器</td>\r\n<td>https://github.com/zjunlp/EasyEdit</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>OpenDelta：集成了各种增量微调方案的开源实现</td>\r\n<td>https://github.com/thunlp/OpenDelta</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h3 id=\"automulti-agent\">Auto/Multi Agent</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 59%\" />\r\n<col style=\"width: 40%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>工具描述</th>\r\n<th>链接</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>ChatDev: 面壁智能开源多智能体协作的虚拟软件公司</td>\r\n<td>https://github.com/OpenBMB/ChatDev</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>Generative Agents:斯坦福AI小镇的开源代码</td>\r\n<td>https://github.com/joonspk-research/generative_agents</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>BabyAGI：自执行LLM Agent</td>\r\n<td>https://github.com/yoheinakajima/babyagi</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>AutoGPT：自执行LLM Agent</td>\r\n<td>https://github.com/Torantulino/Auto-GPT</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>MetaGPT:\r\n覆盖软件公司全生命流程，例如产品经理等各个职业的AutoGPT</td>\r\n<td>https://github.com/geekan/MetaGPT</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>ResearchGPT: 论文写作领域的AutoGPT，融合论文拆解+网络爬虫</td>\r\n<td>https://github.com/assafelovic/gpt-researcher</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>MiniAGI：自执行LLM Agent</td>\r\n<td>https://github.com/muellerberndt/mini-agi</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>AL Legion： 自执行LLM Agent</td>\r\n<td>https://github.com/eumemic/ai-legion</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>AgentVerse：多模型交互环境</td>\r\n<td>https://github.com/OpenBMB/AgentVerse</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>AgentSims:\r\n给定一个社会环境，评估LLM作为智能体的预定任务目标完成能力的沙盒环境</td>\r\n<td>https://github.com/py499372727/AgentSims/</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>GPTRPG：RPG环境 AI Agent游戏化</td>\r\n<td>https://github.com/dzoba/gptrpg</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>GPTeam：多智能体交互</td>\r\n<td>https://github.com/101dotxyz/GPTeam</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>GPTEngineer：自动工具构建和代码生成</td>\r\n<td>https://github.com/AntonOsika/gpt-engineer</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>WorkGPT：类似AutoGPT</td>\r\n<td>https://github.com/team-openpm/workgpt</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h3 id=\"agent工具框架类\">Agent工具框架类</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 62%\" />\r\n<col style=\"width: 37%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>工具描述</th>\r\n<th>链接</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>langchain：LLM Agent框架</td>\r\n<td>https://github.com/hwchase17/langchain</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>llama index：LLM Agent框架</td>\r\n<td>https://github.com/jerryjliu/llama_index</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Ragas:\r\n评估检索增强LLM效果的框架，基于大模型prompt评估事实性，召回相关性，召回内容质量，回答相关性等</td>\r\n<td>https://github.com/explodinggradients/ragas#fire-quickstart</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>langflow：把langchain等agent组件做成了可拖拽式的UI</td>\r\n<td>https://github.com/logspace-ai/langflow</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Haystack: LLM Agent\r\n框架，pipeline的设计模式个人感觉比langchain更灵活更简洁</td>\r\n<td>https://github.com/deepset-ai/haystack</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>EdgeChain: 通过Jsonnet配置文件实现LLM Agent</td>\r\n<td>https://github.com/arakoodev/EdgeChains/tree/main</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>semantic-kernel：整合大模型和编程语言的SDK</td>\r\n<td>https://github.com/microsoft/semantic-kernel</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>BMTTools: 清华出品多工具调用开源库，提供微调数据和评估ToolBench</td>\r\n<td>https://github.com/OpenBMB/BMTools</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Jarvis: 大模型调用小模型框架，给小模型一个未来！</td>\r\n<td>https://github.com/search?q=jarvis</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>LLM-ToolMaker:让LLM自己制造Agent</td>\r\n<td>https://github.com/FMInference/FlexGen</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Gorilla: LLM调用大量API</td>\r\n<td>https://github.com/ShishirPatil/gorilla</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>wenda:闻达小模型整合搜索用于知识融入</td>\r\n<td>https://github.com/l15y/wenda</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Alexandria:\r\n从Arix论文开始把整个互联网变成向量索引，可以免费下载</td>\r\n<td>https://alex.macrocosm.so/download</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>RapidAPI: 统一这个世界的所有API，最大API\r\nHub，有调用成功率，latency等，是真爱！</td>\r\n<td>https://rapidapi.com/hub</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h3 id=\"其他垂直领域agent\">其他垂直领域Agent</h3>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 54%\" />\r\n<col style=\"width: 45%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>工具描述</th>\r\n<th>链接</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>Deep-KE：基于LLM对数据进行智能解析实现知识抽取</td>\r\n<td>https://github.com/zjunlp/DeepKE</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>IncarnaMind：多文档RAG方案，动态chunking的方案可以借鉴</td>\r\n<td>https://github.com/junruxiong/IncarnaMind</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Vectra：平台化的LLM\r\nAgent搭建方案，从索引构建，内容召回排序，到事实检查的LLM生成</td>\r\n<td>https://vectara.com/tour-vectara/</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>Data-Copilot：时间序列等结构化数据分析领域的Agent解决方案</td>\r\n<td>https://github.com/zwq2018/Data-Copilot</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>DB-GPT:\r\n以数据库为基础的GPT实验项目，使用本地化的GPT大模型与您的数据和环境进行交互</td>\r\n<td>https://db-gpt.readthedocs.io/projects/db-gpt-docs-zh-cn/zh_CN/latest/index.html</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>guardrails：降低模型幻觉的python框架，promp模板+validation+修正</td>\r\n<td>https://github.com/shreyar/guardrails</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>guidance：微软新开源框架，同样是降低模型幻觉的框架，prompt+chain的升级版加入逐步生成和思维链路</td>\r\n<td>https://github.com/guidance-ai/guidance</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>SolidGPT: 上传个人数据，通过命令交互创建项目PRD等</td>\r\n<td>https://github.com/AI-Citizen/SolidGPT</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"training-data\">Training Data</h2>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 5%\" />\r\n<col style=\"width: 37%\" />\r\n<col style=\"width: 57%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>数据类型</th>\r\n<th>数据描述</th>\r\n<th>数据链接</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>self-instruct，GPT3自动生成&amp;过滤得到指令集</td>\r\n<td>https://github.com/yizhongw/self-instruct</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>Standford Alpaca：52K\r\ntext-davinci-003生成的self-instruct指令数据集</td>\r\n<td>https://github.com/tatsu-lab/stanford_alpaca</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>GPT4-for-LLM 中文+英文+对比指令</td>\r\n<td>https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>GPTTeacher更多样的通用指令，角色扮演和代码指令</td>\r\n<td>https://github.com/teknium1/GPTeacher/tree/main</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>中文翻译Alpaca还有一些其他指令数据集</td>\r\n<td>https://github.com/hikariming/alpaca_chinese_dataset\r\nhttps://github.com/carbonz0/alpaca-chinese-dataset</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>alpaca指令GPT4生成，和以上几版对比显著质量更高，回复更长</td>\r\n<td>https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/tree/main</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>Guanaco数据：对Alphca指令重写后以不同语言生成总共534K，有对话和非对话类型，还有补充的QA生成样本</td>\r\n<td>https://huggingface.co/datasets/JosephusCheung/GuanacoDataset</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>OIG中文指令包括翻译alpaca+natural+unnatural，多轮对话，考试，leetcode指令</td>\r\n<td>https://github.com/BAAI-Zlab/COIG</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>Vicuna训练使用的样本，用API获取了sharegpt上用户和chatgpt对话历史，部分网友整理到了HF</td>\r\n<td>https://github.com/domeccleston/sharegpt\r\nhttps://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/tree/main</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>HC3指令数据中英文，包括金融，开放QA，百科，DBQA，医学等包含人工回复</td>\r\n<td>https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese/tree/main</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>MOSS开源的SFT数据包含使用plugin的对话数据</td>\r\n<td>https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese/tree/main</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>InstructWild数据：用四处爬取的chatgpt指令作为种子self-instruct扩充生成，中英双语</td>\r\n<td>https://github.com/XueFuzhao/InstructionWild/tree/main/data</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>BELLE100万指令数据，参考Alpaca用ChatGPT生成，有数学，多轮对话，校色对话等等</td>\r\n<td>https://github.com/LianjiaTech/BELLE</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>PromptCLUE多任务提示数据集：模板构建，只包含标准NLP任务</td>\r\n<td>https://github.com/CLUEbenchmark/pCLUE</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>TK-Instruct微调用的指令数据集, 全人工标注1600+NLP任务</td>\r\n<td>https://instructions.apps.allenai.org/</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>T0微调用的指令数据集（P3）</td>\r\n<td>https://huggingface.co/datasets/bigscience/P3</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>p3衍生的46种多语言数据集（xmtf）</td>\r\n<td>https://github.com/bigscience-workshop/xmtf</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>Unnatural Instruction使用GPT3生成后改写得到240k</td>\r\n<td>https://github.com/orhonovich/unnatural-instructions</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>alpaca COT对多个数据源进行了清理并统一格式放到的了HF,\r\n重点是人工整理的COT数据</td>\r\n<td>https://github.com/PhoebusSi/Alpaca-CoT</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>人工编写包含23种常见的中文NLP任务的指令数据，中文写作方向</td>\r\n<td>https://github.com/yangjianxin1/Firefly</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>Amazon COT指令样本包括各类QA，bigbench，math等</td>\r\n<td>https://github.com/amazon-science/auto-cot</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>CSL包含 396,209 篇中文核心期刊论文元信息\r\n（标题、摘要、关键词、学科、门类）可做预训练可构建NLP指令任务</td>\r\n<td>https://github.com/ydli-ai/CSL</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>alpaca code 20K代码指令数据</td>\r\n<td>https://github.com/sahil280114/codealpaca#data-release</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>GPT4Tools 71K GPT4指令样本</td>\r\n<td>https://github.com/StevenGrove/GPT4Tools</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>指令微调</td>\r\n<td>GPT4指令+角色扮演+代码指令</td>\r\n<td>https://github.com/teknium1/GPTeacher</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>指令微调</td>\r\n<td>Mol-Instructions 2043K\r\n分子+蛋白质+生物分子文本指令，覆盖分子设计、蛋白质功能预测、蛋白质设计等任务</td>\r\n<td>https://github.com/zjunlp/Mol-Instructions</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>数学</td>\r\n<td>腾讯人工智能实验室发布网上爬取的数学问题APE210k</td>\r\n<td>https://github.com/Chenny0808/ape210k</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>数学</td>\r\n<td>猿辅导 AI Lab开源小学应用题Math23K</td>\r\n<td>https://github.com/SCNU203/Math23k/tree/main</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>数学</td>\r\n<td>grade school\r\nmath把OpenAI的高中数学题有改造成指令样本有2-8步推理过程</td>\r\n<td>https://huggingface.co/datasets/qwedsacf/grade-school-math-instructions</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>数学</td>\r\n<td>数学问答数据集有推理过程和多项选择</td>\r\n<td>https://huggingface.co/datasets/math_qa/viewer/default/test?row=2</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>数学</td>\r\n<td>AMC竞赛数学题</td>\r\n<td>https://huggingface.co/datasets/competition_math</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>数学</td>\r\n<td>线性代数等纯数学计算题</td>\r\n<td>https://huggingface.co/datasets/math_dataset</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>代码</td>\r\n<td>APPS从不同的开放访问编码网站Codeforces、Kattis 等收集的问题</td>\r\n<td>https://opendatalab.org.cn/APPS</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>代码</td>\r\n<td>Lyra代码由带有嵌入式 SQL 的 Python\r\n代码组成，经过仔细注释的数据库操作程序，配有中文评论和英文评论。</td>\r\n<td>https://opendatalab.org.cn/Lyra</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>代码</td>\r\n<td>Conala来自StackOverflow问题,手动注释3k，英文</td>\r\n<td>https://opendatalab.org.cn/CoNaLa/download</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>代码</td>\r\n<td>code-alpaca ChatGPT生成20K代码指令样本</td>\r\n<td>https://github.com/sahil280114/codealpaca.git</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>代码</td>\r\n<td>32K,\r\n四种不同类型、不同难度的代码相关中文对话数据，有大模型生成，</td>\r\n<td>https://github.com/zxx000728/CodeGPT</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>对话</td>\r\n<td>LAION 策划的开放指令通用数据集中手动选择的组件子集 已开源40M\r\n3万个,100M在路上</td>\r\n<td>https://github.com/LAION-AI/Open-Instruction-Generalist</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>对话</td>\r\n<td>Baize基于Chat GPT构建的self-chat数据</td>\r\n<td>https://github.com/project-baize/baize-chatbot/tree/main/data</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>对话</td>\r\n<td>FaceBook开源BlenderBot训练对话数据~6K</td>\r\n<td>https://huggingface.co/datasets/blended_skill_talk</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>对话</td>\r\n<td>AllenAI开源38.5万个对话高质量数据集SODA</td>\r\n<td>https://realtoxicityprompts.apps.allenai.org/</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>对话</td>\r\n<td>InstructDial在单一对话任务类型上进行指令微调</td>\r\n<td>https://github.com/prakharguptaz/Instructdial</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>对话</td>\r\n<td>Ultra Chat 两个独立的 ChatGPT Turbo API\r\n进行对话，从而生成多轮对话数据</td>\r\n<td>https://github.com/thunlp/UltraChat</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>对话</td>\r\n<td>Awesome Open-domain Dialogue Models提供多个开放域对话数据</td>\r\n<td>https://github.com/cingtiye/Awesome-Open-domain-Dialogue-Models#%E4%B8%AD%E6%96%87%E5%BC%80%E6%94%BE%E5%9F%9F%E5%AF%B9%E8%AF%9D%E6%95%B0%E6%8D%AE%E9%9B%86</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>对话</td>\r\n<td>Salesforce开源超全DialogStudio</td>\r\n<td>https://github.com/salesforce/DialogStudio</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>对话</td>\r\n<td>基于事实Reference的多轮问答中文数据，已开源5万，之后会开源更多</td>\r\n<td>https://github.com/sufengniu/RefGPT</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>RLFH</td>\r\n<td>北大河狸开源RLHF数据集10K，1M需要申请</td>\r\n<td>https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF-10K</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>RLHF</td>\r\n<td>Anthropic hh-rlhf数据集</td>\r\n<td>https://huggingface.co/datasets/Anthropic/hh-rlhf</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>RLHF</td>\r\n<td>Stack-exchange上问题对应多个答案，每个答案有打分</td>\r\n<td>https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences/tree/main</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>RLHF</td>\r\n<td>Facebook Bot Adversarial Dialogues数据集5K</td>\r\n<td>https://github.com/facebookresearch/ParlAI</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>RLHF</td>\r\n<td>AllenAI Real Toxicity prompts</td>\r\n<td>https://github.com/facebookresearch/ParlAI</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>RLHF</td>\r\n<td>OpenAssistant Conversations 160K消息，13500人工生成, 英文为主</td>\r\n<td>https://huggingface.co/datasets/OpenAssistant/oasst1</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>RLHF</td>\r\n<td>知乎问答偏好数据集</td>\r\n<td>https://huggingface.co/datasets/liyucheng/zhihu_rlhf_3k</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>RLHF</td>\r\n<td>hh-rlhf中文翻译偏好数据</td>\r\n<td>https://huggingface.co/datasets/liswei/rm-static-zhTW</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>RLHF</td>\r\n<td>面壁智能开源大规模偏好数据，基于64Kprompt使用不同模型生成4个回答使用GPT-4评估</td>\r\n<td>https://github.com/OpenBMB/UltraFeedback</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>评估集</td>\r\n<td>BigBench(Beyond the Imitation Game Benchmark)</td>\r\n<td>https://github.com/google/BIG-bench</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>评估集</td>\r\n<td>Complex QA：用于ChatGPT的评测指令集</td>\r\n<td>https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-ChatGPT</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>评估集</td>\r\n<td>Langchain开源评估数据集</td>\r\n<td>https://huggingface.co/LangChainDatasets</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>评估集</td>\r\n<td>2010-2022年全国高考卷的题目</td>\r\n<td>https://github.com/OpenLMLab/GAOKAO-Bench</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>评估集</td>\r\n<td>中文通用大模型综合性评测基准SuperCLUE</td>\r\n<td>https://github.com/CLUEbenchmark/SuperCLUE</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>英文预训练</td>\r\n<td>RedPajama开源的复刻llama的预训练数据集，1.21万亿Token</td>\r\n<td>https://github.com/togethercomputer/RedPajama-Data</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>英文预训练</td>\r\n<td>Cerebras基于RedPajama进行清洗去重后得到的高质量数据集,\r\n6270亿Token</td>\r\n<td>https://huggingface.co/datasets/cerebras/SlimPajama-627B/tree/main/train</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>英文预训练</td>\r\n<td>Pile 22个高质量数据集混合的预训练数据集800G,全量开放下载</td>\r\n<td>https://pile.eleuther.ai/</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>通用预训练</td>\r\n<td>UER整理CLUECorpusSmall+News Commentary中英</td>\r\n<td>https://github.com/dbiir/UER-py/wiki/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>中文预训练</td>\r\n<td>智源人工智能开源的wudao 200G预训练数据</td>\r\n<td><a\r\nhref=\"https://openi.pcl.ac.cn/BAAI/WuDao-Data\">https://github.com/BAAI-WuDao/WuDaoMM</a></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>中文预训练</td>\r\n<td>里屋社区发起开源力量收集中文互联网语料集MNBVC目标是对标ChatGPT的40T</td>\r\n<td>https://github.com/esbatmop/MNBVC</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>中文预训练</td>\r\n<td>复旦开源15万中文图书下载和抽取方案</td>\r\n<td>https://github.com/FudanNLPLAB/CBook-150K</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>中文预训练</td>\r\n<td>书生万卷数据集来自公开网页多模态数据集，包括文本，图文和视频，其中文本1T，图文150G</td>\r\n<td>https://opendatalab.org.cn/OpenDataLab/WanJuan1_dot_0</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>领域预训练</td>\r\n<td>首个中文科学文献数据集CSL,也有多种NLP任务数据</td>\r\n<td>https://github.com/ydli-ai/CSL</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>平行语料</td>\r\n<td>news-commentary中英平行语料，用于中英间知识迁移</td>\r\n<td>https://data.statmt.org/news-commentary/v15/training/</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>多源数据集整合</td>\r\n<td>opendatalab整合了预训练阶段的多个数据源</td>\r\n<td>https://opendatalab.org.cn/?industry=9821&amp;source=JUU3JTlGJUE1JUU0JUI5JThF</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>Tool-搜索增强</td>\r\n<td>webCPM开源的和搜索工具进行交互问答的数据集，包括网页抽取式摘要，多事实内容回答等人工标注数据</td>\r\n<td>https://github.com/thunlp/WebCPM</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Tool-多工具</td>\r\n<td>BmTools开源的多工具调用指令数据集</td>\r\n<td>https://github.com/OpenBMB/BMTools</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>NL2SQL</td>\r\n<td>DB-GPT-Hub梳理了多源text-to-sql数据集</td>\r\n<td>https://github.com/eosphoros-ai/DB-GPT-Hub</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"aigc\">AIGC</h2>\r\n<ul>\r\n<li><a href=\"https://nexus.snikpic.io/\">NexusGPT</a>: <img\r\nsrc=\"https://img.shields.io/badge/Auto-Agent-white\" />:\r\nAutoGPT可以出来工作了，第一个全AI Freelance平台</li>\r\n<li><a href=\"https://www.cognosys.ai/create\">cognosys</a>:\r\n全网最火的web端AutoGPT，不过咋说呢试用了下感觉下巴要笑掉了，不剧透去试试你就知道\r\n<img src=\"https://img.shields.io/badge/Auto-Agent-white\" /></li>\r\n<li><a\r\nhref=\"https://godmode.space/\">godmode</a>：可以进行人为每一步交互的的AutoGPT<img\r\nsrc=\"https://img.shields.io/badge/Auto-Agent-white\" /></li>\r\n<li><a href=\"https://agentgpt.reworkd.ai/\">agentgpt</a>:\r\n基础版AutoGPT<img src=\"https://img.shields.io/badge/Auto-Agent-white\" />\r\n⭐️</li>\r\n<li><a href=\"https://www.doanythingmachine.com/\">do Anything</a>:\r\nAutoGPT Like的to Do List生成器 <img\r\nsrc=\"https://img.shields.io/badge/Auto-Agent-white\" /></li>\r\n<li><a href=\"https://www.chatmind.tech/\">ChatMind</a>:\r\nchatgpt生成思维导图，模板很丰富，泛化性也不错，已经被XMind收购了~ <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /> ⭐️</li>\r\n<li><a href=\"https://www.bing.com/\">New\r\nBing</a>：需要连外网否则会重定向到bing中国，需要申请waitlist <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Search-yellow\" /> ⭐️</li>\r\n<li><a href=\"https://www.perplexity.ai/\">Perplexity.ai</a>:\r\n同样需要科学上网，感觉比Bing做的更好的接入ChatGPT的神奇搜索引擎，在Bing之外还加入了相关推荐和追问\r\n<img src=\"https://img.shields.io/badge/AIGC-Search-yellow\" /> ⭐️</li>\r\n<li><a href=\"https://github.com/dice2o/BingGPT\">BingGPT</a>:\r\nNewBing开源桌面客户端，可以将聊天记录导出 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Search-yellow\" /></li>\r\n<li><a href=\"https://github.com/refuel-ai/autolabel\">AutoLabel</a>:\r\nAutoLabel标注方案 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20wirter%20tools-brightgreen\" /></li>\r\n<li><a href=\"https://get.mem.ai/\">Mem</a>:\r\n笔记类产品，可以构建个人知识AI管家例如知识图谱，已获openai融资 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20wirter%20tools-brightgreen\" /></li>\r\n<li><a href=\"https://github.com/arc53/DocsGPT\">DocsGPT</a>:\r\n把ChatGPT开放域问答转化成封闭域问答的通用方案，试用垂类领域问答场景,可以试用定制的ChatBot\r\n<img src=\"https://img.shields.io/badge/Tool-Business-red\" /> ⭐️</li>\r\n<li><a\r\nhref=\"https://github.com/imClumsyPanda/langchain-ChatGLM\">langchain-ChatGLM</a>:\r\n基于ChatGLM的本地知识问答，和上面的DocsGPT相似，不过可以本地部署⭐️</li>\r\n<li><a href=\"https://chat2doc.cn/\">ChatPDF</a>: 国内的ChatPDF,\r\n上传pdf后，会给出文章的Top5可能问题，然后对话式从文档中进行问答和检索，10s读3万字\r\n<img src=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a\r\nhref=\"https://chatdoc.com/?viaurl=ainavpro.com\">ChatDoc</a>:ChatPDF升级版，增加了表格类解析，和完善的索引引用加跳转加对应文章内容高亮，哈哈我准备自己整一个\r\n<img src=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a href=\"https://github.com/kaixindelele/ChatPaper\">ChatPaper</a>:\r\n根据输入关键词，自动在arxiv上下载最新的论文，并对论文进行摘要总结，可以在huggingface上试用！\r\n<img src=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a href=\"https://www.openread.academy/home\">OpenRead</a>:\r\n面向论文写作，阅读场景，可以帮助生成文献综述，以及提供和NotionAI相似的智能Markdown用于写作\r\n<img src=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a\r\nhref=\"https://github.com/mukulpatnaik/researchgpt\">researchgpt</a>:\r\n和ChatPDF类似，支持arivx论文下载，加载后对话式获取论文重点 <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a href=\"https://briefgpt.xyz/?viaurl=ainavpro.com\">BriefGPT</a>:\r\n日更Arxiv论文，并对论文进行摘要，关键词抽取，帮助研究者了解最新动态,\r\nUI不错哟 <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a\r\nhref=\"https://github.com/binary-husky/chatgpt_academic\">ChatGPT-academic</a>:\r\n又是一个基于gradio实现的paper润色，摘要等功能打包的实现 <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a\r\nhref=\"https://github.com/Leizhenpeng/feishu-chatgpt\">feishu-chatgpt</a>:\r\n飞书chatgpt，和365copilot相似也是多组件集成, 有点全！ <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a href=\"https://www.ai-topia.com/\">AI Topiah</a>:\r\n聆心智能AI角色聊天，和路飞唠了两句，多少有点中二之魂在燃烧 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Chatbot-blue\" /></li>\r\n<li><a href=\"https://www.chatbase.co/\">chatbase</a>:\r\n情感角色聊天，还没尝试 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Chatbot-blue\" /></li>\r\n<li><a href=\"https://gptme.vana.com/login\">Vana</a>: virtual DNA,\r\n通过聊天创建虚拟自己！概念很炫 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Chatbot-blue\" /></li>\r\n<li><a\r\nhref=\"https://app.writesonic.com/\">WriteSonic</a>：AI写作，支持对话和定向创作如广告文案，商品描述,\r\n支持Web检索是亮点，支持中文 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20wirter%20tools-brightgreen\" /></li>\r\n<li><a href=\"https://www.copy.ai/\">copy.ai</a>:\r\nWriteSonic竞品，亮点是像论文引用一样每句话都有对应网站链接，可以一键复制到右边的创作Markdown，超级好用！\r\n<img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20wirter%20tools-brightgreen\" />\r\n⭐️</li>\r\n<li><a\r\nhref=\"https://www.notion.so/product?fredir=1\">NotionAI</a>：智能Markdown，适用真相！在创作中用command调用AI辅助润色，扩写，检索内容，给创意idea\r\n<img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20wirter%20tools-brightgreen\" /></li>\r\n<li><a href=\"https://www.jasper.ai/\">Jasper</a>: 同上，全是竞品哈哈 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20wirter%20tools-brightgreen\" /></li>\r\n<li><a href=\"https://copyai.cn/\">copy.down</a>:\r\n中文的营销文案生成，只能定向创作，支持关键词到文案的生成 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20wirter%20tools-brightgreen\" /></li>\r\n<li><a href=\"https://chatexcel.com/convert\">ChatExcel</a>:\r\n指令控制excel计算，对熟悉excel的有些鸡肋，对不熟悉的有点用 <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a href=\"https://github.com/williamfzc/chat-gpt-ppt\">ChatPPT</a>:\r\n使用ChatGPT进行PPT制作 <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a href=\"https://github.com/JimmyLv/BibiGPT\">BibiGPT</a>:\r\nBilibli视频内容一键总结，多模态文档 <img\r\nsrc=\"https://img.shields.io/badge/Tool-Business-red\" /></li>\r\n<li><a href=\"https://github.com/features/copilot\">Copilot</a>: 要付费哟\r\n<img src=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a href=\"https://github.com/fauxpilot/fauxpilot\">Fauxpilot</a>:\r\ncopilot本地开源替代 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a href=\"http://codegeex.cn/zh-CN\">CodeGex</a>: 国内替代品，还没试过\r\n<img src=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a href=\"https://codeium.com/\">Codeium</a>:\r\nCopilot替代品，有免费版本支持各种plugin <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a href=\"https://www.sqltranslate.app/\">sql translate</a>:\r\ntext2sql，利用 OpenAI 的 API\r\n实现的一个很简单的工具，sql到文字，文字到sql <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a href=\"https://www.ai2sql.io/\">ai2sql</a>:\r\ntext2sql老牌公司，相比sqltranslate功能更全面，支持SQL\r\n语法检查、格式化和生成公式 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a\r\nhref=\"https://www.pingcap.com/chat2query-an-innovative-ai-powered-sql-generator-for-faster-insights/\">chat2query</a>:\r\ntext2sql\r\n相比以上两位支持更自然的文本指令，以及更复杂的数据分析类的sql生成 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /> ⭐️</li>\r\n<li><a href=\"https://outerbase.com/\">OuterBase</a>: text2sql\r\n设计风格很吸睛！电子表格结合mysql和dashboard，更适合数据分析宝宝 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a href=\"https://github.com/biobootloader/wolverine\">Wolverine</a>:\r\n代码自我debug的python脚本 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-Coder-blueviolet\" /></li>\r\n<li><a href=\"https://beta.dreamstudio.ai/dream\">dreamstudio.ai</a>:\r\n开创者，Stable Difussion， 有试用quota <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20Artist-orange\" /></li>\r\n<li><a\r\nhref=\"https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F\">midjourney</a>:\r\n开创者，艺术风格为主 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20Artist-orange\" /></li>\r\n<li><a href=\"https://openai.com/product/dall-e-2\">Dall.E</a>:\r\n三巨头这就凑齐了 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20Artist-orange\" /></li>\r\n<li><a\r\nhref=\"https://huggingface.co/spaces/hysts/ControlNet\">ControlNet</a>:\r\n为绘画创作加持可控性 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20Artist-orange\" /></li>\r\n<li><a href=\"https://github.com/Nutlope/restorePhotos\">GFPGAN</a>:\r\n照片修复 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20Artist-orange\" /></li>\r\n<li><a\r\nhref=\"https://huggingface.co/spaces/microsoft/visual_chatgpt\">Visual\r\nChatGPT</a>: 微软发布图像ChatGPT，对话方式进行图像生成编辑，问答 <img\r\nsrc=\"https://img.shields.io/badge/AIGC-AI%20Artist-orange\" /> ⭐️</li>\r\n<li><a href=\"https://www.genmo.ai/\">gemo.ai</a>:\r\n多模态聊天机器人，包括文本，图像，视频生成</li>\r\n<li><a href=\"https://storybird.com/\">storybird</a>:\r\n根据提示词生成故事绘本，还可以售卖</li>\r\n</ul>\r\n<h2 id=\"resources\">Resources</h2>\r\n<h3 id=\"教程类\">教程类</h3>\r\n<ul>\r\n<li><a href=\"https://github.com/openai/openai-cookbook\">OpenAI\r\nCookbook</a>: 提供OpenAI模型使用示例 ⭐️</li>\r\n<li><a href=\"https://github.com/riba2534/openai-scf-goproxy\">OpenAI\r\n接口被墙解决办法</a>:\r\n使用腾讯云搭建代理，亲测非常好用且手残党也可以轻松上手</li>\r\n<li><a\r\nhref=\"https://promptperfect.jinaai.cn/\">PromptPerfect</a>:用魔法打败魔法，输入原始提示词，模型进行定向优化，试用后我有点沉默了，可以定向支持不同使用prompt的模型如Difussion，ChatGPT，\r\nDalle等</li>\r\n<li><a href=\"https://www.clickprompt.org/zh-CN/\">ClickPrompt</a>:\r\n为各种prompt加持的工具生成指令包括Difussion，chatgptdeng, 需要OpenAI\r\nKey</li>\r\n<li><a href=\"https://newzone.top/chatgpt/\">ChatGPT\r\nShortCut</a>：提供各式场景下的Prompt范例，范例很全，使用后可以点赞！\r\n⭐️</li>\r\n<li><a\r\nhref=\"https://enchanting-trader-463.notion.site/Full-ChatGPT-Prompts-Resources-8aa78bb226b7467ab59b70d2b27042e9\">Full\r\nChatGPT Prompts + Resources</a>:\r\n各种尝尽的prompt范例，和以上场景有所不同</li>\r\n<li><a href=\"https://learnprompting.org/\">learning Prompt</a>: prompt\r\nengineering超全教程，和落地应用收藏，包括很多LLM调用Agent的高级场景\r\n⭐️</li>\r\n<li><a\r\nhref=\"https://github.com/ORDINAND/The-Art-of-Asking-ChatGPT-for-High-Quality-Answers-A-complete-Guide-to-Prompt-Engineering-Technique\">The\r\nart of asking chatgpt for high quality answers</a>:\r\n如何写Prompt指令出书了，链接是中文翻译的版本，比较偏基础使用</li>\r\n<li><a\r\nhref=\"https://github.com/dair-ai/Prompt-Engineering-Guide\">Prompt-Engineer-Guide</a>:\r\n同learnig prompt类的集成教程，互相引用可还行？！分类索引做的更好些\r\n⭐️</li>\r\n<li><a\r\nhref=\"https://www.mojidoc.com/05z7y-dd5pa7hu3zfmhnbngoeztyqcnq-00b\">OpenAI\r\n应用汇总指南</a>: 纯应用类的汇总指南</li>\r\n<li><a href=\"https://www.ainavpro.com/#term-209\">AI 导航</a>:\r\n包括但不限于ChatGPT的应用汇总网站，更新很快，发现了一些新大陆</li>\r\n<li><a href=\"https://www.alignmentforum.org/\">AI Alignment Forum</a>:\r\nRLHF等对齐相关最新论文和观点的讨论论坛</li>\r\n<li><a\r\nhref=\"https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/\">Langchain:\r\nChat with your data</a>:吴恩达LLM实践课程</li>\r\n<li><a\r\nhref=\"https://github.com/phodal/aigc\">构筑大语言模型应用：应用开发与架构设计</a>:\r\n一本关于 LLM 在真实世界应用的开源电子书</li>\r\n<li><a\r\nhref=\"https://github.com/databricks-academy/large-language-models\">Large\r\nLanguage Models: Application through Production</a>:\r\n大模型应用Edx出品的课程</li>\r\n</ul>\r\n<h3 id=\"书籍博客类\">书籍博客类</h3>\r\n<ul>\r\n<li><a href=\"https://openai.com/blog/chatgpt/\">OpenAI ChatGPT\r\nIntro</a></li>\r\n<li><a href=\"https://openai.com/blog/instruction-following/\">OpenAI\r\nInstructGPT intro</a></li>\r\n<li>AllenAI ChatGPT能力解读：<a\r\nhref=\"https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1\">How\r\ndoes GPT Obtain its Ability? Tracing Emergent Abilities of Language\r\nModels to their Sources</a> ⭐️</li>\r\n<li>Huggingface ChatGPT能力解读：<a\r\nhref=\"https://huggingface.co/blog/dialog-agents\">The techniques behind\r\nChatGPT: RLHF, IFT, CoT, Red teaming, and more</a></li>\r\n<li>Stephen Wolfram ChatGPT能力解读: <a\r\nhref=\"https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/\">What\r\nIs ChatGPT Doing and Why Does It Work?</a></li>\r\n<li><a\r\nhref=\"https://github.com/chenweiphd/ChatGPT-Hub\">Chatgpt相关解读汇总</a></li>\r\n<li><a\r\nhref=\"https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai/\">麻省理工科技采访OpenAI工程师</a></li>\r\n<li><a\r\nhref=\"https://www.jiqizhixin.com/articles/2018-11-15-6?from=timeline\">AGI历史与现状</a></li>\r\n<li><a href=\"https://zhuanlan.zhihu.com/p/597586623\">张俊林\r\n通向AGI之路：大型语言模型（LLM）技术精要</a></li>\r\n<li><a\r\nhref=\"https://www.zhihu.com/question/589639535/answer/2936696161\">知乎回答\r\nOpenAI 发布 GPT-4，有哪些技术上的优化或突破?</a></li>\r\n<li><a\r\nhref=\"https://zhuanlan.zhihu.com/p/609877277\">追赶ChatGPT的难点与平替</a></li>\r\n<li><a\r\nhref=\"https://zhuanlan.zhihu.com/p/615554635\">压缩即泛化，泛化即智能</a>\r\n⭐️</li>\r\n<li><a\r\nhref=\"https://new.qq.com/rain/a/20230423A08J7400\">陆奇最新演讲实录：我的大模型世界观｜第十四期</a></li>\r\n<li><a href=\"https://lilianweng.github.io/posts/2023-06-23-agent/\">LLM\r\nPowered Autonomous Agents</a> ⭐️</li>\r\n<li><a\r\nhref=\"https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac\">All\r\nYou Need to Know to Build Your First LLM App</a> ⭐️</li>\r\n<li><a\r\nhref=\"https://www.semianalysis.com/p/gpt-4-architecture-infrastructure\">GPT-4\r\nArchitecture, Infrastructure, Training Dataset, Costs, Vision,\r\nMoE</a></li>\r\n<li><a\r\nhref=\"https://weread.qq.com/web/bookDetail/93832630811e7e827g0173ca\">为什么伟大不能被计划</a>:\r\nOpenAI研究员出书</li>\r\n<li><a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&amp;mid=2649769138&amp;idx=1&amp;sn=2c408b73f66a52e43ea991b957729519&amp;chksm=bec3d9af89b450b95e6432dc33f4f32ae7a29cc8e2916369aad6156c5817927d1f73a0c84e82&amp;scene=21#wechat_redirect\">拾象投研机构对LLM的调研报告（文中有两次PPT的申请链接）</a>:\r\n对大模型应用给出了很全面的总结梳理</li>\r\n<li><a href=\"https://www.guotaixia.com/post/5336.html\">启明创投State of\r\nGenerative AI 2023</a>:\r\n最近发现应用落地才是LLM真正产生价值的核心，开始更多关注一些投研的分析报告</li>\r\n<li><a\r\nhref=\"https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated\">How\r\nto Use AI to Do Stuff: An Opinionated Guide</a></li>\r\n<li><a href=\"https://www.interconnects.ai/p/llama-2-from-meta\">Llama 2:\r\nan incredible open LLM</a></li>\r\n<li><a\r\nhref=\"https://book.douban.com/subject/36449803/?icn=index-latestbook-subject\">Wolfram语言之父新书：这就是ChatGPT</a></li>\r\n<li><a\r\nhref=\"https://pair.withgoogle.com/explorables/grokking/\">谷歌出品：对大模型领悟能力的一些探索很有意思\r\nDo Machine Learning Models Memorize or Generalize?</a> ⭐️</li>\r\n<li><a\r\nhref=\"https://simons.berkeley.edu/talks/ilya-sutskever-openai-2023-08-14\">OpenAI首席科学家最新讲座解读LM无监督预训练学了啥\r\nAn observation on Generalization</a> ⭐️</li>\r\n<li><a\r\nhref=\"https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents\">The\r\nComplete Beginners Guide To Autonomous Agents</a>: Octane AI创始人 Matt\r\nSchlicht发表的关于人工智能代理的一些思考</li>\r\n<li><a\r\nhref=\"https://yaofu.notion.site/An-Initial-Exploration-of-Theoretical-Support-for-Language-Model-Data-Engineering-Part-1-Pretraini-dc480d9bf7ff4659afd8c9fb738086eb\">An\r\nInitial Exploration of Theoretical Support for Language Model Data\r\nEngineering. Part 1: Pretraining</a>:\r\n符尧大佬系列新作，通过了解大模型背后的数据工程来了解模型本质，第一篇预训练数据</li>\r\n<li><a\r\nhref=\"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650893355&amp;idx=1&amp;sn=5911ccc05abf5177bb71a47ea5a748c8&amp;chksm=84e4a855b39321434a2a386c9f359979da99dd441e6cf8f88062f1e909ad8f5b9b24198d1edb&amp;scene=0&amp;xtrack=1\">Large\r\nLanguage Models (in 2023)</a> OpenAI科学家最新大模型演讲</li>\r\n</ul>\r\n<h2 id=\"papers\">Papers</h2>\r\n<h3 id=\"paper-list\">paper List</h3>\r\n<ul>\r\n<li>https://github.com/dongguanting/In-Context-Learning_PaperList</li>\r\n<li>https://github.com/thunlp/PromptPapers</li>\r\n<li>https://github.com/Timothyxxx/Chain-of-ThoughtsPapers</li>\r\n<li>https://github.com/thunlp/ToolLearningPapers</li>\r\n<li>https://github.com/MLGroupJLU/LLM-eval-survey</li>\r\n</ul>\r\n<h3 id=\"综述\">综述</h3>\r\n<ul>\r\n<li>A Survey of Large Language Models</li>\r\n<li>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting\r\nMethods in Natural Language Processing ⭐️</li>\r\n<li>Paradigm Shift in Natural Language Processing</li>\r\n<li>Pre-Trained Models: Past, Present and Future</li>\r\n<li>What Language Model Architecture and Pretraining objects work best\r\nfor zero shot generalization ⭐️</li>\r\n<li>Towards Reasoning in Large Language Models: A Survey</li>\r\n<li>Reasoning with Language Model Prompting: A Survey ⭐️</li>\r\n<li>An Overview on Language Models: Recent Developments and Outlook\r\n⭐️</li>\r\n<li>A Survey of Large Language Models[6.29更新版]</li>\r\n<li>Unifying Large Language Models and Knowledge Graphs: A Roadmap</li>\r\n<li>Augmented Language Models: a Survey ⭐️</li>\r\n<li>Domain Specialization as the Key to Make Large Language Models\r\nDisruptive: A Comprehensive Survey</li>\r\n<li>Challenges and Applications of Large Language Models</li>\r\n<li>The Rise and Potential of Large Language Model Based Agents: A\r\nSurvey</li>\r\n</ul>\r\n<h3 id=\"大模型能力探究\">大模型能力探究</h3>\r\n<ul>\r\n<li>In Context Learning\r\n<ul>\r\n<li>LARGER LANGUAGE MODELS DO IN-CONTEXT LEARNING DIFFERENTLY</li>\r\n<li>How does in-context learning work? A framework for understanding the\r\ndifferences from traditional supervised learning</li>\r\n<li>Why can GPT learn in-context? Language Model Secretly Perform\r\nGradient Descent as Meta-Optimizers ⭐️</li>\r\n<li>Rethinking the Role of Demonstrations What Makes incontext learning\r\nwork? ⭐️</li>\r\n<li>Trained Transformers Learn Linear Models In-Context</li>\r\n</ul></li>\r\n<li>涌现能力\r\n<ul>\r\n<li>Sparks of Artificial General Intelligence: Early experiments with\r\nGPT-4</li>\r\n<li>Emerging Ability of Large Language Models ⭐️</li>\r\n<li>LANGUAGE MODELS REPRESENT SPACE AND TIME</li>\r\n</ul></li>\r\n<li>能力评估\r\n<ul>\r\n<li>IS CHATGPT A GENERAL-PURPOSE NATURAL LANGUAGE PROCESSING TASK\r\nSOLVER?</li>\r\n<li>Can Large Language Models Infer Causation from Correlation?</li>\r\n<li>Holistic Evaluation of Language Model</li>\r\n<li>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and\r\nBeyond</li>\r\n<li>Theory of Mind May Have Spontaneously Emerged in Large Language\r\nModels</li>\r\n<li>Beyond The Imitation Game: Quantifying And Extrapolating The\r\nCapabilities Of Language Models</li>\r\n<li>Do Models Explain Themselves? Counterfactual Simulatability of\r\nNatural Language Explanations</li>\r\n<li>Demystifying GPT Self-Repair for Code Generation</li>\r\n<li>Evidence of Meaning in Language Models Trained on Programs</li>\r\n<li>Can Explanations Be Useful for Calibrating Black Box Models</li>\r\n<li>On the Robustness of ChatGPT: An Adversarial and Out-of-distribution\r\nPerspective</li>\r\n<li>Language acquisition: do children and language models follow similar\r\nlearning stages?</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"prompt-tunning范式\">Prompt Tunning范式</h3>\r\n<ul>\r\n<li>Tunning Free Prompt\r\n<ul>\r\n<li>GPT2: Language Models are Unsupervised Multitask Learners</li>\r\n<li>GPT3: Language Models are Few-Shot Learners ⭐️</li>\r\n<li>LAMA: Language Models as Knowledge Bases?</li>\r\n<li>AutoPrompt: Eliciting Knowledge from Language Models</li>\r\n</ul></li>\r\n<li>Fix-Prompt LM Tunning\r\n<ul>\r\n<li>T5: Exploring the Limits of Transfer Learning with a Unified\r\nText-to-Text Transformer</li>\r\n<li>PET-TC(a): Exploiting Cloze Questions for Few Shot Text\r\nClassification and Natural Language Inference ⭐️</li>\r\n<li>PET-TC(b): PETSGLUE It’s Not Just Size That Matters Small Language\r\nModels are also few-shot learners</li>\r\n<li>GenPET: Few-Shot Text Generation with Natural Language\r\nInstructions</li>\r\n<li>LM-BFF: Making Pre-trained Language Models Better Few-shot Learners\r\n⭐️</li>\r\n<li>ADEPT: Improving and Simplifying Pattern Exploiting Training</li>\r\n</ul></li>\r\n<li>Fix-LM Prompt Tunning\r\n<ul>\r\n<li>Prefix-tuning: Optimizing continuous prompts for generation</li>\r\n<li>Prompt-tunning: The power of scale for parameter-efficient prompt\r\ntuning ⭐️</li>\r\n<li>P-tunning: GPT Understands Too ⭐️</li>\r\n<li>WARP: Word-level Adversarial ReProgramming</li>\r\n</ul></li>\r\n<li>LM + Prompt Tunning\r\n<ul>\r\n<li>P-tunning v2: Prompt Tuning Can Be Comparable to Fine-tunning\r\nUniversally Across Scales and Tasks</li>\r\n<li>PTR: Prompt Tuning with Rules for Text Classification</li>\r\n<li>PADA: Example-based Prompt Learning for on-the-fly Adaptation to\r\nUnseen Domains</li>\r\n</ul></li>\r\n<li>Fix-LM Adapter Tunning\r\n<ul>\r\n<li>LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS ⭐️</li>\r\n<li>LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer\r\nLearning</li>\r\n<li>Parameter-Efficient Transfer Learning for NLP</li>\r\n<li>INTRINSIC DIMENSIONALITY EXPLAINS THE EFFECTIVENESS OF LANGUAGE\r\nMODEL FINE-TUNING</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"主流llms\">主流LLMS</h3>\r\n<ul>\r\n<li>GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL</li>\r\n<li>LLaMA: Open and Efficient Foundation Language Models</li>\r\n<li>PaLM: Scaling Language Modeling with Pathways</li>\r\n<li>PaLM 2 Technical Report</li>\r\n<li>GPT-4 Technical Report</li>\r\n<li>Backpack Language Models</li>\r\n<li>Llama 2: Open Foundation and Fine-Tuned Chat Models</li>\r\n<li>OpenBA: An Open-sourced 15B Bilingual Asymmetric seq2seq Model\r\nPre-trained from Scratch</li>\r\n<li>Sheared LLaMA: Accelerating Language Model Pre-training via\r\nStructured Pruning</li>\r\n<li>Mistral 7B</li>\r\n</ul>\r\n<h3 id=\"指令微调对齐-instruction_tunning\">指令微调&amp;对齐\r\n(instruction_tunning)</h3>\r\n<ul>\r\n<li>经典方案\r\n<ul>\r\n<li>Flan: FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS ⭐️</li>\r\n<li>Flan-T5: Scaling Instruction-Finetuned Language Models</li>\r\n<li>ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning</li>\r\n<li>Instruct-GPT: Training language models to follow instructions with\r\nhuman feedback ⭐️</li>\r\n<li>T0: MULTITASK PROMPTED TRAINING ENABLES ZERO-SHOT TASK\r\nGENERALIZATION</li>\r\n<li>Natural Instructions: Cross-Task Generalization via Natural Language\r\nCrowdsourcing Instructions</li>\r\n<li>Tk-INSTRUCT: SUPER-NATURALINSTRUCTIONS: Generalization via\r\nDeclarative Instructions on 1600+ NLP Tasks</li>\r\n<li>ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves\r\nZero-shot Generalization</li>\r\n<li>Unnatural Instructions: Tuning Language Models with (Almost) No\r\nHuman Labor</li>\r\n<li>INSTRUCTEVAL Towards Holistic Evaluation of Instrucion-Tuned Large\r\nLanguage Models</li>\r\n</ul></li>\r\n<li>更少，质量更高、更多样的指令数据带来质变\r\n<ul>\r\n<li>LIMA: Less Is More for Alignment ⭐️</li>\r\n<li>Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low\r\nTraining Data Instruction Tuning</li>\r\n<li>Textbooks Are All You Need ⭐️</li>\r\n<li>AlpaGasus: Training A Better Alpaca with Fewer Data</li>\r\n<li>InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning\r\nMiniGPT-4</li>\r\n<li>Instruction Mining: High-Quality Instruction Data Selection for\r\nLarge Language Models</li>\r\n<li>Visual Instruction Tuning with Polite Flamingo</li>\r\n</ul></li>\r\n<li>新对齐/微调方案\r\n<ul>\r\n<li>WizardLM: Empowering Large Language Models to Follow Complex\r\nInstructions</li>\r\n<li>Becoming self-instruct: introducing early stopping criteria for\r\nminimal instruct tuning</li>\r\n<li>Self-Alignment with Instruction Backtranslation ⭐️</li>\r\n<li>Mixture-of-Experts Meets Instruction Tuning:A Winning Combination\r\nfor Large Language Models</li>\r\n<li>Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks</li>\r\n<li>PROMPT2MODEL: Generating Deployable Models from Natural Language\r\nInstructions</li>\r\n<li>OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs</li>\r\n<li>Principle-Driven Self-Alignment of Language Models from Scratch with\r\nMinimal Human Supervision</li>\r\n<li>Improving Language Model Negotiation with Self-Play and In-Context\r\nLearning from AI Feedback</li>\r\n</ul></li>\r\n<li>微调经验/实验报告\r\n<ul>\r\n<li>BELLE: Exploring the Impact of Instruction Data Scaling on Large\r\nLanguage Models: An Empirical Study on Real-World Use Cases</li>\r\n<li>Baize: Baize: An Open-Source Chat Model with Parameter-Efficient\r\nTuning on Self-Chat Data</li>\r\n<li>A Comparative Study between Full-Parameter and LoRA-based\r\nFine-Tuning on Chinese Instruction Data for Large LM</li>\r\n<li>Exploring ChatGPT’s Ability to Rank Content: A Preliminary Study on\r\nConsistency with Human Preferences</li>\r\n<li>Towards Better Instruction Following Language Models for Chinese:\r\nInvestigating the Impact of Training Data and Evaluation</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"对话模型\">对话模型</h3>\r\n<ul>\r\n<li>LaMDA: Language Models for Dialog Applications</li>\r\n<li>Sparrow: Improving alignment of dialogue agents via targeted human\r\njudgements ⭐️</li>\r\n<li>BlenderBot 3: a deployed conversational agent that continually\r\nlearns to responsibly engage</li>\r\n<li>How NOT To Evaluate Your Dialogue System: An Empirical Study of\r\nUnsupervised Evaluation Metrics for Dialogue Response Generation</li>\r\n<li>DialogStudio: Towards Richest and Most Diverse Unified Dataset\r\nCollection for Conversational AI</li>\r\n<li>Enhancing Chat Language Models by Scaling High-quality Instructional\r\nConversations</li>\r\n<li>DiagGPT: An LLM-based Chatbot with Automatic Topic Management for\r\nTask-Oriented Dialogue</li>\r\n</ul>\r\n<h3 id=\"思维链-prompt_chain_of_thought\">思维链\r\n(prompt_chain_of_thought)</h3>\r\n<ul>\r\n<li>基础&amp;进阶用法\r\n<ul>\r\n<li>[zero-shot-COT] Large Language Models are Zero-Shot Reasoners\r\n⭐️</li>\r\n<li>[few-shot COT] Chain of Thought Prompting Elicits Reasoning in Large\r\nLanguage Models ⭐️</li>\r\n<li>SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE\r\nMODELS</li>\r\n<li>LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE\r\nMODELS ⭐️</li>\r\n<li>Tree of Thoughts: Deliberate Problem Solving with Large Language\r\nModels</li>\r\n<li>Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought\r\nReasoning by Large Language Models</li>\r\n<li>Decomposed Prompting A MODULAR APPROACH FOR Solving Complex\r\nTasks</li>\r\n<li>Successive Prompting for Decomposing Complex Questions</li>\r\n<li>Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought\r\nFramework</li>\r\n<li>Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in\r\nLarge Language Models</li>\r\n<li>Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for\r\nMulti-hop Visual Reasoning</li>\r\n<li>LAMBADA: Backward Chaining for Automated Reasoning in Natural\r\nLanguage</li>\r\n<li>Algorithm of Thoughts: Enhancing Exploration of Ideas in Large\r\nLanguage Models</li>\r\n<li>Graph of Thoughts: Solving Elaborate Problems with Large Language\r\nModels</li>\r\n</ul></li>\r\n<li>分领域COT [Math, Code, Tabular, QA]\r\n<ul>\r\n<li>Solving Quantitative Reasoning Problems with Language Models</li>\r\n<li>SHOW YOUR WORK: SCRATCHPADS FOR INTERMEDIATE COMPUTATION WITH\r\nLANGUAGE MODELS</li>\r\n<li>Solving math word problems with processand outcome-based\r\nfeedback</li>\r\n<li>CodeRL: Mastering Code Generation through Pretrained Models and Deep\r\nReinforcement Learning</li>\r\n<li>T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large\r\nLanguage Model Signals for Science Question Answering</li>\r\n<li>LEARNING PERFORMANCE-IMPROVING CODE EDITS</li>\r\n<li>Large Language Models are Versatile Decomposers: Decompose Evidence\r\nand Questions for Table-based Reasoning</li>\r\n<li>Tab-CoT: Zero-shot Tabular Chain of Thought</li>\r\n</ul></li>\r\n<li>原理分析\r\n<ul>\r\n<li>Towards Understanding Chain-of-Thought Prompting: An Empirical Study\r\nof What Matters ⭐️</li>\r\n<li>TEXT AND PATTERNS: FOR EFFECTIVE CHAIN OF THOUGHT IT TAKES TWO TO\r\nTANGO</li>\r\n<li>Towards Revealing the Mystery behind Chain of Thought: a Theoretical\r\nPerspective</li>\r\n<li>Large Language Models Can Be Easily Distracted by Irrelevant\r\nContext</li>\r\n</ul></li>\r\n<li>小模型COT蒸馏\r\n<ul>\r\n<li>Specializing Smaller Language Models towards Multi-Step Reasoning\r\n⭐️</li>\r\n<li>Teaching Small Language Models to Reason</li>\r\n<li>Large Language Models are Reasoning Teachers</li>\r\n<li>Distilling Reasoning Capabilities into Smaller Language Models</li>\r\n<li>The CoT Collection: Improving Zero-shot and Few-shot Learning of\r\nLanguage Models via Chain-of-Thought Fine-Tuning</li>\r\n</ul></li>\r\n<li>COT样本自动构建/选择\r\n<ul>\r\n<li>STaR: Self-Taught Reasoner Bootstrapping ReasoningWith\r\nReasoning</li>\r\n<li>AutoCOT：AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE\r\nMODELS</li>\r\n<li>Large Language Models Can Self-Improve</li>\r\n<li>Active Prompting with Chain-of-Thought for Large Language\r\nModels</li>\r\n<li>COMPLEXITY-BASED PROMPTING FOR MULTI-STEP REASONING</li>\r\n</ul></li>\r\n<li>others\r\n<ul>\r\n<li>OlaGPT Empowering LLMs With Human-like Problem-Solving\r\nabilities</li>\r\n<li>Challenging BIG-Bench tasks and whether chain-of-thought can solve\r\nthem</li>\r\n<li>Large Language Models are Better Reasoners with\r\nSelf-Verification</li>\r\n<li>ThoughtSource A central hub for large language model reasoning\r\ndata</li>\r\n<li>Two Failures of Self-Consistency in the Multi-Step Reasoning of\r\nLLMs</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"rlhf\">RLHF</h3>\r\n<ul>\r\n<li>Deepmind\r\n<ul>\r\n<li>Teaching language models to support answers with verified\r\nquotes</li>\r\n<li>sparrow, Improving alignment of dialogue agents via targetd human\r\njudgements ⭐️</li>\r\n</ul></li>\r\n<li>openai\r\n<ul>\r\n<li>PPO: Proximal Policy Optimization Algorithms ⭐️</li>\r\n<li>Deep Reinforcement Learning for Human Preference</li>\r\n<li>Fine-Tuning Language Models from Human Preferences</li>\r\n<li>learning to summarize from human feedback</li>\r\n<li>InstructGPT: Training language models to follow instructions with\r\nhuman feedback ⭐️</li>\r\n<li>Scaling Laws for Reward Model Over optimization ⭐️</li>\r\n</ul></li>\r\n<li>Anthropic\r\n<ul>\r\n<li>A General Language Assistant as a Laboratory for Alignmen</li>\r\n<li>Red Teaming Language Models to Reduce Harms Methods,Scaling\r\nBehaviors and Lessons Learned</li>\r\n<li>Training a Helpful and Harmless Assistant with Reinforcement\r\nLearning from Human Feedback ⭐️</li>\r\n<li>Constitutional AI Harmlessness from AI Feedback ⭐️</li>\r\n<li>Pretraining Language Models with Human Preferences</li>\r\n<li>The Capacity for Moral Self-Correction in Large Language Models</li>\r\n</ul></li>\r\n<li>AllenAI, RL4LM：IS REINFORCEMENT LEARNING (NOT) FOR NATURAL LANGUAGE\r\nPROCESSING BENCHMARKS</li>\r\n<li>改良方案\r\n<ul>\r\n<li>RRHF: Rank Responses to Align Language Models with Human Feedback\r\nwithout tears</li>\r\n<li>PRM：Let's verify step by step</li>\r\n<li>Chain of Hindsight Aligns Language Models with Feedback</li>\r\n<li>AlpacaFarm: A Simulation Framework for Methods that Learn from Human\r\nFeedback</li>\r\n<li>Open Problems and Fundamental Limitations of Reinforcement Learning\r\nfrom Human Feedback</li>\r\n<li>RAFT: Reward rAnked FineTuning for Generative Foundation Model\r\nAlignment</li>\r\n</ul></li>\r\n<li>Training Socially Aligned Language Models in Simulated Human\r\nSociety</li>\r\n</ul>\r\n<h3 id=\"llm-agent-让模型使用工具-llm_agent\">LLM Agent 让模型使用工具\r\n(llm_agent)</h3>\r\n<ul>\r\n<li>基于prompt通用方案\r\n<ul>\r\n<li>ReAct: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS ⭐️</li>\r\n<li>Self-ask: MEASURING AND NARROWING THE COMPOSITIONALITY GAP IN\r\nLANGUAGE MODELS ⭐️</li>\r\n<li>MRKL SystemsA modular, neuro-symbolic architecture that combines\r\nlarge language models, external knowledge sources and discrete\r\nreasoning</li>\r\n<li>PAL: Program-aided Language Models</li>\r\n<li>ART: Automatic multi-step reasoning and tool-use for large language\r\nmodels</li>\r\n<li>ReWOO: Decoupling Reasoning from Observations for Efficient\r\nAugmented Language Models ⭐️</li>\r\n<li>Interleaving Retrieval with Chain-of-Thought Reasoning for\r\nKnowledge-Intensive Multi-Step Questions</li>\r\n<li>Chameleon: Plug-and-Play Compositional Reasoning with Large Language\r\nModels ⭐️</li>\r\n<li>Faithful Chain-of-Thought Reasoning</li>\r\n<li>Reflexion: Language Agents with Verbal Reinforcement Learning\r\n⭐️</li>\r\n<li>Search-in-the-Chain: Towards Accurate, Credible and Traceable Large\r\nLanguage Models for Knowledge-intensive Tasks</li>\r\n<li>Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought\r\nFramework</li>\r\n<li>RestGPT: Connecting Large Language Models with Real-World RESTful\r\nAPIs</li>\r\n<li>ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based\r\nLarge Language Models</li>\r\n<li>InstructTODS: Large Language Models for End-to-End Task-Oriented\r\nDialogue Systems</li>\r\n</ul></li>\r\n<li>基于微调通用方案\r\n<ul>\r\n<li>TALM: Tool Augmented Language Models</li>\r\n<li>Toolformer: Language Models Can Teach Themselves to Use Tools\r\n⭐️</li>\r\n<li>Tool Learning with Foundation Models</li>\r\n<li>Tool Maker：Large Language Models as Tool Maker</li>\r\n<li>TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with\r\nMillions of APIs</li>\r\n</ul></li>\r\n<li>检索增强方案\r\n<ul>\r\n<li>WebGPT：Browser-assisted question-answering with human feedback</li>\r\n<li>WebGLM: Towards An Efficient Web-Enhanced Question Answering System\r\nwith Human Preferences</li>\r\n<li>WebCPM: Interactive Web Search for Chinese Long-form Question\r\nAnswering ⭐️</li>\r\n<li>REPLUG: Retrieval-Augmented Black-Box Language Models</li>\r\n<li>Query Rewriting for Retrieval-Augmented Large Language Models</li>\r\n<li>RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit</li>\r\n<li>Atlas: Few-shot Learning with Retrieval Augmented Language\r\nModels</li>\r\n<li>RRAML: Reinforced Retrieval Augmented Machine Learning</li>\r\n<li>Investigating the Factual Knowledge Boundary of Large Language\r\nModels with Retrieval Augmentation</li>\r\n<li>PDFTriage: Question Answering over Long, Structured Documents</li>\r\n</ul></li>\r\n<li>调用模型方案\r\n<ul>\r\n<li>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in\r\nHuggingFace</li>\r\n<li>Gorilla：Large Language Model Connected with Massive APIs ⭐️</li>\r\n<li>OpenAGI: When LLM Meets Domain Experts</li>\r\n</ul></li>\r\n<li>垂直领域\r\n<ul>\r\n<li>WebShop: Towards Scalable Real-World Web Interaction with Grounded\r\nLanguage Agents</li>\r\n<li>ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via\r\nTool Embeddings</li>\r\n<li>ChemCrow Augmenting large language models with chemistry tools</li>\r\n<li>Data-Copilot: Bridging Billions of Data and Humans with Autonomous\r\nWorkflow</li>\r\n<li>GeneGPT: Augmenting Large Language Models with Domain Tools for\r\nImproved Access to Biomedical Information</li>\r\n<li>PointLLM: Empowering Large Language Models to Understand Point\r\nClouds</li>\r\n<li>Interpretable Long-Form Legal Question Answering with\r\nRetrieval-Augmented Large Language Models</li>\r\n<li>Generating Explanations in Medical Question-Answering by Expectation\r\nMaximization Inference over Evidence</li>\r\n<li>CarExpert: Leveraging Large Language Models for In-Car\r\nConversational Question Answering</li>\r\n</ul></li>\r\n<li>评估\r\n<ul>\r\n<li>Evaluating Verifiability in Generative Search Engines</li>\r\n<li>Mind2Web: Towards a Generalist Agent for the Web</li>\r\n<li>Auto-GPT for Online Decision Making: Benchmarks and Additional\r\nOpinions</li>\r\n<li>API-Bank: A Benchmark for Tool-Augmented LLMs</li>\r\n<li>ToolLLM: Facilitating Large Language Models to Master 16000+\r\nReal-world APIs</li>\r\n</ul></li>\r\n<li>MultiAgent\r\n<ul>\r\n<li>Generative Agents: Interactive Simulacra of Human Behavior</li>\r\n<li>AgentVerse: Facilitating Multi-Agent Collaboration and Exploring\r\nEmergent Behaviors in Agents</li>\r\n<li>CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale\r\nLanguage Model Society</li>\r\n<li>Exploring Large Language Models for Communication Games: An\r\nEmpirical Study on Werewolf</li>\r\n<li>Communicative Agents for Software Development</li>\r\n</ul></li>\r\n<li>其他\r\n<ul>\r\n<li>LLM+P: Empowering Large Language Models with Optimal Planning\r\nProficiency</li>\r\n<li>Inference with Reference: Lossless Acceleration of Large Language\r\nModels</li>\r\n<li>RecallM: An Architecture for Temporal Context Understanding and\r\nQuestion Answering</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"指令数据生成-instruction_data_gen\">指令数据生成\r\n(instruction_data_gen)</h3>\r\n<ul>\r\n<li>APE: LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS ⭐️</li>\r\n<li>SELF-INSTRUCT: Aligning Language Model with Self Generated\r\nInstructions ⭐️</li>\r\n<li>iPrompt: Explaining Data Patterns in Natural Language via\r\nInterpretable Autoprompting</li>\r\n<li>Flipped Learning: Guess the Instruction! Flipped Learning Makes\r\nLanguage Models Stronger Zero-Shot Learners</li>\r\n<li>Fairness-guided Few-shot Prompting for Large Language Models</li>\r\n<li>Instruction induction: From few examples to natural language task\r\ndescriptions.</li>\r\n<li>Baize An Open-Source Chat Model with Parameter-Efficient Tuning on\r\nself-Chat Data</li>\r\n<li>SELF-QA Unsupervised Knowledge Guided alignment.</li>\r\n<li>GPT Self-Supervision for a Better Data Annotator</li>\r\n<li>The Flan Collection Designing Data and Methods</li>\r\n<li>Self-Consuming Generative Models Go MAD</li>\r\n<li>InstructEval: Systematic Evaluation of Instruction Selection\r\nMethods</li>\r\n<li>Overwriting Pretrained Bias with Finetuning Data</li>\r\n<li>WizardLM: Empowering Large Language Models to Follow Complex\r\nInstructions</li>\r\n</ul>\r\n<h3 id=\"预训练数据pretrain_data\">预训练数据(pretrain_data)</h3>\r\n<ul>\r\n<li>DoReMi: Optimizing Data Mixtures Speeds Up Language Model\r\nPretraining</li>\r\n<li>The Pile: An 800GB Dataset of Diverse Text for Language\r\nModeling</li>\r\n<li>CCNet: Extracting High Quality Monolingual Datasets fromWeb Crawl\r\nData</li>\r\n<li>WanJuan: A Comprehensive Multimodal Dataset for Advancing English\r\nand Chinese Large Models</li>\r\n<li>CLUECorpus2020: A Large-scale Chinese Corpus for Pre-training\r\nLanguage Model</li>\r\n</ul>\r\n<h3 id=\"领域模型-domain_llms\">领域模型 (domain_llms)</h3>\r\n<ul>\r\n<li>MedGPT: Medical Concept Prediction from Clinical Narratives</li>\r\n<li>BioGPT：Generative Pre-trained Transformer for Biomedical Text\r\nGeneration and Mining</li>\r\n<li>Galactia：A Large Language Model for Science</li>\r\n<li>PubMed GPT: A Domain-specific large language model for biomedical\r\ntext ⭐️</li>\r\n<li>BloombergGPT： A Large Language Model for Finance</li>\r\n<li>ChatDoctor：Medical Chat Model Fine-tuned on LLaMA Model using\r\nMedical Domain Knowledge</li>\r\n<li>Med-PaLM：Large Language Models Encode Clinical Knowledge[V1,V2]\r\n⭐️</li>\r\n<li>Augmented Large Language Models with Parametric Knowledge\r\nGuiding</li>\r\n<li>XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of\r\nBillions Parameters</li>\r\n<li>ChatLaw Open-Source Legal Large Language Model ⭐️</li>\r\n<li>MediaGPT : A Large Language Model For Chinese Media</li>\r\n<li>SMILE: Single-turn to Multi-turn Inclusive Language Expansion via\r\nChatGPT for Mental Health Support</li>\r\n<li>KITLM: Domain-Specific Knowledge InTegration into Language Models\r\nfor Question Answering</li>\r\n<li>FinVis-GPT: A Multimodal Large Language Model for Financial Chart\r\nAnalysis</li>\r\n<li>EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task\r\nTasks for E-commerce</li>\r\n<li>FinGPT: Open-Source Financial Large Language Models</li>\r\n<li>TableGPT: Towards Unifying Tables, Nature Language and Commands into\r\nOne GPT</li>\r\n<li>CFGPT: Chinese Financial Assistant with Large Language Model</li>\r\n<li>Zhongjing: Enhancing the Chinese Medical Capabilities of Large\r\nLanguage Model through Expert Feedback and Real-world Multi-turn\r\nDialogue</li>\r\n</ul>\r\n<h3 id=\"llm超长文本处理-long_input\">LLM超长文本处理 (long_input)</h3>\r\n<ul>\r\n<li>Parallel Context Windows for Large Language Models</li>\r\n<li>Structured Prompting: Scaling In-Context Learning to 1,000\r\nExamples</li>\r\n<li><a href=\"https://spaces.ac.cn/archives/9617\">苏剑林,\r\nNBCE：使用朴素贝叶斯扩展LLM的Context处理长度</a> ⭐️</li>\r\n<li>Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing\r\nImportant Tokens</li>\r\n<li>Unlimiformer: Long-Range Transformers with Unlimited Length\r\nInput</li>\r\n<li>Scaling Transformer to 1M tokens and beyond with RMT</li>\r\n<li>RECURRENTGPT: Interactive Generation of (Arbitrarily) Long Text</li>\r\n<li>TRAIN SHORT, TEST LONG: ATTENTION WITH LINEAR BIASES ENABLES INPUT\r\nLENGTH EXTRAPOLATION ⭐️</li>\r\n<li>FlashAttention: Fast and Memory-Efficient Exact Attention with\r\nIO-Awareness</li>\r\n<li>Extending Context Window of Large Language Models via Positional\r\nInterpolation</li>\r\n<li>LongNet: Scaling Transformers to 1,000,000,000 Tokens</li>\r\n<li>https://kaiokendev.github.io/til#extending-context-to-8k</li>\r\n<li><a\r\nhref=\"https://spaces.ac.cn/archives/9675\">苏剑林,Transformer升级之路：10、RoPE是一种β进制编码</a>\r\n⭐️</li>\r\n<li><a\r\nhref=\"https://spaces.ac.cn/archives/9706\">苏剑林,Transformer升级之路：11、将β进制位置进行到底</a></li>\r\n<li><a\r\nhref=\"https://spaces.ac.cn/archives/9708\">苏剑林,Transformer升级之路：12、无限外推的ReRoPE？</a></li>\r\n<li>Focused Transformer: Contrastive Training for Context Scaling</li>\r\n<li>Lost in the Middle: How Language Models Use Long Contexts ⭐️</li>\r\n<li>EFFICIENT STREAMING LANGUAGE MODELS WITH ATTENTION SINKS</li>\r\n<li>Ring Attention with Blockwise Transformers for Near-Infinite\r\nContext</li>\r\n</ul>\r\n<h3 id=\"nl2sql\">NL2SQL</h3>\r\n<ul>\r\n<li>大模型方案\r\n<ul>\r\n<li>DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with\r\nSelf-Correction ⭐️</li>\r\n<li>C3: Zero-shot Text-to-SQL with ChatGPT ⭐️</li>\r\n<li>SQL-PALM: IMPROVED LARGE LANGUAGE MODEL ADAPTATION FOR\r\nTEXT-TO-SQL</li>\r\n<li>BIRD Can LLM Already Serve as A Database Interface? A BIg Bench for\r\nLarge-Scale Database Grounded Text-to-SQL ⭐️</li>\r\n<li>A Case-Based Reasoning Framework for Adaptive Prompting in\r\nCross-Domain Text-to-SQL</li>\r\n<li>ChatDB: AUGMENTING LLMS WITH DATABASES AS THEIR SYMBOLIC MEMORY</li>\r\n<li>A comprehensive evaluation of ChatGPT’s zero-shot Text-to-SQL\r\ncapability</li>\r\n<li>Few-shot Text-to-SQL Translation using Structure and Content Prompt\r\nLearning</li>\r\n</ul></li>\r\n<li>Domain Knowledge Intensive\r\n<ul>\r\n<li>Towards Knowledge-Intensive Text-to-SQL Semantic Parsing with\r\nFormulaic Knowledge</li>\r\n<li>Bridging the Generalization Gap in Text-to-SQL Parsing with Schema\r\nExpansion</li>\r\n<li>Towards Robustness of Text-to-SQL Models against Synonym\r\nSubstitution</li>\r\n<li>FinQA: A Dataset of Numerical Reasoning over Financial Data</li>\r\n</ul></li>\r\n<li>others\r\n<ul>\r\n<li>RESDSQL: Decoupling Schema Linking and Skeleton Parsing for\r\nText-to-SQL</li>\r\n<li>MIGA: A Unified Multi-task Generation Framework for Conversational\r\nText-to-SQL</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"降低模型幻觉-reliability\">降低模型幻觉 (reliability)</h3>\r\n<ul>\r\n<li>Survey of Hallucination in Natural Language Generation</li>\r\n<li>Trusting Your Evidence: Hallucinate Less with Context-aware Decoding\r\n⭐️</li>\r\n<li>SELF-REFINE:ITERATIVE REFINEMENT WITH SELF-FEEDBACK ⭐️</li>\r\n<li>PROMPTING GPT-3 TO BE RELIABLE</li>\r\n<li>Enhancing Self-Consistency and Performance of Pre-Trained Language\r\nModels through Natural Language Inference</li>\r\n<li>On the Advance of Making Language Models Better Reasoners</li>\r\n<li>Progressive-Hint Prompting Improves Reasoning in Large Language\r\nModels</li>\r\n<li>ASK ME ANYTHING: A SIMPLE STRATEGY FOR PROMPTING LANGUAGE MODELS\r\n⭐️</li>\r\n<li>Inference-Time Intervention: Eliciting Truthful Answers from a\r\nLanguage Model</li>\r\n<li>Reflexion: an autonomous agent with dynamic memory and\r\nself-reflection</li>\r\n<li>Self-consistency for open-ended generations</li>\r\n<li>Check Your Facts and Try Again: Improving Large Language Models with\r\nExternal Knowledge and Automated Feedback</li>\r\n<li>Factuality Enhanced Language Models for Open-Ended Text\r\nGeneration</li>\r\n<li>Adaptive Chameleon or Stubborn Sloth: Unraveling the Behavior of\r\nLarge Language Models in Knowledge Clashes</li>\r\n<li>Rethinking with Retrieval: Faithful Large Language Model\r\nInference</li>\r\n<li>RefGPT: Reference → Truthful &amp; Customized Dialogues Generation\r\nby GPTs and for GPTs</li>\r\n<li>Enabling Large Language Models to Generate Text with Citations</li>\r\n<li>Large language models and the perils of their hallucinations</li>\r\n</ul>\r\n<h3 id=\"大模型评估evaluation\">大模型评估（evaluation）</h3>\r\n<ul>\r\n<li>事实性评估\r\n<ul>\r\n<li>TRUSTWORTHY LLMS: A SURVEY AND GUIDELINE FOR EVALUATING LARGE\r\nLANGUAGE MODELS’ ALIGNMENT</li>\r\n<li>TrueTeacher: Learning Factual Consistency Evaluation with Large\r\nLanguage Models</li>\r\n<li>TRUE: Re-evaluating Factual Consistency Evaluation</li>\r\n<li>SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for\r\nGenerative Large Language Models</li>\r\n<li>FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in\r\nLong Form Text Generation</li>\r\n<li>KoLA: Carefully Benchmarking World Knowledge of Large Language\r\nModels</li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"推理优化inference\">推理优化(inference)</h3>\r\n<ul>\r\n<li>Fast Transformer Decoding: One Write-Head is All You Need</li>\r\n<li>Fast Inference from Transformers via Speculative Decoding</li>\r\n<li>GQA: Training Generalized Multi-Query Transformer Models from\r\nMulti-Head Checkpoints</li>\r\n<li>Skeleton-of-Thought: Large Language Models Can Do Parallel\r\nDecoding</li>\r\n<li>SkipDecode: Autoregressive Skip Decoding with Batching and Caching\r\nfor Efficient LLM Inference</li>\r\n<li>BatchPrompt: Accomplish more with less</li>\r\n</ul>\r\n<h3\r\nid=\"模型知识编辑黑科技model_edit\">模型知识编辑黑科技(model_edit)</h3>\r\n<ul>\r\n<li>ROME：Locating and Editing Factual Associations in GPT</li>\r\n<li>Transformer Feed-Forward Layers Are Key-Value Memories</li>\r\n<li>MEMIT: Mass-Editing Memory in a Transformer</li>\r\n<li>MEND：Fast Model Editing at Scale</li>\r\n<li>Editing Large Language Models: Problems, Methods, and\r\nOpportunities</li>\r\n</ul>\r\n<h3 id=\"other-prompt-engineerprompt_engineer\">Other Prompt\r\nEngineer(prompt_engineer)</h3>\r\n<ul>\r\n<li>Calibrate Before Use: Improving Few-Shot Performance of Language\r\nModels</li>\r\n<li>In-Context Instruction Learning</li>\r\n<li>LEARNING PERFORMANCE-IMPROVING CODE EDITS</li>\r\n<li>Boosting Theory-of-Mind Performance in Large Language Models via\r\nPrompting</li>\r\n<li>Generated Knowledge Prompting for Commonsense Reasoning</li>\r\n<li>RECITATION-AUGMENTED LANGUAGE MODELS</li>\r\n<li>kNN PROMPTING: BEYOND-CONTEXT LEARNING WITH CALIBRATION-FREE NEAREST\r\nNEIGHBOR INFERENCE</li>\r\n<li>EmotionPrompt: Leveraging Psychology for Large Language Models\r\nEnhancement via Emotional Stimulus</li>\r\n<li>Causality-aware Concept Extraction based on Knowledge-guided\r\nPrompting</li>\r\n<li>LARGE LANGUAGE MODELS AS OPTIMIZERS</li>\r\n</ul>\r\n<h3 id=\"multimodal\">Multimodal</h3>\r\n<ul>\r\n<li>InstructBLIP: Towards General-purpose Vision-Language Models with\r\nInstruction Tuning</li>\r\n<li>Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation\r\nModels</li>\r\n<li>PaLM-E: An Embodied Multimodal Language Model</li>\r\n<li>LLava Visual Instruction Tuning</li>\r\n<li>MiniGPT-4: Enhancing Vision-Language Understanding with Advanced\r\nLarge Language Models</li>\r\n<li>TabLLM: Few-shot Classification of Tabular Data with Large Language\r\nModels</li>\r\n<li>BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich\r\nVisual Questions</li>\r\n<li>mPLUG-Owl : Modularization Empowers Large Language Models with\r\nMultimodality</li>\r\n<li>LVLM eHub: A Comprehensive Evaluation Benchmark for Large\r\nVisionLanguage Models</li>\r\n</ul>\r\n<h3 id=\"others\">Others</h3>\r\n<ul>\r\n<li>Pretraining on the Test Set Is All You Need\r\n哈哈作者你是懂讽刺文学的</li>\r\n<li>Learnware: Small Models Do Big</li>\r\n<li>The economic potential of generative AI</li>\r\n<li>A PhD Student’s Perspective on Research in NLP in the Era of Very\r\nLarge Language Models</li>\r\n</ul>\r\n<h1 id=\"参考链接来源\">🗂 参考链接来源</h1>\r\n<ul>\r\n<li><a\r\nhref=\"https://github.com/luban-agi/Awesome-AIGC-Tutorials/tree/main\">Awesome-AIGC-Tutorials/</a></li>\r\n<li><a\r\nhref=\"https://github.com/gongminmin/awesome-aigc\">https://github.com/gongminmin/awesome-aigc</a></li>\r\n<li><a\r\nhref=\"https://github.com/Moonvy/OpenPromptStudio\">https://github.com/Moonvy/OpenPromptStudio</a></li>\r\n<li><a\r\nhref=\"https://github.com/wshzd/Awesome-AIGC/tree/main\">https://github.com/wshzd/Awesome-AIGC/tree/main</a></li>\r\n<li><a\r\nhref=\"https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide\">https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide</a></li>\r\n<li>Stable Diffusion全套教程<a\r\nhref=\"https://github.com/ai-vip/stable-diffusion-tutorial\">https://github.com/ai-vip/stable-diffusion-tutorial</a></li>\r\n<li>https://github.com/open-mmlab/mmagic</li>\r\n<li>https://github.com/IDEA-CCNL/Fengshenbang-LM</li>\r\n</ul>\r\n<h1 id=\"友情链接\">🤝 友情链接</h1>\r\n<ul>\r\n<li><a href=\"http://waytoagi.com/\">WayToAGI</a>\r\n<ul>\r\n<li>WaytoAGI.com\r\n是最全面的中文AIGC资源知识库，包括最新AI动态、提示词、学习指南等，长期保持活跃更新。</li>\r\n</ul></li>\r\n<li><a href=\"https://github.com/luban-agi/Awesome-Tool-Learning\">Awesome\r\nTool Learning</a>\r\n<ul>\r\n<li>Awesome Tool Learning\r\n提供丰富的关于工具学习的资源，包括论文、框架和应用程序。</li>\r\n</ul></li>\r\n<li><a href=\"https://github.com/luban-agi/Awesome-Domain-LLM\">Awesome\r\nDomain LLM</a>\r\n<ul>\r\n<li>这个GitHub仓库是一个汇集和整理了自ChatGPT等大语言模型出现后，各种垂直领域开源模型、数据集和评测基准的列表，同时鼓励大家为其贡献未收录的资源。</li>\r\n</ul></li>\r\n</ul>\r\n<h1 id=\"声明\">🗂声明</h1>\r\n<p>以上部分资料来自网络整理，供大家学习参考，如有侵权，麻烦联系我删除！</p>\r\n","feature":true,"text":" AIGC项目展示 一、AIGC技术 这里收集了关于AIGC的各种精选教程和资源，既适合初学者也适合进阶AI爱好者。 📜 目录 👋 入门 💬 大语言模型 💡 提...","permalink":"/post/aigcpaper","photos":[],"count_time":{"symbolsCount":"88k","symbolsTime":"1:20"},"categories":[{"name":"人工智能","slug":"人工智能","count":9,"path":"api/categories/人工智能.json"}],"tags":[{"name":"核心算法","slug":"核心算法","count":8,"path":"api/tags/核心算法.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%80aigc%E6%8A%80%E6%9C%AF\"><span class=\"toc-text\">一、AIGC技术</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%9B%AE%E5%BD%95\"><span class=\"toc-text\">📜 目录</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%A5%E9%97%A8\"><span class=\"toc-text\">👋 入门</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B\"><span class=\"toc-text\">💡 提示工程</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5\"><span class=\"toc-text\">🔧 大语言模型实践</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA\"><span class=\"toc-text\">🔬 大语言模型理论</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ai%E7%BB%98%E7%94%BB\"><span class=\"toc-text\">🎨 AI绘画</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%89%BA%E6%9C%AF%E5%9F%BA%E7%A1%80%E4%B8%8Eai%E7%BB%98%E7%94%BB%E6%8A%80%E5%B7%A7\"><span class=\"toc-text\">🧑‍🎨 艺术基础与AI绘画技巧</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#stable-diffusion%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8\"><span class=\"toc-text\">🌊 Stable Diffusion原理与应用</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ai%E9%9F%B3%E9%A2%91\"><span class=\"toc-text\">🔊 AI音频</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E6%A8%A1%E6%80%81\"><span class=\"toc-text\">🌈 多模态</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0\"><span class=\"toc-text\">🧠 深度学习</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ai%E7%B3%BB%E7%BB%9F\"><span class=\"toc-text\">💻 AI系统</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E4%B8%AD%E5%9B%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8\"><span class=\"toc-text\">二、中国大模型列表</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8\"><span class=\"toc-text\">大模型列表</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9B%BD%E5%A4%96%E5%A4%A7%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">国外大模型</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%89aigc%E8%A7%86%E9%A2%91%E4%BC%9A%E8%AE%AE%E8%AE%BF%E8%B0%88\"><span class=\"toc-text\">三、AIGC视频会议&amp;访谈</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%99%BA%E6%BA%90%E7%A4%BE%E5%8C%BA\"><span class=\"toc-text\">智源社区</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AE%BF%E8%B0%88%E8%A7%86%E9%A2%91\"><span class=\"toc-text\">访谈&amp;视频</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E4%BD%93%E9%AA%8C%E6%95%88%E6%9E%9C%E4%B8%93%E4%B8%9A%E8%AF%84%E4%BC%B0\"><span class=\"toc-text\">LLM体验效果&amp;专业评估</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">LLM垂直领域大模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B3%95%E5%BE%8B\"><span class=\"toc-text\">法律</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8C%BB%E7%96%97\"><span class=\"toc-text\">医疗</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%87%91%E8%9E%8D\"><span class=\"toc-text\">金融</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">环境</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8\"><span class=\"toc-text\">网络安全</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BA%A4%E9%80%9A\"><span class=\"toc-text\">交通</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%B6%E4%BB%96\"><span class=\"toc-text\">其他</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B\"><span class=\"toc-text\">LLM文本检测</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E9%95%BF%E6%96%87%E6%9C%AC%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88\"><span class=\"toc-text\">LLM长文本解决方案</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E5%8F%AF%E6%8E%A7%E6%80%A7%E4%B8%8E%E5%AE%89%E5%85%A8\"><span class=\"toc-text\">LLM可控性与安全</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E8%AE%AD%E7%BB%83%E5%BE%AE%E8%B0%83%E4%BC%98%E5%8C%96%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2\"><span class=\"toc-text\">LLM训练、微调、优化以及部署</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">LLM训练</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E5%BE%AE%E8%B0%83\"><span class=\"toc-text\">LLM微调</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">LLM优化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E9%83%A8%E7%BD%B2\"><span class=\"toc-text\">LLM部署</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E5%8D%9A%E5%AE%A2%E8%AE%BA%E6%96%87%E4%BB%A5%E5%8F%8A%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">LLM博客、论文以及代码</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llm%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">LLM数据集</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#prompt%E5%B7%A5%E7%A8%8B\"><span class=\"toc-text\">Prompt工程</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#agi%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7%E5%8D%9A%E5%AE%A2%E8%AE%BA%E6%96%87\"><span class=\"toc-text\">AGI开源工具&amp;博客&amp;论文</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90\"><span class=\"toc-text\">文本生成</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatgpt\"><span class=\"toc-text\">ChatGPT</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#chatgpt-%E5%BA%94%E7%94%A8%E7%AF%87\"><span class=\"toc-text\">ChatGPT 应用篇</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#chatgpt-%E5%B7%A5%E5%85%B7%E7%AF%87\"><span class=\"toc-text\">ChatGPT 工具篇</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#chatgpt-%E6%8A%80%E6%9C%AF%E7%AF%87\"><span class=\"toc-text\">ChatGPT 技术篇</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#gpt4\"><span class=\"toc-text\">GPT4</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#gpt4-%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3\"><span class=\"toc-text\">GPT4 官方文档</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#gpt4-%E5%8D%9A%E5%AE%A2%E7%AF%87\"><span class=\"toc-text\">GPT4 博客篇</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#gpt4-%E8%AE%BA%E6%96%87%E7%AF%87\"><span class=\"toc-text\">GPT4 论文篇</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#anima\"><span class=\"toc-text\">Anima</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#bard\"><span class=\"toc-text\">Bard</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#baize\"><span class=\"toc-text\">Baize</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#baichuan%E4%BB%A5%E5%8F%8A%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">baichuan以及扩展</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#bloom\"><span class=\"toc-text\">BLOOM</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#biomedgpt\"><span class=\"toc-text\">BiomedGPT</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#claude\"><span class=\"toc-text\">Claude</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#claude-2\"><span class=\"toc-text\">Claude 2</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatglm-6b%E4%BB%A5%E5%8F%8A%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">ChatGLM-6B以及扩展</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatyuan\"><span class=\"toc-text\">ChatYuan</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#copilot-x\"><span class=\"toc-text\">Copilot X</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#colossalai\"><span class=\"toc-text\">ColossalAI</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#cpm-bee\"><span class=\"toc-text\">CPM-Bee</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#chatdb\"><span class=\"toc-text\">ChatDB</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#dolly\"><span class=\"toc-text\">Dolly</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#dolly2.0\"><span class=\"toc-text\">Dolly2.0</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#deepspeed-chat\"><span class=\"toc-text\">DeepSpeed-Chat</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#frugalgpt\"><span class=\"toc-text\">FrugalGPT</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#gpt3.5\"><span class=\"toc-text\">GPT3.5</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#jittorllms\"><span class=\"toc-text\">JittorLLMs</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm-as-controller\"><span class=\"toc-text\">LLM as Controller</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#metagpt\"><span class=\"toc-text\">MetaGPT</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#minigpt-4\"><span class=\"toc-text\">MiniGPT-4</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#moss\"><span class=\"toc-text\">MOSS</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#openchatkit\"><span class=\"toc-text\">OpenChatKit</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#openassistant\"><span class=\"toc-text\">OpenAssistant</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#webcpm\"><span class=\"toc-text\">WebCPM</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llama%E4%BB%A5%E5%8F%8A%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">LLaMA以及扩展</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E5%83%8F%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90\"><span class=\"toc-text\">图像、视频生成</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90\"><span class=\"toc-text\">代码生成</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AF%AD%E9%9F%B3%E7%94%9F%E6%88%90\"><span class=\"toc-text\">语音生成</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E6%A8%A1%E6%80%81%E7%94%9F%E6%88%90\"><span class=\"toc-text\">多模态生成</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%9B%9B%E6%9E%84%E7%AD%91%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B8%8E%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1\"><span class=\"toc-text\">四、构筑大语言模型应用：应用开发与架构设计</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%94promptllm%E8%AE%BA%E6%96%87%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8Baigc%E5%BA%94%E7%94%A8\"><span class=\"toc-text\">五、Prompt&amp;LLM论文、开源数据&amp;模型、AIGC应用</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#decryptprompt\"><span class=\"toc-text\">DecryptPrompt</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#my-blogs-chatgpt%E5%BA%94%E7%94%A8\"><span class=\"toc-text\">My blogs &amp; ChatGPT应用</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#llms\"><span class=\"toc-text\">LLMS</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B\"><span class=\"toc-text\">模型评测</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9B%BD%E5%A4%96%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">国外开源模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9B%BD%E5%86%85%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">国内开源模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B%E8%BF%9B%E5%B1%95\"><span class=\"toc-text\">垂直领域模型&amp;进展</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#tool-and-library\"><span class=\"toc-text\">Tool and Library</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6\"><span class=\"toc-text\">推理框架</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83rlhf%E6%A1%86%E6%9E%B6\"><span class=\"toc-text\">指令微调，预训练，rlhf框架</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#automulti-agent\"><span class=\"toc-text\">Auto&#x2F;Multi Agent</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#agent%E5%B7%A5%E5%85%B7%E6%A1%86%E6%9E%B6%E7%B1%BB\"><span class=\"toc-text\">Agent工具框架类</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%B6%E4%BB%96%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9Fagent\"><span class=\"toc-text\">其他垂直领域Agent</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#training-data\"><span class=\"toc-text\">Training Data</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#aigc\"><span class=\"toc-text\">AIGC</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#resources\"><span class=\"toc-text\">Resources</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%95%99%E7%A8%8B%E7%B1%BB\"><span class=\"toc-text\">教程类</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B9%A6%E7%B1%8D%E5%8D%9A%E5%AE%A2%E7%B1%BB\"><span class=\"toc-text\">书籍博客类</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#papers\"><span class=\"toc-text\">Papers</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#paper-list\"><span class=\"toc-text\">paper List</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BB%BC%E8%BF%B0\"><span class=\"toc-text\">综述</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E6%8E%A2%E7%A9%B6\"><span class=\"toc-text\">大模型能力探究</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#prompt-tunning%E8%8C%83%E5%BC%8F\"><span class=\"toc-text\">Prompt Tunning范式</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B8%BB%E6%B5%81llms\"><span class=\"toc-text\">主流LLMS</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E5%AF%B9%E9%BD%90-instruction_tunning\"><span class=\"toc-text\">指令微调&amp;对齐\r\n(instruction_tunning)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">对话模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%80%9D%E7%BB%B4%E9%93%BE-prompt_chain_of_thought\"><span class=\"toc-text\">思维链\r\n(prompt_chain_of_thought)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#rlhf\"><span class=\"toc-text\">RLHF</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm-agent-%E8%AE%A9%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E5%B7%A5%E5%85%B7-llm_agent\"><span class=\"toc-text\">LLM Agent 让模型使用工具\r\n(llm_agent)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8C%87%E4%BB%A4%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90-instruction_data_gen\"><span class=\"toc-text\">指令数据生成\r\n(instruction_data_gen)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AEpretrain_data\"><span class=\"toc-text\">预训练数据(pretrain_data)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B-domain_llms\"><span class=\"toc-text\">领域模型 (domain_llms)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#llm%E8%B6%85%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86-long_input\"><span class=\"toc-text\">LLM超长文本处理 (long_input)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#nl2sql\"><span class=\"toc-text\">NL2SQL</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%99%8D%E4%BD%8E%E6%A8%A1%E5%9E%8B%E5%B9%BB%E8%A7%89-reliability\"><span class=\"toc-text\">降低模型幻觉 (reliability)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0evaluation\"><span class=\"toc-text\">大模型评估（evaluation）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96inference\"><span class=\"toc-text\">推理优化(inference)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%9F%A5%E8%AF%86%E7%BC%96%E8%BE%91%E9%BB%91%E7%A7%91%E6%8A%80model_edit\"><span class=\"toc-text\">模型知识编辑黑科技(model_edit)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#other-prompt-engineerprompt_engineer\"><span class=\"toc-text\">Other Prompt\r\nEngineer(prompt_engineer)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#multimodal\"><span class=\"toc-text\">Multimodal</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#others\"><span class=\"toc-text\">Others</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E6%9D%A5%E6%BA%90\"><span class=\"toc-text\">🗂 参考链接来源</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5\"><span class=\"toc-text\">🤝 友情链接</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%A3%B0%E6%98%8E\"><span class=\"toc-text\">🗂声明</span></a></li></ol>","author":{"name":"King's OvO²","slug":"blog-author","avatar":"https://s2.loli.net/2023/10/21/NZgSpryHx6LthfM.png","link":"/","description":"","socials":{"github":"https://github.com/KangChou","twitter":"https://twitter.com/","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/","csdn":"https://blog.csdn.net/weixin_41194129?type=lately","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"AI绘画之复原神秘的楼兰古国【从辉煌到遍地黄沙】","uid":"19444a03784a5e93538b32ece3254a9f","slug":"aigc4","date":"2023-10-20T15:36:31.930Z","updated":"2023-10-20T17:52:52.901Z","comments":true,"path":"api/articles/aigc4.json","keywords":null,"cover":"https://s2.loli.net/2023/10/20/khSxlGV9D74tbQL.jpg","text":"楼兰，楼兰国是西域古国名（遗址在今新疆罗布泊西北岸）。西汉昭帝（公元前77年）前的楼兰既指楼兰国，而西汉昭帝后的楼兰则指的是楼兰城（今亦称楼兰故城）。 公元前3...","permalink":"/post/aigc4","photos":[],"count_time":{"symbolsCount":412,"symbolsTime":"1 mins."},"categories":[{"name":"人工智能","slug":"人工智能","count":9,"path":"api/categories/人工智能.json"}],"tags":[{"name":"核心算法","slug":"核心算法","count":8,"path":"api/tags/核心算法.json"}],"author":{"name":"King's OvO²","slug":"blog-author","avatar":"https://s2.loli.net/2023/10/21/NZgSpryHx6LthfM.png","link":"/","description":"","socials":{"github":"https://github.com/KangChou","twitter":"https://twitter.com/","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/","csdn":"https://blog.csdn.net/weixin_41194129?type=lately","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"AI绘画之中国古建筑之美","uid":"5c307478e6960dd7681eaa126a1f4100","slug":"aigc1","date":"2023-09-06T09:19:32.000Z","updated":"2023-10-20T16:21:43.966Z","comments":true,"path":"api/articles/aigc1.json","keywords":null,"cover":"https://s2.loli.net/2023/10/20/HE7McJ1rgasZA5w.png","text":"古建筑之美，在于它承载的是不同历史时期的人文特色，承载的是碧瓦朱檐间亘古流传的故事，还承载了中华千百年的历史文化。 中国古建筑见证了中国千古文化底蕴，一砖一瓦一...","permalink":"/post/aigc1","photos":[],"count_time":{"symbolsCount":819,"symbolsTime":"1 mins."},"categories":[{"name":"人工智能","slug":"人工智能","count":9,"path":"api/categories/人工智能.json"}],"tags":[{"name":"核心算法","slug":"核心算法","count":8,"path":"api/tags/核心算法.json"}],"author":{"name":"King's OvO²","slug":"blog-author","avatar":"https://s2.loli.net/2023/10/21/NZgSpryHx6LthfM.png","link":"/","description":"","socials":{"github":"https://github.com/KangChou","twitter":"https://twitter.com/","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/","csdn":"https://blog.csdn.net/weixin_41194129?type=lately","juejin":"","customs":{}}},"feature":true}}